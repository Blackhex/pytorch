<testsuites>
  <testsuite name="pytest" errors="0" failures="1" skipped="297" tests="1068" time="2433.505" timestamp="2023-05-05T21:45:11.235284" hostname="BartonTest">
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_abs_cpu_float32" time="0.415" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_acos_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_acosh_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_asin_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_asinh_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_atan2_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_atan_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_atanh_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_cat_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_clamp_cpu_float32" time="0.065" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_digamma_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_div_floor_rounding_cpu_float32" time="0.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_div_no_rounding_mode_cpu_float32" time="0.009" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_div_trunc_rounding_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_erf_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_erfc_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_erfinv_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_exp2_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_expm1_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_ge_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_gt_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_i0_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_igamma_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_igammac_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_le_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_lgamma_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_det_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_det_singular_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_householder_product_cpu_float32" time="0.012" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_inv_cpu_float32" time="0.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_matrix_power_cpu_float32" time="0.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_log1p_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_log_softmax_cpu_float32" time="0.018" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_log_softmax_with_dtype_cpu_float32" time="0.010" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_logit_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_logsumexp_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_lt_cpu_float32" time="0.010" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mH_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_matmul_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_matrix_exp_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_max_binary_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_min_binary_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_movedim_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mul_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mvlgamma_mvlgamma_p_1_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mvlgamma_mvlgamma_p_3_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mvlgamma_mvlgamma_p_5_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_ne_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_neg_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv1d_cpu_float32" time="0.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv2d_cpu_float32" time="0.017" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv_transpose1d_cpu_float32" time="0.011" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv_transpose2d_cpu_float32" time="0.016" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv_transpose3d_cpu_float32" time="0.031" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_group_norm_cpu_float32" time="0.009" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_layer_norm_cpu_float32" time="0.011" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_outer_cpu_float32" time="0.011" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_decimals_0_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_decimals_3_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_decimals_neg_3_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_sigmoid_cpu_float32" time="0.009" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_sinc_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_softmax_cpu_float32" time="0.014" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_softmax_with_dtype_cpu_float32" time="0.011" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_sub_cpu_float32" time="0.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_tanh_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_transpose_cpu_float32" time="0.012" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_trunc_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_vstack_cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_xlogy_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_H_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_H_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_T_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_T_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___getitem___cpu_complex64" time="3.707" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___radd___cpu_complex64" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___radd___cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rdiv___cpu_complex64" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rdiv___cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmatmul___cpu_complex64" time="0.007" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmatmul___cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmod___cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmul___cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmul___cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rpow___cpu_complex64" time="0.017" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\_tensor.py:879: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rpow___cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rsub___cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rsub___cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__native_batch_norm_legit_cpu_float32" time="2.119" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__segment_reduce_lengths_cpu_float32" time="5.459" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__segment_reduce_offsets_cpu_float32" time="5.437" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__softmax_backward_data_cpu_float32" time="0.098" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__upsample_bilinear2d_aa_cpu_float32" time="0.019" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_abs_cpu_complex64" time="0.331" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_abs_cpu_float32" time="0.171" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acos_cpu_complex64" time="0.950" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acos_cpu_float32" time="0.473" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acosh_cpu_complex64" time="0.892" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acosh_cpu_float32" time="0.443" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_add_cpu_complex64" time="3.829" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_add_cpu_float32" time="1.978" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addbmm_cpu_complex64" time="4.318" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addbmm_cpu_float32" time="1.054" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcdiv_cpu_complex64" time="4.141" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcdiv_cpu_float32" time="1.988" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcmul_cpu_complex64" time="4.775" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcmul_cpu_float32" time="2.383" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_cpu_complex64" time="2.037" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_cpu_float32" time="0.615" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_decomposed_cpu_complex64" time="2.016" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_decomposed_cpu_float32" time="0.631" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmv_cpu_complex64" time="2.081" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmv_cpu_float32" time="1.014" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addr_cpu_complex64" time="1.410" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addr_cpu_float32" time="0.688" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_all_cpu_complex64" time="1.203" file="test_ops_jit.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py:160: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Copy.cpp:276.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_all_cpu_float32" time="0.660" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_allclose_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_allclose_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_amax_cpu_float32" time="3.127" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_amin_cpu_float32" time="3.152" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_aminmax_cpu_float32" time="0.403" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_angle_cpu_complex64" time="0.312" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_angle_cpu_float32" time="0.160" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_any_cpu_complex64" time="1.183" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_any_cpu_float32" time="0.627" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_arange_cpu_float32" time="0.034" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argmax_cpu_float32" time="0.681" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argmin_cpu_float32" time="0.633" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argsort_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argwhere_cpu_complex64" time="0.553" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argwhere_cpu_float32" time="0.312" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_cpu_complex64" time="1.783" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_cpu_float32" time="0.887" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_partial_views_cpu_complex64" time="0.364" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_partial_views_cpu_float32" time="0.356" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_scatter_cpu_complex64" time="2.577" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_scatter_cpu_float32" time="1.268" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asin_cpu_complex64" time="0.349" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asin_cpu_float32" time="0.173" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asinh_cpu_complex64" time="0.335" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asinh_cpu_float32" time="0.165" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atan2_cpu_float32" time="1.478" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atan_cpu_complex64" time="0.337" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atan_cpu_float32" time="0.174" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atanh_cpu_complex64" time="0.326" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atanh_cpu_float32" time="0.163" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_1d_cpu_complex64" time="0.967" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_1d_cpu_float32" time="0.096" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_2d_cpu_complex64" time="0.964" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_2d_cpu_float32" time="0.093" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_3d_cpu_complex64" time="0.964" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_3d_cpu_float32" time="0.092" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_baddbmm_cpu_complex64" time="4.653" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_baddbmm_cpu_float32" time="1.025" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bernoulli_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bfloat16_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bfloat16_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_block_diag_cpu_complex64" time="1.368" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_block_diag_cpu_float32" time="0.097" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bmm_cpu_complex64" time="0.354" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bmm_cpu_float32" time="0.182" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bool_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bool_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_shapes_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_tensors_cpu_complex64" time="0.231" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_tensors_cpu_float32" time="0.118" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_to_cpu_complex64" time="2.268" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_to_cpu_float32" time="1.113" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bucketize_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected failure!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected failure!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_byte_cpu_complex64" time="0.031" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_byte_cpu_float32" time="0.031" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cartesian_prod_cpu_complex64" time="0.510" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cartesian_prod_cpu_float32" time="0.087" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cat_cpu_complex64" time="1.613" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cat_cpu_float32" time="1.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cauchy_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cdist_cpu_float32" time="15.749" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cdouble_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cdouble_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ceil_cpu_float32" time="0.167" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cfloat_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cfloat_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chalf_cpu_complex64" time="0.051" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_methods_invocations.py:15407: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\EmptyTensor.cpp:32.) op=lambda x, *args, **kwargs: x.chalf(*args, **kwargs),
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chalf_cpu_float32" time="0.015" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_char_cpu_complex64" time="0.030" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_char_cpu_float32" time="0.032" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_cpu_complex64" time="6.234" file="test_ops_jit.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py:160: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.
L = torch.cholesky(A)
should be replaced with
L = torch.linalg.cholesky(A)
and
U = torch.cholesky(A, upper=True)
should be replaced with
U = torch.linalg.cholesky(A).mH().
This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:1702.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_cpu_float32" time="2.893" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_inverse_cpu_complex64" time="3.988" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_inverse_cpu_float32" time="1.997" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_solve_cpu_complex64" time="3.989" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_solve_cpu_float32" time="2.062" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chunk_cpu_complex64" time="1.212" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chunk_cpu_float32" time="0.575" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clamp_cpu_float32" time="0.876" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clamp_max_cpu_float32" time="1.362" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clamp_min_cpu_float32" time="1.363" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clone_cpu_complex64" time="0.605" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clone_cpu_float32" time="0.302" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_column_stack_cpu_complex64" time="0.497" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_column_stack_cpu_float32" time="0.251" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_combinations_cpu_complex64" time="3.207" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_combinations_cpu_float32" time="1.525" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_complex_cpu_float32" time="0.723" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_cpu_complex64" time="0.891" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_cpu_float32" time="0.405" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_physical_cpu_complex64" time="0.307" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_physical_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_constant_pad_nd_cpu_complex64" time="8.366" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_constant_pad_nd_cpu_float32" time="4.067" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_contiguous_cpu_complex64" time="0.318" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_contiguous_cpu_float32" time="0.167" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_copysign_cpu_float32" time="1.370" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_corrcoef_cpu_complex64" time="1.427" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_corrcoef_cpu_float32" time="0.670" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cos_cpu_complex64" time="0.937" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cos_cpu_float32" time="0.476" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cosh_cpu_complex64" time="0.964" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cosh_cpu_float32" time="0.471" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_count_nonzero_cpu_complex64" time="1.847" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_count_nonzero_cpu_float32" time="0.972" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cov_cpu_complex64" time="0.373" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cov_cpu_float32" time="0.360" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cross_cpu_complex64" time="0.974" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cross_cpu_float32" time="0.487" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cummax_cpu_float32" time="0.493" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cummin_cpu_float32" time="0.495" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumprod_cpu_complex64" time="4.318" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumprod_cpu_float32" time="2.076" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumsum_cpu_complex64" time="1.262" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumsum_cpu_float32" time="0.619" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumulative_trapezoid_cpu_complex64" time="1.507" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumulative_trapezoid_cpu_float32" time="0.744" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_deg2rad_cpu_float32" time="0.159" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_cpu_complex64" time="4.780" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_cpu_float32" time="2.342" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_embed_cpu_complex64" time="4.781" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_embed_cpu_float32" time="2.442" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagflat_cpu_complex64" time="1.595" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagflat_cpu_float32" time="0.769" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_copy_cpu_complex64" time="2.423" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_copy_cpu_float32" time="1.223" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_cpu_complex64" time="4.867" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_cpu_float32" time="2.402" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_scatter_cpu_complex64" time="5.217" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_scatter_cpu_float32" time="2.525" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diff_cpu_complex64" time="22.371" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diff_cpu_float32" time="10.672" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_digamma_cpu_float32" time="0.445" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dist_cpu_complex64" time="16.204" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dist_cpu_float32" time="8.017" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_floor_rounding_cpu_float32" time="1.602" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_no_rounding_mode_cpu_complex64" time="3.155" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_no_rounding_mode_cpu_float32" time="1.610" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_trunc_rounding_cpu_float32" time="1.677" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dot_cpu_complex64" time="0.673" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dot_cpu_float32" time="0.179" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_double_cpu_complex64" time="0.091" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_double_cpu_float32" time="0.097" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dsplit_cpu_complex64" time="0.823" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dsplit_cpu_float32" time="0.413" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dstack_cpu_complex64" time="0.361" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dstack_cpu_float32" time="0.188" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_einsum_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_einsum_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_like_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_like_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_permuted_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_permuted_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eq_cpu_complex64" time="0.932" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eq_cpu_float32" time="0.569" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_equal_cpu_complex64" time="0.349" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_equal_cpu_float32" time="0.196" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_erf_cpu_float32" time="0.182" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_erfc_cpu_float32" time="0.553" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_erfinv_cpu_float32" time="0.181" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp2_cpu_complex64" time="0.943" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp2_cpu_float32" time="0.452" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp_cpu_complex64" time="1.001" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp_cpu_float32" time="0.475" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_as_cpu_complex64" time="0.503" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_as_cpu_float32" time="0.266" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_cpu_complex64" time="1.531" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_cpu_float32" time="0.787" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expm1_cpu_complex64" time="0.336" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expm1_cpu_float32" time="0.172" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exponential_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eye_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eye_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft2_cpu_complex64" time="1.045" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft2_cpu_float32" time="0.545" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft_cpu_complex64" time="1.123" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft_cpu_float32" time="0.589" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftn_cpu_complex64" time="1.381" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftn_cpu_float32" time="0.697" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftshift_cpu_complex64" time="0.818" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftshift_cpu_float32" time="0.404" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft2_cpu_complex64" time="1.041" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft2_cpu_float32" time="0.541" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft_cpu_complex64" time="1.121" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft_cpu_float32" time="0.575" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfftn_cpu_complex64" time="1.305" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfftn_cpu_float32" time="0.676" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft2_cpu_complex64" time="1.049" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft2_cpu_float32" time="0.540" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft_cpu_complex64" time="1.118" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft_cpu_float32" time="0.590" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftn_cpu_complex64" time="1.417" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftn_cpu_float32" time="0.680" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftshift_cpu_complex64" time="0.811" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftshift_cpu_float32" time="0.401" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ihfft2_cpu_float32" time="0.542" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ihfft_cpu_float32" time="0.590" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ihfftn_cpu_float32" time="0.691" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft2_cpu_complex64" time="1.054" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft2_cpu_float32" time="0.535" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft_cpu_complex64" time="1.207" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft_cpu_float32" time="0.585" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfftn_cpu_complex64" time="1.295" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfftn_cpu_float32" time="0.667" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_rfft2_cpu_float32" time="0.542" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_rfft_cpu_float32" time="0.580" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_rfftn_cpu_float32" time="0.685" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fill_cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fill_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flatten_cpu_complex64" time="1.856" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flatten_cpu_float32" time="0.939" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flip_cpu_complex64" time="3.123" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flip_cpu_float32" time="1.575" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fliplr_cpu_complex64" time="0.601" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fliplr_cpu_float32" time="0.302" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flipud_cpu_complex64" time="0.592" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flipud_cpu_float32" time="0.302" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_cpu_complex64" time="0.091" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_cpu_float32" time="0.091" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_power_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_power_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_floor_cpu_float32" time="0.167" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_floor_divide_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fmax_cpu_float32" time="1.371" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fmin_cpu_float32" time="1.374" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fmod_cpu_float32" time="1.457" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_frac_cpu_float32" time="0.173" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_frexp_cpu_float32" time="0.469" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_like_cpu_complex64" time="0.373" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_like_cpu_float32" time="0.199" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gather_cpu_complex64" time="1.586" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gather_cpu_float32" time="0.789" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ge_cpu_float32" time="0.496" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_geometric_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_geqrf_cpu_complex64" time="3.522" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_geqrf_cpu_float32" time="1.824" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gradient_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gradient_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_grid_sampler_2d_cpu_float32" time="1.021" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gt_cpu_float32" time="0.496" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_half_cpu_complex64" time="0.094" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_half_cpu_float32" time="0.092" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_heaviside_cpu_float32" time="0.443" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_histc_cpu_float32" time="4.846" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_histogram_cpu_float32" time="0.717" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_histogramdd_cpu_float32" time="0.231" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hsplit_cpu_complex64" time="0.784" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hsplit_cpu_float32" time="0.378" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hstack_cpu_complex64" time="0.356" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hstack_cpu_float32" time="0.176" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hypot_cpu_float32" time="1.363" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_i0_cpu_float32" time="0.447" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_igamma_cpu_float32" time="0.442" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_igammac_cpu_float32" time="0.437" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_imag_cpu_complex64" time="0.443" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_add_cpu_complex64" time="3.037" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_add_cpu_float32" time="1.492" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_copy_cpu_complex64" time="1.001" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_copy_cpu_float32" time="0.498" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_fill_cpu_complex64" time="1.964" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_fill_cpu_float32" time="0.972" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_put_cpu_complex64" time="1.404" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_put_cpu_float32" time="0.689" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_reduce_cpu_float32" time="5.695" file="test_ops_jit.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py:160: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\TensorAdvancedIndexing.cpp:1110.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_select_cpu_complex64" time="0.949" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_select_cpu_float32" time="0.484" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_inner_cpu_complex64" time="0.648" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_inner_cpu_float32" time="0.318" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_int_cpu_complex64" time="0.032" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_int_cpu_float32" time="0.031" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isclose_cpu_complex64" time="1.729" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isclose_cpu_float32" time="0.901" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isfinite_cpu_complex64" time="0.282" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isfinite_cpu_float32" time="0.155" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isin_cpu_float32" time="0.057" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isinf_cpu_complex64" time="0.104" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isinf_cpu_float32" time="0.056" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isnan_cpu_complex64" time="0.101" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isnan_cpu_float32" time="0.057" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isneginf_cpu_float32" time="0.054" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isposinf_cpu_float32" time="0.053" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isreal_cpu_complex64" time="0.271" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isreal_cpu_float32" time="0.147" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_istft_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped! istft does not match the native function">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped! istft does not match the native function</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_2inputs_2outputs_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_2inputs_2outputs_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_4inputs_with_extra_args_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_4inputs_with_extra_args_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_return_by_ref_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_return_by_ref_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_unary_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_unary_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_kron_cpu_complex64" time="0.370" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_kron_cpu_float32" time="0.176" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_kthvalue_cpu_float32" time="1.703" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ldexp_cpu_complex64" time="2.847" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ldexp_cpu_float32" time="1.397" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_le_cpu_float32" time="0.506" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lerp_cpu_complex64" time="7.896" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lerp_cpu_float32" time="2.600" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lgamma_cpu_float32" time="0.458" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_cpu_complex64" time="3.239" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_cpu_float32" time="1.650" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_ex_cpu_complex64" time="3.344" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_ex_cpu_float32" time="1.607" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cond_cpu_complex64" time="0.513" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cond_cpu_float32" time="0.260" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cross_cpu_complex64" time="0.504" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cross_cpu_float32" time="0.251" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_cpu_complex64" time="1.372" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_cpu_float32" time="0.702" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_singular_cpu_complex64" time="5.412" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_singular_cpu_float32" time="3.663" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_diagonal_cpu_complex64" time="2.395" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_diagonal_cpu_float32" time="1.183" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eig_cpu_complex64" time="1.516" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eig_cpu_float32" time="0.765" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigh_cpu_complex64" time="1.431" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigh_cpu_float32" time="0.711" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvals_cpu_complex64" time="1.345" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvals_cpu_float32" time="0.681" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvalsh_cpu_complex64" time="1.407" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvalsh_cpu_float32" time="0.634" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_householder_product_cpu_complex64" time="2.573" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_householder_product_cpu_float32" time="1.327" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_cpu_complex64" time="1.293" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_cpu_float32" time="0.639" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_ex_cpu_complex64" time="1.380" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_ex_cpu_float32" time="0.693" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_cpu_complex64" time="0.006" file="test_ops_jit.py">
      <failure message="Exception: &#10;                Error testing linalg.ldl_factor function variant&#10;                with dtype: torch.complex64&#10;                with inputs SampleInput(input=tensor([[-0.6672+2.1439j, -1.5107-0.8421j, -1.8603-1.2981j,  0.7680-0.5762j,&#10;  0.6918+0.6470j],&#10;[-1.5107-0.8421j,  1.3722-1.1678j,  1.6211+2.2143j,  0.3795-1.2266j,&#10;  0.3179+0.1067j],&#10;[-1.8603-1.2981j,  1.6211+2.2143j, -0.8296-1.4695j,  1.5598+1.1365j,&#10;  0.2750-1.0817j],&#10;[ 0.7680-0.5762j,  0.3795-1.2266j,  1.5598+1.1365j, -1.1712-0.9925j,&#10; -1.9657-0.5530j],&#10;[ 0.6918+0.6470j,  0.3179+0.1067j,  0.2750-1.0817j, -1.9657-0.5530j,&#10;  0.9055-0.5933j]]), args=(), kwargs={'hermitian': False}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002173DBA1260&gt;, broadcasts_input=False, name=''):">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 85, in test_variant_consistency_jit
    self.indiv_variant_test_jit(device, dtype, op, sample, func_type, variant, has_fake_function)
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 120, in indiv_variant_test_jit
    check_against_reference(self,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py", line 89, in check_against_reference
    outputs = self.runAndSaveRNG(reference_func, nograd_inputs, kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py", line 160, in runAndSaveRNG
    results = func(*inputs, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: false INTERNAL ASSERT FAILED at "C:\\Users\\radekbarton\\Projects\\pytorch\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp":1567, please report a bug to PyTorch. torch.linalg.ldl_factor: Unknown error code: 4.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 92, in test_variant_consistency_jit
    raise Exception(variant_error_info) from e
Exception: 
                Error testing linalg.ldl_factor function variant
                with dtype: torch.complex64
                with inputs SampleInput(input=tensor([[-0.6672+2.1439j, -1.5107-0.8421j, -1.8603-1.2981j,  0.7680-0.5762j,
  0.6918+0.6470j],
[-1.5107-0.8421j,  1.3722-1.1678j,  1.6211+2.2143j,  0.3795-1.2266j,
  0.3179+0.1067j],
[-1.8603-1.2981j,  1.6211+2.2143j, -0.8296-1.4695j,  1.5598+1.1365j,
  0.2750-1.0817j],
[ 0.7680-0.5762j,  0.3795-1.2266j,  1.5598+1.1365j, -1.1712-0.9925j,
 -1.9657-0.5530j],
[ 0.6918+0.6470j,  0.3179+0.1067j,  0.2750-1.0817j, -1.9657-0.5530j,
  0.9055-0.5933j]]), args=(), kwargs={'hermitian': False}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002173DBA1260&gt;, broadcasts_input=False, name=''):</failure>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_cpu_float32" time="0.154" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_ex_cpu_complex64" time="0.564" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_ex_cpu_float32" time="0.161" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_solve_cpu_complex64" time="1.261" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_solve_cpu_float32" time="0.468" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_cpu_complex64" time="7.996" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_cpu_float32" time="8.066" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_grad_oriented_cpu_complex64" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_grad_oriented_cpu_float32" time="0.011" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_cpu_float32" time="2.540" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_factor_cpu_float32" time="2.603" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_factor_ex_cpu_float32" time="2.420" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_solve_cpu_float32" time="31.638" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_norm_cpu_complex64" time="11.163" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_norm_cpu_float32" time="5.606" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_power_cpu_complex64" time="2.967" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_power_cpu_float32" time="1.475" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_hermitian_cpu_complex64" time="0.407" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_hermitian_cpu_float32" time="0.218" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_multi_dot_cpu_complex64" time="1.207" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_multi_dot_cpu_float32" time="0.602" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_cpu_complex64" time="16.234" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_cpu_float32" time="8.162" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_subgradients_at_zero_cpu_complex64" time="11.970" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_subgradients_at_zero_cpu_float32" time="6.053" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_cpu_complex64" time="4.247" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_cpu_float32" time="2.039" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_hermitian_cpu_complex64" time="1.406" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_hermitian_cpu_float32" time="0.687" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_singular_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_singular_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_qr_cpu_complex64" time="8.377" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_qr_cpu_float32" time="4.080" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_slogdet_cpu_complex64" time="1.567" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_slogdet_cpu_float32" time="0.766" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_cpu_complex64" time="2.955" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_cpu_float32" time="1.450" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_ex_cpu_complex64" time="3.162" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_ex_cpu_float32" time="1.571" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_triangular_cpu_float32" time="41.741" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svd_cpu_complex64" time="40.249" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svd_cpu_float32" time="19.873" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svdvals_cpu_complex64" time="5.379" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svdvals_cpu_float32" time="2.735" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vander_cpu_complex64" time="1.621" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vander_cpu_float32" time="0.796" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vecdot_cpu_float32" time="3.407" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vector_norm_cpu_complex64" time="29.622" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vector_norm_cpu_float32" time="14.907" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linspace_cpu_complex64" time="2.412" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linspace_cpu_float32" time="0.033" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log10_cpu_complex64" time="0.934" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log10_cpu_float32" time="0.475" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log1p_cpu_complex64" time="0.337" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log1p_cpu_float32" time="0.172" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log2_cpu_complex64" time="0.948" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log2_cpu_float32" time="0.472" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_cpu_complex64" time="0.933" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_cpu_float32" time="0.471" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_normal_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_softmax_cpu_float32" time="1.148" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_softmax_with_dtype_cpu_complex64" time="2.313" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_softmax_with_dtype_cpu_float32" time="1.183" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logaddexp2_cpu_float32" time="0.168" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logaddexp_cpu_complex64" time="2.887" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logaddexp_cpu_float32" time="1.387" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logcumsumexp_cpu_complex64" time="1.869" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logcumsumexp_cpu_float32" time="0.949" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logdet_cpu_complex64" time="2.880" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logdet_cpu_float32" time="1.385" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_and_cpu_complex64" time="0.800" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_and_cpu_float32" time="0.426" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_not_cpu_complex64" time="0.267" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_not_cpu_float32" time="0.148" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_or_cpu_complex64" time="0.809" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_or_cpu_float32" time="0.425" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_xor_cpu_complex64" time="0.798" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_xor_cpu_float32" time="0.430" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logit_cpu_float32" time="0.603" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logspace_cpu_complex64" time="20.781" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logspace_cpu_float32" time="0.033" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logsumexp_cpu_float32" time="2.588" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_long_cpu_complex64" time="0.031" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_long_cpu_float32" time="0.032" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lt_cpu_float32" time="0.502" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_cpu_float32" time="0.174" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\functional.py:1731: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2001.)
  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_solve_cpu_float32" time="14.617" file="test_ops_jit.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py:160: UserWarning: torch.lu_solve is deprecated in favor of torch.linalg.lu_solveand will be removed in a future PyTorch release.
Note that torch.linalg.lu_solve has its arguments reversed.
X = torch.lu_solve(B, LU, pivots)
should be replaced with
X = torch.linalg.lu_solve(LU, pivots, B) (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2155.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_unpack_cpu_complex64" time="5.198" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_unpack_cpu_float32" time="2.632" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mH_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mH_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mT_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mT_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_amax_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_amin_cpu_float32" time="0.023" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_argmax_cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_argmin_cpu_float32" time="0.006" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumprod_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumprod_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumsum_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumsum_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_fill_cpu_complex64" time="2.493" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_fill_cpu_float32" time="1.251" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_log_softmax_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_logaddexp_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_logsumexp_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_mean_cpu_complex64" time="0.012" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_mean_cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_median_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_norm_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_normalize_cpu_complex64" time="0.008" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_normalize_cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_prod_cpu_complex64" time="0.009" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_prod_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_scatter_cpu_complex64" time="1.286" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_scatter_cpu_float32" time="0.631" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_select_cpu_complex64" time="2.123" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_select_cpu_float32" time="1.054" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_softmax_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_softmin_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_std_cpu_complex64" time="0.030" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_std_cpu_float32" time="0.006" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_sum_cpu_complex64" time="0.009" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_sum_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_var_cpu_complex64" time="0.030" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_var_cpu_float32" time="0.006" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matmul_cpu_complex64" time="4.824" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matmul_cpu_float32" time="2.538" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matrix_exp_cpu_complex64" time="1.179" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matrix_exp_cpu_float32" time="0.739" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_binary_cpu_float32" time="1.605" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_pool2d_with_indices_backward_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_reduction_no_dim_cpu_float32" time="0.322" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_reduction_with_dim_cpu_float32" time="0.846" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_maximum_cpu_float32" time="1.372" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mean_cpu_complex64" time="6.839" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mean_cpu_float32" time="3.582" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_median_cpu_float32" time="2.051" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_list_of_tensors_cpu_complex64" time="1.894" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_list_of_tensors_cpu_float32" time="0.920" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_variadic_tensors_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_variadic_tensors_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_min_binary_cpu_float32" time="1.534" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_min_reduction_no_dim_cpu_float32" time="0.302" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_min_reduction_with_dim_cpu_float32" time="0.840" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_minimum_cpu_float32" time="1.365" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mm_cpu_complex64" time="0.683" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mm_cpu_float32" time="0.180" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mode_cpu_float32" time="1.467" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_movedim_cpu_complex64" time="0.746" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_movedim_cpu_float32" time="0.445" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_msort_cpu_float32" time="0.382" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mul_cpu_complex64" time="3.086" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mul_cpu_float32" time="1.611" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_multinomial_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mv_cpu_complex64" time="0.350" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mv_cpu_float32" time="0.177" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mvlgamma_mvlgamma_p_1_cpu_float32" time="1.538" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mvlgamma_mvlgamma_p_3_cpu_float32" time="1.552" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mvlgamma_mvlgamma_p_5_cpu_float32" time="1.533" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nan_to_num_cpu_float32" time="0.458" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nanmean_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nanmedian_cpu_float32" time="2.045" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nanquantile_cpu_float32" time="10.821" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nansum_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_copy_cpu_complex64" time="0.515" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_copy_cpu_float32" time="0.267" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_cpu_complex64" time="3.178" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_cpu_float32" time="1.572" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_native_batch_norm_cpu_float32" time="0.177" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_native_dropout_backward_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_native_layer_norm_cpu_float32" time="0.205" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ne_cpu_complex64" time="0.824" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ne_cpu_float32" time="0.500" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_neg_cpu_complex64" time="0.326" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_neg_cpu_float32" time="0.166" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_strided_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected: new_empty_strided is not comparable">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected: new_empty_strided is not comparable</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_strided_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected: new_empty_strided is not comparable">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected: new_empty_strided is not comparable</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_full_cpu_complex64" time="0.407" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_full_cpu_float32" time="0.212" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_ones_cpu_complex64" time="0.386" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_ones_cpu_float32" time="0.203" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_zeros_cpu_complex64" time="0.388" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_zeros_cpu_float32" time="0.204" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nextafter_cpu_float32" time="0.437" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_avg_pool1d_cpu_float32" time="0.702" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_avg_pool2d_cpu_float32" time="0.312" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_avg_pool3d_cpu_float32" time="0.291" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_max_pool1d_cpu_float32" time="1.246" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_max_pool2d_cpu_float32" time="0.684" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_max_pool3d_cpu_float32" time="0.011" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_alpha_dropout_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_avg_pool1d_cpu_float32" time="1.470" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_avg_pool2d_cpu_float32" time="1.180" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_avg_pool3d_cpu_float32" time="1.074" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_batch_norm_cpu_float32" time="2.342" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_bilinear_cpu_float32" time="1.595" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_binary_cross_entropy_cpu_float32" time="1.197" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_binary_cross_entropy_with_logits_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_celu_cpu_float32" time="0.259" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv1d_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv1d_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv2d_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Works on some configs!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Works on some configs!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv2d_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Works on some configs!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Works on some configs!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose1d_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose1d_cpu_float32" time="0.152" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose2d_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose2d_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose3d_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose3d_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_cosine_embedding_loss_cpu_float32" time="0.828" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_cosine_similarity_cpu_float32" time="0.906" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_cross_entropy_cpu_float32" time="3.539" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_ctc_loss_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_dropout2d_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_dropout3d_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_dropout_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_elu_cpu_float32" time="0.281" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_embedding_bag_cpu_float32" time="0.006" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_embedding_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_feature_alpha_dropout_with_train_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_feature_alpha_dropout_without_train_cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_feature_alpha_dropout_without_train_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_fractional_max_pool2d_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_fractional_max_pool3d_cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_gaussian_nll_loss_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_gelu_cpu_float32" time="0.670" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_glu_cpu_float32" time="3.883" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_grid_sample_cpu_float32" time="2.805" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_group_norm_cpu_float32" time="0.048" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardshrink_cpu_float32" time="0.519" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardsigmoid_cpu_float32" time="0.177" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardswish_cpu_float32" time="0.358" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardtanh_cpu_float32" time="0.555" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hinge_embedding_loss_cpu_float32" time="1.173" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_huber_loss_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_instance_norm_cpu_float32" time="0.048" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_area_cpu_float32" time="0.578" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_bicubic_cpu_float32" time="0.360" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_bilinear_cpu_float32" time="0.341" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_linear_cpu_float32" time="0.339" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_nearest_cpu_float32" time="0.337" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_trilinear_cpu_float32" time="0.349" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_kl_div_cpu_float32" time="2.145" file="test_ops_jit.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_l1_loss_cpu_complex64" time="2.138" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_l1_loss_cpu_float32" time="0.141" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_layer_norm_cpu_float32" time="0.800" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_leaky_relu_cpu_float32" time="0.799" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_linear_cpu_complex64" time="2.857" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_linear_cpu_float32" time="1.523" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_local_response_norm_cpu_float32" time="0.345" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_logsigmoid_cpu_float32" time="0.286" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_margin_ranking_loss_cpu_float32" time="3.097" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_pool1d_cpu_float32" time="160.174" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_pool2d_cpu_float32" time="303.900" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_pool3d_cpu_float32" time="177.394" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool1d_cpu_float32" time="56.030" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool1d_grad_cpu_float32" time="4.111" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool2d_cpu_float32" time="85.301" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool2d_grad_cpu_float32" time="5.408" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool3d_cpu_float32" time="33.261" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool3d_grad_cpu_float32" time="4.370" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_mish_cpu_float32" time="0.290" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_mse_loss_cpu_float32" time="0.144" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_multi_margin_loss_cpu_float32" time="0.423" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_multilabel_margin_loss_cpu_float32" time="0.231" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_multilabel_soft_margin_loss_cpu_float32" time="1.509" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_nll_loss_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_normalize_cpu_complex64" time="2.050" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_normalize_cpu_float32" time="1.085" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_circular_cpu_complex64" time="1.494" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_circular_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_constant_cpu_complex64" time="8.519" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_constant_cpu_float32" time="4.198" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_reflect_cpu_complex64" time="2.831" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_reflect_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_replicate_cpu_complex64" time="2.718" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_replicate_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pairwise_distance_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pairwise_distance_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pdist_cpu_float32" time="0.485" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_shuffle_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_shuffle_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_unshuffle_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_unshuffle_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_poisson_nll_loss_cpu_float32" time="8.964" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_prelu_cpu_float32" time="0.019" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_relu6_cpu_float32" time="0.264" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_relu_cpu_float32" time="0.344" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_rrelu_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_scaled_dot_product_attention_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_selu_cpu_float32" time="0.249" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_silu_complex_cpu_complex64" time="0.162" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_silu_cpu_float32" time="0.261" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_smooth_l1_loss_cpu_float32" time="0.150" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_soft_margin_loss_cpu_float32" time="0.682" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softmin_cpu_float32" time="0.751" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softmin_with_dtype_cpu_complex64" time="1.463" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softmin_with_dtype_cpu_float32" time="0.768" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softplus_cpu_float32" time="0.265" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softshrink_cpu_float32" time="0.388" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softsign_cpu_complex64" time="0.641" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softsign_cpu_float32" time="0.336" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_tanhshrink_cpu_complex64" time="0.566" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_tanhshrink_cpu_float32" time="0.303" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_threshold_cpu_float32" time="0.378" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_loss_cpu_complex64" time="1.878" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_loss_cpu_float32" time="0.933" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_with_distance_loss_cpu_complex64" time="0.012" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_with_distance_loss_cpu_float32" time="0.008" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_unfold_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Internal assert failed!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Internal assert failed!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_unfold_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Internal assert failed!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Internal assert failed!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_upsample_bilinear_cpu_float32" time="0.346" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_44048.py:6: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_44048.py:6: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_44048.py:6: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_upsample_nearest_cpu_float32" time="0.333" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_44054.py:6: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_44054.py:6: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_44054.py:6: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nonzero_cpu_complex64" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nonzero_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nonzero_static_cpu_complex64" time="5.502" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nonzero_static_cpu_float32" time="2.836" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_cpu_complex64" time="18.748" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_cpu_float32" time="0.156" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_fro_cpu_complex64" time="0.417" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_fro_cpu_float32" time="0.180" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_inf_cpu_complex64" time="1.870" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_inf_cpu_float32" time="0.157" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_nuc_cpu_complex64" time="0.192" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_nuc_cpu_float32" time="0.192" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_in_place_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_in_place_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_number_mean_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_like_cpu_complex64" time="0.363" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_like_cpu_float32" time="0.197" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ormqr_cpu_complex64" time="71.323" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ormqr_cpu_float32" time="33.535" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_outer_cpu_complex64" time="0.337" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_outer_cpu_float32" time="0.169" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pca_lowrank_cpu_float32" time="0.013" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_permute_cpu_complex64" time="1.344" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_permute_cpu_float32" time="0.716" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pinverse_cpu_complex64" time="2.692" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pinverse_cpu_float32" time="1.312" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polar_cpu_float32" time="0.741" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_0_cpu_float32" time="0.758" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_1_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_2_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_3_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_4_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_positive_cpu_complex64" time="0.310" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_positive_cpu_float32" time="0.160" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pow_cpu_complex64" time="3.266" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pow_cpu_float32" time="1.570" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_prod_cpu_complex64" time="13.427" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_prod_cpu_float32" time="6.535" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_put_cpu_complex64" time="7.158" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_put_cpu_float32" time="3.516" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_qr_cpu_complex64" time="15.853" file="test_ops_jit.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py:160: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2431.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_qr_cpu_float32" time="7.755" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_quantile_cpu_float32" time="10.790" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rad2deg_cpu_float32" time="0.163" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rand_like_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rand_like_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randint_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randint_like_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_like_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_like_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ravel_cpu_complex64" time="0.906" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ravel_cpu_float32" time="0.469" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_real_cpu_complex64" time="0.445" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_real_cpu_float32" time="0.226" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reciprocal_cpu_complex64" time="0.938" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reciprocal_cpu_float32" time="0.475" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_remainder_cpu_float32" time="1.472" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_renorm_cpu_complex64" time="1.424" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_renorm_cpu_float32" time="0.697" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_cpu_complex64" time="3.787" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_cpu_float32" time="1.878" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_interleave_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_interleave_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_as_cpu_complex64" time="0.631" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_as_cpu_float32" time="0.317" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_cpu_complex64" time="2.243" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_cpu_float32" time="1.110" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize__cpu_complex64" time="0.045" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize__cpu_float32" time="0.045" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize_as__cpu_complex64" time="0.044" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize_as__cpu_float32" time="0.044" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_conj_cpu_complex64" time="0.594" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_conj_cpu_float32" time="0.301" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_neg_cpu_complex64" time="0.592" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_neg_cpu_float32" time="0.299" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_roll_cpu_complex64" time="5.569" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_roll_cpu_float32" time="2.773" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rot90_cpu_complex64" time="11.155" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rot90_cpu_float32" time="5.467" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_cpu_float32" time="0.170" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_decimals_0_cpu_float32" time="0.463" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_decimals_3_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_decimals_neg_3_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsqrt_cpu_complex64" time="0.945" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsqrt_cpu_float32" time="0.478" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsub_cpu_complex64" time="1.945" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsub_cpu_float32" time="0.996" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scalar_tensor_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scalar_tensor_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_add_cpu_complex64" time="2.300" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_add_cpu_float32" time="1.141" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_cpu_complex64" time="2.629" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_cpu_float32" time="1.293" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_amax_cpu_float32" time="3.589" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_amin_cpu_float32" time="3.593" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_mean_cpu_float32" time="3.716" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_prod_cpu_float32" time="3.975" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_sum_cpu_float32" time="3.566" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_searchsorted_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected failure!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected failure!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_select_cpu_complex64" time="1.599" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_select_cpu_float32" time="0.812" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_select_scatter_cpu_float32" time="0.820" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sgn_cpu_complex64" time="0.330" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sgn_cpu_float32" time="0.164" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_short_cpu_complex64" time="0.032" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_short_cpu_float32" time="0.032" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sigmoid_cpu_complex64" time="0.938" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sigmoid_cpu_float32" time="0.480" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sign_cpu_float32" time="0.160" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_bartlett_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_blackman_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_cosine_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_exponential_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_gaussian_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_general_cosine_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_general_hamming_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_hamming_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_hann_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_kaiser_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_nuttall_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signbit_cpu_float32" time="0.054" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sin_cpu_complex64" time="0.343" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sin_cpu_float32" time="0.175" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinc_cpu_complex64" time="0.913" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinc_cpu_float32" time="0.453" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinh_cpu_complex64" time="0.338" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinh_cpu_float32" time="0.177" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_slice_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="variant consistency doesn't work on torch.ops">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: variant consistency doesn't work on torch.ops</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_slice_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="variant consistency doesn't work on torch.ops">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: variant consistency doesn't work on torch.ops</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_slice_scatter_cpu_float32" time="1.639" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_softmax_cpu_float32" time="1.184" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_softmax_with_dtype_cpu_complex64" time="2.337" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_softmax_with_dtype_cpu_float32" time="1.198" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sort_cpu_float32" time="9.241" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sparse_mm_reduce_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sparse_sampled_addmm_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sparse_sampled_addmm_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_airy_ai_cpu_float32" time="0.083" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_j0_cpu_float32" time="0.083" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_j1_cpu_float32" time="0.081" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_y0_cpu_float32" time="0.079" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_y1_cpu_float32" time="0.083" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_t_cpu_float32" time="0.228" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_u_cpu_float32" time="0.230" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_v_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_w_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_entr_cpu_float32" time="0.162" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_erfcx_cpu_float32" time="0.231" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_hermite_polynomial_h_cpu_float32" time="0.234" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_hermite_polynomial_he_cpu_float32" time="0.229" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_i0e_cpu_float32" time="0.166" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_i1_cpu_float32" time="0.234" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_i1e_cpu_float32" time="0.237" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_laguerre_polynomial_l_cpu_float32" time="0.231" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_legendre_polynomial_p_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_log_ndtr_cpu_float32" time="0.240" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_i0_cpu_float32" time="0.082" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_i1_cpu_float32" time="0.082" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_k0_cpu_float32" time="0.079" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_k1_cpu_float32" time="0.081" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_ndtr_cpu_float32" time="0.239" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_ndtri_cpu_float32" time="0.237" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_polygamma_special_polygamma_n_0_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_scaled_modified_bessel_k0_cpu_float32" time="0.081" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_scaled_modified_bessel_k1_cpu_float32" time="0.083" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_t_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_u_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_v_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_w_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_spherical_bessel_j0_cpu_float32" time="0.083" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_xlog1py_cpu_float32" time="0.710" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_zeta_cpu_float32" time="0.231" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_cpu_complex64" time="0.716" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_cpu_float32" time="0.360" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_list_args_cpu_complex64" time="1.226" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_list_args_cpu_float32" time="0.590" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_with_sizes_cpu_complex64" time="1.629" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_with_sizes_cpu_float32" time="0.788" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sqrt_cpu_complex64" time="0.342" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sqrt_cpu_float32" time="0.172" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_square_cpu_complex64" time="0.890" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_square_cpu_float32" time="0.448" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_cpu_complex64" time="2.477" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_cpu_float32" time="1.256" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_multiple_cpu_complex64" time="1.896" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_multiple_cpu_float32" time="1.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stack_cpu_complex64" time="1.556" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stack_cpu_float32" time="0.898" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_cpu_complex64" time="3.514" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_cpu_float32" time="1.763" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_cpu_complex64" time="1.864" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_cpu_float32" time="0.924" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_unbiased_cpu_complex64" time="0.367" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_unbiased_cpu_float32" time="0.185" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_unbiased_cpu_complex64" time="0.679" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_unbiased_cpu_float32" time="0.371" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stft_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped! stft does not match the native function">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped! stft does not match the native function</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stft_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped! stft does not match the native function">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped! stft does not match the native function</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sub_cpu_complex64" time="3.917" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sub_cpu_float32" time="2.104" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_cpu_complex64" time="6.484" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_cpu_float32" time="3.316" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_to_size_cpu_complex64" time="2.548" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_to_size_cpu_float32" time="0.866" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_svd_cpu_complex64" time="82.237" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_svd_cpu_float32" time="40.269" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_svd_lowrank_cpu_float32" time="0.014" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_t_cpu_complex64" time="0.923" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_t_cpu_float32" time="0.459" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_along_dim_cpu_complex64" time="1.624" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_along_dim_cpu_float32" time="0.788" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_cpu_complex64" time="3.044" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_cpu_float32" time="1.491" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tan_cpu_complex64" time="0.335" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tan_cpu_float32" time="0.178" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tanh_cpu_complex64" time="0.347" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tanh_cpu_float32" time="0.172" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensor_split_cpu_complex64" time="3.921" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensor_split_cpu_float32" time="1.874" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensordot_cpu_complex64" time="0.502" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensordot_cpu_float32" time="0.245" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tile_cpu_complex64" time="9.044" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tile_cpu_float32" time="4.477" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_sparse_cpu_complex64" time="0.148" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_sparse_cpu_float32" time="0.244" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_topk_cpu_float32" time="2.459" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trace_cpu_complex64" time="0.315" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trace_cpu_float32" time="0.164" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_transpose_cpu_complex64" time="2.582" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_transpose_cpu_float32" time="1.318" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapezoid_cpu_complex64" time="1.579" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapezoid_cpu_float32" time="0.766" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapz_cpu_complex64" time="1.552" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapz_cpu_float32" time="0.769" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triangular_solve_cpu_complex64" time="5.126" file="test_ops_jit.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_jit.py:160: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.
torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.
X = torch.triangular_solve(B, A).solution
should be replaced with
X = torch.linalg.solve_triangular(A, B). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2197.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triangular_solve_cpu_float32" time="2.514" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tril_cpu_complex64" time="3.803" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tril_cpu_float32" time="1.792" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triu_cpu_complex64" time="3.882" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triu_cpu_float32" time="1.803" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_true_divide_cpu_complex64" time="3.252" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_true_divide_cpu_float32" time="1.666" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trunc_cpu_float32" time="0.171" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unbind_cpu_complex64" time="2.467" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unbind_cpu_float32" time="1.175" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unflatten_cpu_complex64" time="3.369" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unflatten_cpu_float32" time="1.679" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_copy_cpu_complex64" time="3.673" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_copy_cpu_float32" time="1.800" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_cpu_complex64" time="3.682" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_cpu_float32" time="1.802" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_uniform_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_uniform_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unique_consecutive_cpu_float32" time="0.054" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unique_cpu_float32" time="0.046" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsafe_split_cpu_complex64" time="0.717" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsafe_split_cpu_float32" time="0.361" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsqueeze_cpu_complex64" time="2.811" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsqueeze_cpu_float32" time="1.425" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_cpu_complex64" time="3.613" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_cpu_float32" time="1.818" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_cpu_complex64" time="1.926" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_cpu_float32" time="0.948" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_unbiased_cpu_complex64" time="0.386" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_unbiased_cpu_float32" time="0.180" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_unbiased_cpu_complex64" time="0.714" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_unbiased_cpu_float32" time="0.345" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vdot_cpu_complex64" time="0.685" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vdot_cpu_float32" time="0.169" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_complex_cpu_float32" time="0.085" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_cpu_complex64" time="0.659" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_cpu_float32" time="0.317" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_real_cpu_complex64" time="0.158" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_copy_cpu_float32" time="0.611" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_cpu_complex64" time="1.188" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_cpu_float32" time="0.630" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vsplit_cpu_complex64" time="0.797" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vsplit_cpu_float32" time="0.404" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vstack_cpu_complex64" time="0.352" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vstack_cpu_float32" time="0.185" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_where_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_where_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_xlogy_cpu_float32" time="1.492" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zero__cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zero__cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_like_cpu_complex64" time="0.357" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_like_cpu_float32" time="0.214" file="test_ops_jit.py" />
  </testsuite>
</testsuites>