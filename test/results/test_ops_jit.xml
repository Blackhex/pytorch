<testsuites>
  <testsuite name="pytest" errors="0" failures="5" skipped="399" tests="1078" time="1938.089" timestamp="2023-03-27T15:11:45.141039" hostname="BartonTest">
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_abs_cpu_float32" time="0.453" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_acos_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_acosh_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_asin_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_asinh_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_atan2_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_atan_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_atanh_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_cat_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_clamp_cpu_float32" time="0.062" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_digamma_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_div_floor_rounding_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_div_no_rounding_mode_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_div_trunc_rounding_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_erf_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_erfc_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_erfinv_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_exp2_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_expm1_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_ge_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_gt_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_i0_cpu_float32" time="0.002" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_igamma_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_igammac_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_le_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_lgamma_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_det_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_det_singular_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_householder_product_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_inv_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_linalg_matrix_power_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_log1p_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_log_softmax_cpu_float32" time="0.010" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_log_softmax_with_dtype_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_logit_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_logsumexp_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_lt_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mH_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_matmul_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_matrix_exp_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_max_binary_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_min_binary_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_movedim_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mul_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mvlgamma_mvlgamma_p_1_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mvlgamma_mvlgamma_p_3_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_mvlgamma_mvlgamma_p_5_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_ne_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_neg_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv1d_cpu_float32" time="0.010" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv2d_cpu_float32" time="0.015" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv_transpose1d_cpu_float32" time="0.010" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv_transpose2d_cpu_float32" time="0.014" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_conv_transpose3d_cpu_float32" time="0.029" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_group_norm_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_nn_functional_layer_norm_cpu_float32" time="0.009" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_outer_cpu_float32" time="0.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_decimals_0_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_decimals_3_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_round_decimals_neg_3_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:193: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_sigmoid_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_sinc_cpu_float32" time="0.004" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_softmax_cpu_float32" time="0.011" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_softmax_with_dtype_cpu_float32" time="0.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_sub_cpu_float32" time="0.009" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_tanh_cpu_float32" time="0.005" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_transpose_cpu_float32" time="0.015" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_trunc_cpu_float32" time="0.006" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_vstack_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_jit_alias_remapping_xlogy_cpu_float32" time="0.003" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_H_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_H_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_T_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_T_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___getitem___cpu_complex64" time="3.647" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___getitem___cpu_float32" time="2.048" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___radd___cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___radd___cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rdiv___cpu_complex64" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rdiv___cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmatmul___cpu_complex64" time="0.006" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmatmul___cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmod___cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmul___cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rmul___cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rpow___cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>c:\users\radekbarton\projects\pytorch\torch\_tensor.py:878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rpow___cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rsub___cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit___rsub___cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__native_batch_norm_legit_cpu_float32" time="0.152" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__segment_reduce_lengths_cpu_float32" time="5.360" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__segment_reduce_offsets_cpu_float32" time="5.333" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__softmax_backward_data_cpu_float32" time="0.079" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit__upsample_bilinear2d_aa_cpu_float32" time="0.020" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_abs_cpu_complex64" time="0.306" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_abs_cpu_float32" time="0.153" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acos_cpu_complex64" time="0.916" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acos_cpu_float32" time="0.448" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acosh_cpu_complex64" time="0.852" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_acosh_cpu_float32" time="0.441" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_add_cpu_complex64" time="3.759" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_add_cpu_float32" time="1.902" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addbmm_cpu_complex64" time="8.119" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addbmm_cpu_float32" time="1.887" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcdiv_cpu_complex64" time="4.036" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcdiv_cpu_float32" time="1.927" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcmul_cpu_complex64" time="4.442" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addcmul_cpu_float32" time="2.360" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_cpu_complex64" time="0.052" file="test_ops_jit.py">
      <failure message="Exception: &#10;                 Error testing addmm function variant&#10;                 with dtype: torch.complex64&#10;                 with inputs SampleInput(input=tensor([[-4.9425-0.9272j,  1.1837-2.4633j,  8.4951-4.1119j],&#10; [ 2.7945-6.1066j, -1.0653-2.3877j, 3.8831+6.2869j]],&#10;requires_grad=True), args=(tensor([[ 2.1889-0.8172j, -2.3046+7.0563j],&#10; [-2.1266+6.4973j, -4.0044+7.4175j]], requires_grad=True), tensor([[ 8.9640+6.1694j,  5.1619+3.3498j, -4.4253+0.1074j],&#10; [ 3.0990-2.3517j,  1.6134+5.2711j, -8.3388-8.1918j]],&#10;requires_grad=True)), kwargs={'alpha': (2+3j), 'beta': (1+2j)}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1A1CBD9E0&gt;, broadcasts_input=False, name=''):">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 85, in test_variant_consistency_jit
    self.indiv_variant_test_jit(device, dtype, op, sample, func_type, variant, has_fake_function)
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 120, in indiv_variant_test_jit
    check_against_reference(self,
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 135, in check_against_reference
    self.assertEqual(grads, grads_test)
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_utils.py", line 3011, in assertEqual
    raise error_metas[0].to_error(
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 3.876239415382761 at index (0, 1) (up to 1e-05 allowed)
Greatest relative difference: 0.20065710536786482 at index (0, 1) (up to 1.3e-06 allowed)

The failure occurred for item [1]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 92, in test_variant_consistency_jit
    raise Exception(variant_error_info) from e
Exception: 
                 Error testing addmm function variant
                 with dtype: torch.complex64
                 with inputs SampleInput(input=tensor([[-4.9425-0.9272j,  1.1837-2.4633j,  8.4951-4.1119j],
 [ 2.7945-6.1066j, -1.0653-2.3877j, 3.8831+6.2869j]], requires_grad=True), args=(tensor([[ 2.1889-0.8172j, -2.3046+7.0563j],
 [-2.1266+6.4973j, -4.0044+7.4175j]], requires_grad=True), tensor([[ 8.9640+6.1694j,  5.1619+3.3498j, -4.4253+0.1074j],
 [ 3.0990-2.3517j,  1.6134+5.2711j, -8.3388-8.1918j]], requires_grad=True)), kwargs={'alpha': (2+3j), 'beta': (1+2j)}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1A1CBD9E0&gt;, broadcasts_input=False, name=''):</failure>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_cpu_float32" time="0.585" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_decomposed_cpu_complex64" time="0.038" file="test_ops_jit.py">
      <failure message="Exception: &#10;                 Error testing addmm function variant&#10;                 with dtype: torch.complex64&#10;                 with inputs SampleInput(input=tensor([[-4.9425-0.9272j,  1.1837-2.4633j,  8.4951-4.1119j],&#10; [ 2.7945-6.1066j, -1.0653-2.3877j, 3.8831+6.2869j]],&#10;requires_grad=True), args=(tensor([[ 2.1889-0.8172j, -2.3046+7.0563j],&#10; [-2.1266+6.4973j, -4.0044+7.4175j]], requires_grad=True), tensor([[ 8.9640+6.1694j,  5.1619+3.3498j, -4.4253+0.1074j],&#10; [ 3.0990-2.3517j,  1.6134+5.2711j, -8.3388-8.1918j]],&#10;requires_grad=True)), kwargs={'alpha': 1, 'beta': 1}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1A1D18540&gt;, broadcasts_input=False, name=''):">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 85, in test_variant_consistency_jit
    self.indiv_variant_test_jit(device, dtype, op, sample, func_type, variant, has_fake_function)
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 120, in indiv_variant_test_jit
    check_against_reference(self,
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 112, in check_against_reference
    self.assertEqual(grads, grads_test)
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_utils.py", line 3011, in assertEqual
    raise error_metas[0].to_error(
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.0750754122505024 at index (0, 1) (up to 1e-05 allowed)
Greatest relative difference: 0.23876459465520525 at index (0, 1) (up to 1.3e-06 allowed)

The failure occurred for item [1]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 92, in test_variant_consistency_jit
    raise Exception(variant_error_info) from e
Exception: 
                 Error testing addmm function variant
                 with dtype: torch.complex64
                 with inputs SampleInput(input=tensor([[-4.9425-0.9272j,  1.1837-2.4633j,  8.4951-4.1119j],
 [ 2.7945-6.1066j, -1.0653-2.3877j, 3.8831+6.2869j]], requires_grad=True), args=(tensor([[ 2.1889-0.8172j, -2.3046+7.0563j],
 [-2.1266+6.4973j, -4.0044+7.4175j]], requires_grad=True), tensor([[ 8.9640+6.1694j,  5.1619+3.3498j, -4.4253+0.1074j],
 [ 3.0990-2.3517j,  1.6134+5.2711j, -8.3388-8.1918j]], requires_grad=True)), kwargs={'alpha': 1, 'beta': 1}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1A1D18540&gt;, broadcasts_input=False, name=''):</failure>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmm_decomposed_cpu_float32" time="0.597" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmv_cpu_complex64" time="2.017" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addmv_cpu_float32" time="0.978" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addr_cpu_complex64" time="1.357" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_addr_cpu_float32" time="0.647" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_all_cpu_complex64" time="1.216" file="test_ops_jit.py">
      <system-err>c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py:160: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Copy.cpp:276.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_all_cpu_float32" time="0.596" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_allclose_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_allclose_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_amax_cpu_float32" time="3.048" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_amin_cpu_float32" time="3.059" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_aminmax_cpu_float32" time="0.376" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_angle_cpu_complex64" time="0.294" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_angle_cpu_float32" time="0.140" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_any_cpu_complex64" time="1.140" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_any_cpu_float32" time="0.594" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_arange_cpu_float32" time="0.027" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argmax_cpu_float32" time="0.642" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argmin_cpu_float32" time="0.591" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argsort_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argwhere_cpu_complex64" time="0.525" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_argwhere_cpu_float32" time="0.292" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_cpu_complex64" time="1.738" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_cpu_float32" time="0.849" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_partial_views_cpu_complex64" time="0.344" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_partial_views_cpu_float32" time="0.334" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_scatter_cpu_complex64" time="2.523" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_as_strided_scatter_cpu_float32" time="1.240" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asin_cpu_complex64" time="0.334" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asin_cpu_float32" time="0.157" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asinh_cpu_complex64" time="0.312" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_asinh_cpu_float32" time="0.142" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atan2_cpu_float32" time="1.430" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atan_cpu_complex64" time="0.315" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atan_cpu_float32" time="0.155" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atanh_cpu_complex64" time="0.297" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atanh_cpu_float32" time="0.143" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_1d_cpu_complex64" time="0.923" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_1d_cpu_float32" time="0.081" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_2d_cpu_complex64" time="0.927" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_2d_cpu_float32" time="0.083" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_3d_cpu_complex64" time="0.921" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_atleast_3d_cpu_float32" time="0.082" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_baddbmm_cpu_complex64" time="8.836" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_baddbmm_cpu_float32" time="1.953" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bernoulli_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bfloat16_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bfloat16_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_block_diag_cpu_complex64" time="1.344" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_block_diag_cpu_float32" time="0.085" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bmm_cpu_complex64" time="0.462" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bmm_cpu_float32" time="0.382" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bool_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bool_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_shapes_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_tensors_cpu_complex64" time="0.237" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_tensors_cpu_float32" time="0.104" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_to_cpu_complex64" time="2.193" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_broadcast_to_cpu_float32" time="1.085" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_bucketize_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected failure!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected failure!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_byte_cpu_complex64" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_byte_cpu_float32" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cartesian_prod_cpu_complex64" time="0.483" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cartesian_prod_cpu_float32" time="0.073" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cat_cpu_complex64" time="1.575" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cat_cpu_float32" time="0.962" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cauchy_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cdist_cpu_float32" time="16.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cdouble_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cdouble_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ceil_cpu_float32" time="0.149" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cfloat_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cfloat_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chalf_cpu_complex64" time="0.018" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_methods_invocations.py:15319: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\EmptyTensor.cpp:32.) op=lambda x, *args, **kwargs: x.chalf(*args, **kwargs),
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chalf_cpu_float32" time="0.012" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_char_cpu_complex64" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_char_cpu_float32" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_inverse_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_inverse_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_solve_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cholesky_solve_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chunk_cpu_complex64" time="1.161" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_chunk_cpu_float32" time="0.550" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clamp_cpu_float32" time="0.843" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clamp_max_cpu_float32" time="1.306" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clamp_min_cpu_float32" time="1.317" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clone_cpu_complex64" time="0.573" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_clone_cpu_float32" time="0.279" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_column_stack_cpu_complex64" time="0.474" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_column_stack_cpu_float32" time="0.230" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_combinations_cpu_complex64" time="2.959" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_combinations_cpu_float32" time="1.450" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_complex_cpu_float32" time="0.680" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_cpu_complex64" time="0.851" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_cpu_float32" time="0.374" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_physical_cpu_complex64" time="0.285" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_conj_physical_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_constant_pad_nd_cpu_complex64" time="8.210" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_constant_pad_nd_cpu_float32" time="3.979" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_contiguous_cpu_complex64" time="0.294" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_contiguous_cpu_float32" time="0.142" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_copysign_cpu_float32" time="1.326" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_corrcoef_cpu_complex64" time="1.205" file="test_ops_jit.py">
      <failure message="Exception: &#10;                 Error testing corrcoef function variant&#10;                 with dtype: torch.complex64&#10;                 with inputs SampleInput(input=tensor([[ 1.8220-3.5221j, -4.4145+2.3285j,  8.3972+4.3191j],&#10; [-0.8691-0.4368j,  5.1155-6.2551j, 2.9920-2.9822j]],&#10;requires_grad=True), args=(), kwargs={}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1B85A6840&gt;, broadcasts_input=False, name=''):">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 85, in test_variant_consistency_jit
    self.indiv_variant_test_jit(device, dtype, op, sample, func_type, variant, has_fake_function)
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 120, in indiv_variant_test_jit
    check_against_reference(self,
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 91, in check_against_reference
    outputs_test = self.runAndSaveRNG(func, nograd_inputs, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 160, in runAndSaveRNG
    results = func(*inputs, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\jit_metaprogramming_utils.py", line 404, in script_fn
    self.assertExportImport(fn.graph, tensors)
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 148, in assertExportImport
    self.assertExportImportModule(m, inputs)
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 154, in assertExportImportModule
    self.assertEqual(a, b, "Results of original model and "
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_utils.py", line 3011, in assertEqual
    raise error_metas[0].to_error(
AssertionError: Tensor-likes are not close!

Mismatched elements: 3 / 4 (75.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)
Results of original model and exported/imported version of model differed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 92, in test_variant_consistency_jit
    raise Exception(variant_error_info) from e
Exception: 
                 Error testing corrcoef function variant
                 with dtype: torch.complex64
                 with inputs SampleInput(input=tensor([[ 1.8220-3.5221j, -4.4145+2.3285j,  8.3972+4.3191j],
 [-0.8691-0.4368j,  5.1155-6.2551j, 2.9920-2.9822j]], requires_grad=True), args=(), kwargs={}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1B85A6840&gt;, broadcasts_input=False, name=''):</failure>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_corrcoef_cpu_float32" time="0.631" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cos_cpu_complex64" time="0.899" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cos_cpu_float32" time="0.443" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cosh_cpu_complex64" time="0.899" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cosh_cpu_float32" time="0.446" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_count_nonzero_cpu_complex64" time="1.784" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_count_nonzero_cpu_float32" time="0.932" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cov_cpu_complex64" time="0.351" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cov_cpu_float32" time="0.330" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cross_cpu_complex64" time="0.938" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cross_cpu_float32" time="0.458" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cummax_cpu_float32" time="0.462" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cummin_cpu_float32" time="0.468" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumprod_cpu_complex64" time="4.575" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumprod_cpu_float32" time="2.026" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumsum_cpu_complex64" time="1.223" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumsum_cpu_float32" time="0.590" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumulative_trapezoid_cpu_complex64" time="1.460" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_cumulative_trapezoid_cpu_float32" time="0.711" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_deg2rad_cpu_float32" time="0.141" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_cpu_complex64" time="4.695" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_cpu_float32" time="2.282" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_embed_cpu_complex64" time="4.597" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diag_embed_cpu_float32" time="2.256" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagflat_cpu_complex64" time="1.468" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagflat_cpu_float32" time="0.708" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_copy_cpu_complex64" time="2.275" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_copy_cpu_float32" time="1.116" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_cpu_complex64" time="4.533" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_cpu_float32" time="2.215" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_scatter_cpu_complex64" time="4.848" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diagonal_scatter_cpu_float32" time="2.344" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diff_cpu_complex64" time="21.760" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_diff_cpu_float32" time="10.499" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_digamma_cpu_float32" time="0.408" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dist_cpu_complex64" time="16.457" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dist_cpu_float32" time="7.937" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_floor_rounding_cpu_float32" time="1.557" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_no_rounding_mode_cpu_complex64" time="3.090" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_no_rounding_mode_cpu_float32" time="1.558" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_div_trunc_rounding_cpu_float32" time="1.549" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dot_cpu_complex64" time="0.645" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dot_cpu_float32" time="0.156" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_double_cpu_complex64" time="0.077" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_double_cpu_float32" time="0.077" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dsplit_cpu_complex64" time="0.744" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dsplit_cpu_float32" time="0.349" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dstack_cpu_complex64" time="0.336" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_dstack_cpu_float32" time="0.157" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_einsum_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_einsum_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_like_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_like_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_permuted_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_empty_permuted_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eq_cpu_complex64" time="0.869" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eq_cpu_float32" time="0.525" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_equal_cpu_complex64" time="0.311" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_equal_cpu_float32" time="0.165" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_erf_cpu_float32" time="0.158" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_erfc_cpu_float32" time="0.449" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_erfinv_cpu_float32" time="0.146" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp2_cpu_complex64" time="0.844" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp2_cpu_float32" time="0.418" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp_cpu_complex64" time="0.902" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exp_cpu_float32" time="0.445" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_as_cpu_complex64" time="0.443" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_as_cpu_float32" time="0.221" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_cpu_complex64" time="1.447" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expand_cpu_float32" time="0.750" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_expm1_cpu_float32" time="0.155" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_exponential_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eye_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_eye_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft2_cpu_complex64" time="1.017" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft2_cpu_float32" time="0.525" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft_cpu_complex64" time="1.079" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fft_cpu_float32" time="0.548" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftn_cpu_complex64" time="1.278" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftn_cpu_float32" time="0.654" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftshift_cpu_complex64" time="0.770" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_fftshift_cpu_float32" time="0.376" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft2_cpu_complex64" time="1.000" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft2_cpu_float32" time="0.513" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft_cpu_complex64" time="1.065" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfft_cpu_float32" time="0.546" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfftn_cpu_complex64" time="1.263" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_hfftn_cpu_float32" time="0.642" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft2_cpu_complex64" time="1.008" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft2_cpu_float32" time="0.515" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft_cpu_complex64" time="1.071" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifft_cpu_float32" time="0.555" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftn_cpu_complex64" time="1.300" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftn_cpu_float32" time="0.657" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftshift_cpu_complex64" time="0.774" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ifftshift_cpu_float32" time="0.377" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ihfft2_cpu_float32" time="0.519" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ihfft_cpu_float32" time="0.551" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_ihfftn_cpu_float32" time="0.651" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft2_cpu_complex64" time="0.996" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft2_cpu_float32" time="0.511" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft_cpu_complex64" time="1.056" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfft_cpu_float32" time="0.536" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfftn_cpu_complex64" time="1.241" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_irfftn_cpu_float32" time="0.635" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_rfft2_cpu_float32" time="0.509" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_rfft_cpu_float32" time="0.553" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fft_rfftn_cpu_float32" time="0.649" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fill_cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fill_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flatten_cpu_complex64" time="1.770" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flatten_cpu_float32" time="0.899" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flip_cpu_complex64" time="3.044" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flip_cpu_float32" time="1.485" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fliplr_cpu_complex64" time="0.567" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fliplr_cpu_float32" time="0.281" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flipud_cpu_complex64" time="0.558" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_flipud_cpu_float32" time="0.273" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_cpu_complex64" time="0.080" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_cpu_float32" time="0.079" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_power_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_float_power_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_floor_cpu_float32" time="0.150" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_floor_divide_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fmax_cpu_float32" time="1.306" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fmin_cpu_float32" time="1.305" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_fmod_cpu_float32" time="1.423" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_frac_cpu_float32" time="0.150" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_frexp_cpu_float32" time="0.451" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_like_cpu_complex64" time="0.372" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_full_like_cpu_float32" time="0.186" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gather_cpu_complex64" time="1.529" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gather_cpu_float32" time="0.743" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ge_cpu_float32" time="0.467" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_geometric_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_geqrf_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_geqrf_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gradient_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gradient_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_grid_sampler_2d_cpu_float32" time="0.969" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_gt_cpu_float32" time="0.466" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_half_cpu_complex64" time="0.076" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_half_cpu_float32" time="0.079" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_heaviside_cpu_float32" time="0.410" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_histc_cpu_float32" time="4.739" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_histogram_cpu_float32" time="0.677" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_histogramdd_cpu_float32" time="0.221" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hsplit_cpu_complex64" time="0.761" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hsplit_cpu_float32" time="0.356" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hstack_cpu_complex64" time="0.324" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hstack_cpu_float32" time="0.159" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_hypot_cpu_float32" time="1.321" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_i0_cpu_float32" time="0.413" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_igamma_cpu_float32" time="0.413" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_igammac_cpu_float32" time="0.412" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_imag_cpu_complex64" time="0.413" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_add_cpu_complex64" time="2.937" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_add_cpu_float32" time="1.435" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_copy_cpu_complex64" time="0.956" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_copy_cpu_float32" time="0.466" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_fill_cpu_complex64" time="1.918" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_fill_cpu_float32" time="0.948" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_put_cpu_complex64" time="1.377" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_put_cpu_float32" time="0.658" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_reduce_cpu_float32" time="5.579" file="test_ops_jit.py">
      <system-err>c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py:160: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\TensorAdvancedIndexing.cpp:1110.)
  results = func(*inputs, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_select_cpu_complex64" time="0.912" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_index_select_cpu_float32" time="0.454" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_inner_cpu_complex64" time="0.610" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_inner_cpu_float32" time="0.292" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_int_cpu_complex64" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_int_cpu_float32" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isclose_cpu_complex64" time="1.707" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isclose_cpu_float32" time="0.866" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isfinite_cpu_complex64" time="0.266" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isfinite_cpu_float32" time="0.133" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isin_cpu_float32" time="0.048" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isinf_cpu_complex64" time="0.087" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isinf_cpu_float32" time="0.045" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isnan_cpu_complex64" time="0.085" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isnan_cpu_float32" time="0.048" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isneginf_cpu_float32" time="0.044" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isposinf_cpu_float32" time="0.045" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isreal_cpu_complex64" time="0.256" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_isreal_cpu_float32" time="0.128" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_istft_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped! istft does not match the native function">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped! istft does not match the native function</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_2inputs_2outputs_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_2inputs_2outputs_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_4inputs_with_extra_args_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_4inputs_with_extra_args_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_return_by_ref_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_binary_return_by_ref_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_unary_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_jiterator_unary_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_kron_cpu_complex64" time="0.343" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_kron_cpu_float32" time="0.160" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_kthvalue_cpu_float32" time="1.641" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ldexp_cpu_complex64" time="2.788" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ldexp_cpu_float32" time="1.333" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_le_cpu_float32" time="0.472" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lerp_cpu_complex64" time="7.720" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lerp_cpu_float32" time="2.569" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lgamma_cpu_float32" time="0.423" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_ex_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cholesky_ex_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cond_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cond_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cross_cpu_complex64" time="0.472" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_cross_cpu_float32" time="0.228" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_singular_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_det_singular_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_diagonal_cpu_complex64" time="2.294" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_diagonal_cpu_float32" time="1.139" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eig_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eig_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigh_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigh_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvals_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvals_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvalsh_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_eigvalsh_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_householder_product_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_householder_product_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_ex_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_inv_ex_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_ex_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_factor_ex_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_solve_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_ldl_solve_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_grad_oriented_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lstsq_grad_oriented_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_factor_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_factor_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_factor_ex_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_factor_ex_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_solve_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_lu_solve_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_norm_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_norm_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_power_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_power_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_hermitian_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_matrix_rank_hermitian_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_multi_dot_cpu_complex64" time="0.359" file="test_ops_jit.py">
      <failure message="Exception: &#10;                 Error testing linalg.multi_dot function variant&#10;                 with dtype: torch.complex64&#10;                 with inputs SampleInput(input=[tensor([[ 3.6408+0.7134j, -3.3414-0.7059j,  8.4709+2.7034j],&#10; [-7.4305+5.7355j,  1.9338+4.4273j, 0.0378+3.5795j]],&#10;requires_grad=True), tensor([[ 2.6902+7.9021j,  4.7497-3.9386j,  4.7164-0.5338j,  5.9508-3.1580j],&#10; [-2.6416+8.3227j,  1.5858+1.2618j,  0.9229+0.5867j,  0.3787-7.8208j],&#10; [ 8.6875+8.5922j, -6.1958+2.2255j,  7.4394+1.7428j, 3.8713+6.7031j]],&#10;requires_grad=True), tensor([[ 3.8203-1.6268j, -7.4816-4.2444j, -5.3582+0.1821j, -6.3726+5.7149j,&#10;   1.7728-3.8982j],&#10; [-5.2152+2.9482j, -2.1544+1.7195j,  0.8456+1.1195j, -1.2455-1.7637j,&#10;  -2.1104+3.4704j],&#10; [-5.8023+0.2109j, -3.6571-8.5529j,  2.5326+2.7732j,  8.0087+5.9134j,&#10;   8.8088-7.0723j],&#10; [-7.8340+2.7992j,  4.4108+3.9650j, -5.9266+7.0432j, -7.8230+2.3983j,&#10;  -3.4459-3.2389j]], requires_grad=True)], args=(), kwargs={}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1C44DC220&gt;, broadcasts_input=False, name=''):">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 85, in test_variant_consistency_jit
    self.indiv_variant_test_jit(device, dtype, op, sample, func_type, variant, has_fake_function)
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 120, in indiv_variant_test_jit
    check_against_reference(self,
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 112, in check_against_reference
    self.assertEqual(grads, grads_test)
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_utils.py", line 3011, in assertEqual
    raise error_metas[0].to_error(
AssertionError: Tensor-likes are not close!

Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: 2.754203250666013e+31 at index (0, 2) (up to 1e-05 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 92, in test_variant_consistency_jit
    raise Exception(variant_error_info) from e
Exception: 
                 Error testing linalg.multi_dot function variant
                 with dtype: torch.complex64
                 with inputs SampleInput(input=[tensor([[ 3.6408+0.7134j, -3.3414-0.7059j,  8.4709+2.7034j],
 [-7.4305+5.7355j,  1.9338+4.4273j, 0.0378+3.5795j]], requires_grad=True), tensor([[ 2.6902+7.9021j,  4.7497-3.9386j,  4.7164-0.5338j,  5.9508-3.1580j],
 [-2.6416+8.3227j,  1.5858+1.2618j,  0.9229+0.5867j,  0.3787-7.8208j],
 [ 8.6875+8.5922j, -6.1958+2.2255j,  7.4394+1.7428j, 3.8713+6.7031j]], requires_grad=True), tensor([[ 3.8203-1.6268j, -7.4816-4.2444j, -5.3582+0.1821j, -6.3726+5.7149j,
   1.7728-3.8982j],
 [-5.2152+2.9482j, -2.1544+1.7195j,  0.8456+1.1195j, -1.2455-1.7637j,
  -2.1104+3.4704j],
 [-5.8023+0.2109j, -3.6571-8.5529j,  2.5326+2.7732j,  8.0087+5.9134j,
   8.8088-7.0723j],
 [-7.8340+2.7992j,  4.4108+3.9650j, -5.9266+7.0432j, -7.8230+2.3983j,
  -3.4459-3.2389j]], requires_grad=True)], args=(), kwargs={}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1C44DC220&gt;, broadcasts_input=False, name=''):</failure>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_multi_dot_cpu_float32" time="0.562" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_subgradients_at_zero_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_norm_subgradients_at_zero_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_hermitian_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_hermitian_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_singular_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_pinv_singular_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_qr_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_qr_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_slogdet_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_slogdet_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_ex_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_ex_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_triangular_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_solve_triangular_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svd_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svd_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svdvals_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_svdvals_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_tensorinv_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_tensorinv_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_tensorsolve_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_tensorsolve_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vander_cpu_complex64" time="1.579" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vander_cpu_float32" time="0.761" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vecdot_cpu_complex64" time="7.009" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vecdot_cpu_float32" time="3.342" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vector_norm_cpu_complex64" time="29.289" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linalg_vector_norm_cpu_float32" time="14.632" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linspace_cpu_complex64" time="2.362" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_linspace_cpu_float32" time="0.028" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log10_cpu_complex64" time="0.905" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log10_cpu_float32" time="0.449" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log1p_cpu_complex64" time="0.314" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log1p_cpu_float32" time="0.154" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log2_cpu_complex64" time="0.901" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log2_cpu_float32" time="0.451" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_cpu_complex64" time="0.895" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_cpu_float32" time="0.443" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_normal_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_softmax_cpu_float32" time="1.103" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_softmax_with_dtype_cpu_complex64" time="2.258" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_log_softmax_with_dtype_cpu_float32" time="1.141" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logaddexp2_cpu_float32" time="0.150" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logaddexp_cpu_complex64" time="2.832" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logaddexp_cpu_float32" time="1.351" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logcumsumexp_cpu_complex64" time="1.827" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logcumsumexp_cpu_float32" time="0.917" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logdet_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logdet_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_and_cpu_complex64" time="0.778" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_and_cpu_float32" time="0.401" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_not_cpu_complex64" time="0.252" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_not_cpu_float32" time="0.128" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_or_cpu_complex64" time="0.786" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_or_cpu_float32" time="0.400" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_xor_cpu_complex64" time="0.774" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logical_xor_cpu_float32" time="0.396" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logit_cpu_float32" time="0.579" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logspace_cpu_complex64" time="20.629" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logspace_cpu_float32" time="0.029" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_logsumexp_cpu_float32" time="2.555" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_long_cpu_complex64" time="0.027" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_long_cpu_float32" time="0.027" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lt_cpu_float32" time="0.488" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_solve_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_solve_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_unpack_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_lu_unpack_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mH_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mH_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mT_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mT_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_amax_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_amin_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_argmax_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_argmin_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumprod_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumprod_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumsum_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_cumsum_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_fill_cpu_complex64" time="2.454" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_fill_cpu_float32" time="1.188" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_log_softmax_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_logaddexp_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_logsumexp_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_mean_cpu_complex64" time="0.008" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_mean_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_median_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_norm_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_normalize_cpu_complex64" time="0.007" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_normalize_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_prod_cpu_complex64" time="0.008" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_prod_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_scatter_cpu_complex64" time="1.249" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_scatter_cpu_float32" time="0.601" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_select_cpu_complex64" time="2.064" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_select_cpu_float32" time="1.007" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_softmax_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_softmin_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_std_cpu_complex64" time="0.025" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_std_cpu_float32" time="0.006" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_sum_cpu_complex64" time="0.008" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_sum_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_var_cpu_complex64" time="0.025" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_masked_var_cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matmul_cpu_complex64" time="0.359" file="test_ops_jit.py">
      <failure message="Exception: &#10;                Error testing matmul function variant&#10;                with dtype: torch.complex64&#10;                with inputs SampleInput(input=tensor([-8.3811+7.2051j, -7.7278+0.6116j, -8.4311+4.8188j, -0.2134+1.5389j,&#10;-4.5560-6.3212j, -4.6871-0.5918j,  3.6625-1.2313j, -1.9316+7.0388j,&#10;-1.9966+2.7680j, -7.5393+8.0101j], requires_grad=True), args=(tensor([[-7.8917-7.3035j,  6.0631+0.2670j, -1.2554-1.8745j, -2.0470+6.4679j,&#10;  3.2009+7.6902j],&#10;[-3.1145-5.9596j, -3.8745-6.7242j, -3.9613+8.1251j,  2.1502+1.7057j,&#10;  2.9993-8.4838j],&#10;[-8.6372+5.1480j, -3.3136+1.5290j, -7.9086-7.1312j,  3.7545-3.8589j,&#10; -6.5927-6.8024j],&#10;[-3.1549-4.3197j,  5.9517-6.6309j,  0.0309-6.1396j, -4.6878-1.3596j,&#10; -4.2882+3.3702j],&#10;[ 3.4604+0.6415j, -0.4822+3.4434j,  0.9444-6.8274j,  2.6801-5.1808j,&#10; -7.0739+4.2569j],&#10;[ 1.4445-2.2530j,  1.3710-2.3009j, -2.5473+7.4365j,  3.6280-5.7715j,&#10; -1.7301+4.3677j],&#10;[-2.2939+3.6455j, -8.7164-8.0823j, -4.3153-0.7362j, -5.7958+2.4635j,&#10;  6.5844-6.8061j],&#10;[ 8.6955-3.4787j, -2.6102+0.6063j, -0.9598+1.2476j,  0.3500+2.4713j,&#10;  7.2352+5.3856j],&#10;[-4.7895+5.5493j, -6.7326+4.0494j, -3.0488+0.3794j, -5.7839+5.1257j,&#10; -0.4161-6.6119j],&#10;[ 5.7476-7.3656j, -3.0392+4.6523j,  4.0985+8.8402j,  6.2109+0.9307j,&#10; -0.2936-4.4911j]], requires_grad=True),), kwargs={}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1C4571580&gt;, broadcasts_input=False, name=''):">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 85, in test_variant_consistency_jit
    self.indiv_variant_test_jit(device, dtype, op, sample, func_type, variant, has_fake_function)
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 120, in indiv_variant_test_jit
    check_against_reference(self,
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_jit.py", line 112, in check_against_reference
    self.assertEqual(grads, grads_test)
  File "c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_utils.py", line 3011, in assertEqual
    raise error_metas[0].to_error(
AssertionError: Tensor-likes are not close!

Mismatched elements: 10 / 10 (100.0%)
Greatest absolute difference: 3.5442305548913385e+30 at index (6,) (up to 1e-05 allowed)
Greatest relative difference: 0.00921968939052082 at index (1,) (up to 1.3e-06 allowed)

The failure occurred for item [0]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py", line 92, in test_variant_consistency_jit
    raise Exception(variant_error_info) from e
Exception: 
                Error testing matmul function variant
                with dtype: torch.complex64
                with inputs SampleInput(input=tensor([-8.3811+7.2051j, -7.7278+0.6116j, -8.4311+4.8188j, -0.2134+1.5389j,
-4.5560-6.3212j, -4.6871-0.5918j,  3.6625-1.2313j, -1.9316+7.0388j,
-1.9966+2.7680j, -7.5393+8.0101j], requires_grad=True), args=(tensor([[-7.8917-7.3035j,  6.0631+0.2670j, -1.2554-1.8745j, -2.0470+6.4679j,
  3.2009+7.6902j],
[-3.1145-5.9596j, -3.8745-6.7242j, -3.9613+8.1251j,  2.1502+1.7057j,
  2.9993-8.4838j],
[-8.6372+5.1480j, -3.3136+1.5290j, -7.9086-7.1312j,  3.7545-3.8589j,
 -6.5927-6.8024j],
[-3.1549-4.3197j,  5.9517-6.6309j,  0.0309-6.1396j, -4.6878-1.3596j,
 -4.2882+3.3702j],
[ 3.4604+0.6415j, -0.4822+3.4434j,  0.9444-6.8274j,  2.6801-5.1808j,
 -7.0739+4.2569j],
[ 1.4445-2.2530j,  1.3710-2.3009j, -2.5473+7.4365j,  3.6280-5.7715j,
 -1.7301+4.3677j],
[-2.2939+3.6455j, -8.7164-8.0823j, -4.3153-0.7362j, -5.7958+2.4635j,
  6.5844-6.8061j],
[ 8.6955-3.4787j, -2.6102+0.6063j, -0.9598+1.2476j,  0.3500+2.4713j,
  7.2352+5.3856j],
[-4.7895+5.5493j, -6.7326+4.0494j, -3.0488+0.3794j, -5.7839+5.1257j,
 -0.4161-6.6119j],
[ 5.7476-7.3656j, -3.0392+4.6523j,  4.0985+8.8402j,  6.2109+0.9307j,
 -0.2936-4.4911j]], requires_grad=True),), kwargs={}, output_process_fn_grad=&lt;function SampleInput.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x000002C1C4571580&gt;, broadcasts_input=False, name=''):</failure>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matmul_cpu_float32" time="2.483" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matrix_exp_cpu_complex64" time="1.018" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_matrix_exp_cpu_float32" time="0.550" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_binary_cpu_float32" time="1.567" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_pool2d_with_indices_backward_cpu_float32" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_reduction_no_dim_cpu_float32" time="0.316" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_max_reduction_with_dim_cpu_float32" time="0.843" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_maximum_cpu_float32" time="1.327" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mean_cpu_complex64" time="6.753" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mean_cpu_float32" time="3.498" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_median_cpu_float32" time="1.985" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_list_of_tensors_cpu_complex64" time="1.835" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_list_of_tensors_cpu_float32" time="0.891" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_variadic_tensors_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_meshgrid_variadic_tensors_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_min_binary_cpu_float32" time="1.510" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_min_reduction_no_dim_cpu_float32" time="0.278" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_min_reduction_with_dim_cpu_float32" time="0.794" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_minimum_cpu_float32" time="1.325" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mm_cpu_complex64" time="0.660" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mm_cpu_float32" time="0.163" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mode_cpu_float32" time="1.296" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_movedim_cpu_complex64" time="0.715" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_movedim_cpu_float32" time="0.420" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_msort_cpu_float32" time="0.370" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mul_cpu_complex64" time="3.028" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mul_cpu_float32" time="1.572" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_multinomial_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mv_cpu_complex64" time="0.324" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mv_cpu_float32" time="0.159" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mvlgamma_mvlgamma_p_1_cpu_float32" time="1.497" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mvlgamma_mvlgamma_p_3_cpu_float32" time="1.491" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_mvlgamma_mvlgamma_p_5_cpu_float32" time="1.495" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nan_to_num_cpu_float32" time="0.419" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nanmean_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nanmedian_cpu_float32" time="2.000" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nanquantile_cpu_float32" time="10.683" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nansum_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_copy_cpu_complex64" time="0.480" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_copy_cpu_float32" time="0.244" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_cpu_complex64" time="3.131" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_narrow_cpu_float32" time="1.531" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_native_batch_norm_cpu_float32" time="0.160" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_native_dropout_backward_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_native_layer_norm_cpu_float32" time="0.179" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ne_cpu_complex64" time="0.796" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ne_cpu_float32" time="0.467" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_neg_cpu_complex64" time="0.306" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_neg_cpu_float32" time="0.148" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_strided_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected: new_empty_strided is not comparable">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected: new_empty_strided is not comparable</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_empty_strided_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected: new_empty_strided is not comparable">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected: new_empty_strided is not comparable</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_full_cpu_complex64" time="0.393" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_full_cpu_float32" time="0.201" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_ones_cpu_complex64" time="0.377" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_ones_cpu_float32" time="0.195" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_zeros_cpu_complex64" time="0.382" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_new_zeros_cpu_float32" time="0.194" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nextafter_cpu_float32" time="0.408" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_avg_pool1d_cpu_float32" time="0.572" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_avg_pool2d_cpu_float32" time="0.366" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_avg_pool3d_cpu_float32" time="0.259" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_max_pool1d_cpu_float32" time="1.421" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_max_pool2d_cpu_float32" time="0.784" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_adaptive_max_pool3d_cpu_float32" time="0.012" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_alpha_dropout_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_avg_pool1d_cpu_float32" time="1.579" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_avg_pool2d_cpu_float32" time="1.298" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_avg_pool3d_cpu_float32" time="1.104" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_batch_norm_cpu_float32" time="2.549" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_bilinear_cpu_float32" time="2.312" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_binary_cross_entropy_cpu_float32" time="1.184" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_binary_cross_entropy_with_logits_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_celu_cpu_float32" time="0.235" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv1d_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv1d_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv2d_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Works on some configs!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Works on some configs!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv2d_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Works on some configs!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Works on some configs!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose1d_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose1d_cpu_float32" time="0.140" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose2d_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose2d_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose3d_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_conv_transpose3d_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_cosine_embedding_loss_cpu_float32" time="0.786" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_cosine_similarity_cpu_float32" time="0.777" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_cross_entropy_cpu_float32" time="3.548" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_ctc_loss_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_dropout2d_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_dropout3d_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_dropout_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_elu_cpu_float32" time="0.273" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_embedding_bag_cpu_float32" time="0.005" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_embedding_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_feature_alpha_dropout_with_train_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_feature_alpha_dropout_without_train_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_feature_alpha_dropout_without_train_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_fractional_max_pool2d_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_fractional_max_pool3d_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_gaussian_nll_loss_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_gelu_cpu_float32" time="0.658" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_glu_cpu_float32" time="3.784" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_grid_sample_cpu_float32" time="2.810" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_group_norm_cpu_float32" time="0.048" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardshrink_cpu_float32" time="0.489" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardsigmoid_cpu_float32" time="0.162" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardswish_cpu_float32" time="0.328" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hardtanh_cpu_float32" time="0.526" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_hinge_embedding_loss_cpu_float32" time="1.149" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_huber_loss_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_instance_norm_cpu_float32" time="0.049" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_area_cpu_float32" time="0.702" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_bicubic_cpu_float32" time="0.356" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_bilinear_cpu_float32" time="0.338" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_linear_cpu_float32" time="0.336" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_nearest_cpu_float32" time="0.334" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_interpolate_trilinear_cpu_float32" time="0.347" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_kl_div_cpu_float32" time="2.085" file="test_ops_jit.py">
      <system-err>c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
code/__torch__/torch/nn/functional.py:18: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:2924: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_l1_loss_cpu_complex64" time="2.048" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_l1_loss_cpu_float32" time="0.127" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_layer_norm_cpu_float32" time="0.786" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_leaky_relu_cpu_float32" time="0.763" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_linear_cpu_complex64" time="2.808" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_linear_cpu_float32" time="1.522" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_local_response_norm_cpu_float32" time="0.308" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_logsigmoid_cpu_float32" time="0.296" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_margin_ranking_loss_cpu_float32" time="3.168" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_pool1d_cpu_float32" time="168.103" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_pool2d_cpu_float32" time="318.533" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_pool3d_cpu_float32" time="118.831" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool1d_cpu_float32" time="46.547" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool1d_grad_cpu_float32" time="4.403" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool2d_cpu_float32" time="127.615" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool2d_grad_cpu_float32" time="11.744" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool3d_cpu_float32" time="71.596" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_max_unpool3d_grad_cpu_float32" time="8.450" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_mish_cpu_float32" time="0.519" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_mse_loss_cpu_float32" time="0.286" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_multi_margin_loss_cpu_float32" time="0.862" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_multilabel_margin_loss_cpu_float32" time="0.465" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_multilabel_soft_margin_loss_cpu_float32" time="2.548" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_nll_loss_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_normalize_cpu_complex64" time="3.778" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_normalize_cpu_float32" time="1.875" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_circular_cpu_complex64" time="2.360" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_circular_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_constant_cpu_complex64" time="11.450" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_constant_cpu_float32" time="4.563" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_reflect_cpu_complex64" time="2.651" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_reflect_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_replicate_cpu_complex64" time="2.722" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pad_replicate_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pairwise_distance_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pairwise_distance_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pdist_cpu_float32" time="0.437" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_shuffle_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_shuffle_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_unshuffle_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_pixel_unshuffle_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_poisson_nll_loss_cpu_float32" time="8.834" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_prelu_cpu_float32" time="0.016" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_relu6_cpu_float32" time="0.243" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_relu_cpu_float32" time="0.323" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_rrelu_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_scaled_dot_product_attention_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_selu_cpu_float32" time="0.226" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_silu_complex_cpu_complex64" time="0.143" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_silu_cpu_float32" time="0.240" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_smooth_l1_loss_cpu_float32" time="0.132" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_soft_margin_loss_cpu_float32" time="0.649" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softmin_cpu_float32" time="0.722" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softmin_with_dtype_cpu_complex64" time="1.420" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softmin_with_dtype_cpu_float32" time="0.738" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softplus_cpu_float32" time="0.245" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softshrink_cpu_float32" time="0.358" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softsign_cpu_complex64" time="0.606" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_softsign_cpu_float32" time="0.317" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_tanhshrink_cpu_complex64" time="0.535" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_tanhshrink_cpu_float32" time="0.273" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_threshold_cpu_float32" time="0.357" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_loss_cpu_complex64" time="1.808" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_loss_cpu_float32" time="0.924" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_with_distance_loss_cpu_complex64" time="0.012" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_triplet_margin_with_distance_loss_cpu_float32" time="0.007" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_unfold_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Internal assert failed!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Internal assert failed!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_unfold_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Internal assert failed!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Internal assert failed!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_upsample_bilinear_cpu_float32" time="0.346" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_32705.py:6: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_32705.py:6: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_32705.py:6: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4084: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nn_functional_upsample_nearest_cpu_float32" time="0.336" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_32711.py:6: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_32711.py:6: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
code/__torch__/torch/nn/functional/___torch_mangle_32711.py:6: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
c:\users\radekbarton\projects\pytorch\torch\nn\functional.py:4028: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nonzero_cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_nonzero_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_cpu_complex64" time="18.425" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_cpu_float32" time="0.142" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_fro_cpu_complex64" time="0.399" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_fro_cpu_float32" time="0.163" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_inf_cpu_complex64" time="1.752" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_inf_cpu_float32" time="0.145" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_nuc_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_norm_nuc_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_in_place_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_in_place_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_normal_number_mean_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_like_cpu_complex64" time="0.352" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ones_like_cpu_float32" time="0.182" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ormqr_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ormqr_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_outer_cpu_complex64" time="0.309" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_outer_cpu_float32" time="0.149" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pca_lowrank_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_permute_cpu_complex64" time="1.287" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_permute_cpu_float32" time="0.675" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pinverse_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pinverse_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polar_cpu_float32" time="0.694" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_0_cpu_float32" time="0.718" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_1_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_2_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_3_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_polygamma_polygamma_n_4_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_positive_cpu_complex64" time="0.283" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_positive_cpu_float32" time="0.137" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pow_cpu_complex64" time="3.176" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_pow_cpu_float32" time="1.528" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_prod_cpu_complex64" time="13.011" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_prod_cpu_float32" time="6.408" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_put_cpu_complex64" time="6.917" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_put_cpu_float32" time="3.338" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_qr_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_qr_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_quantile_cpu_float32" time="10.527" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rad2deg_cpu_float32" time="0.138" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rand_like_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rand_like_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randint_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randint_like_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_like_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_randn_like_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ravel_cpu_complex64" time="0.883" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_ravel_cpu_float32" time="0.439" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_real_cpu_complex64" time="0.410" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_real_cpu_float32" time="0.203" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reciprocal_cpu_complex64" time="0.900" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reciprocal_cpu_float32" time="0.444" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_remainder_cpu_float32" time="1.408" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_renorm_cpu_complex64" time="1.361" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_renorm_cpu_float32" time="0.656" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_cpu_complex64" time="3.690" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_cpu_float32" time="1.815" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_interleave_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_repeat_interleave_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_as_cpu_complex64" time="0.573" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_as_cpu_float32" time="0.281" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_cpu_complex64" time="2.154" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_reshape_cpu_float32" time="1.117" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize__cpu_complex64" time="0.036" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize__cpu_float32" time="0.039" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize_as__cpu_complex64" time="0.035" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resize_as__cpu_float32" time="0.037" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_conj_cpu_complex64" time="0.576" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_conj_cpu_float32" time="0.274" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_neg_cpu_complex64" time="0.558" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_resolve_neg_cpu_float32" time="0.275" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_roll_cpu_complex64" time="5.477" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_roll_cpu_float32" time="2.666" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rot90_cpu_complex64" time="10.901" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rot90_cpu_float32" time="5.322" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_cpu_float32" time="0.150" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_decimals_0_cpu_float32" time="0.431" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_decimals_3_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_round_decimals_neg_3_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsqrt_cpu_complex64" time="0.920" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsqrt_cpu_float32" time="0.444" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsub_cpu_complex64" time="1.879" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_rsub_cpu_float32" time="0.969" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scalar_tensor_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scalar_tensor_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_add_cpu_complex64" time="2.212" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_add_cpu_float32" time="1.074" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_cpu_complex64" time="2.546" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_cpu_float32" time="1.235" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_amax_cpu_float32" time="3.464" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_amin_cpu_float32" time="3.473" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_mean_cpu_float32" time="3.521" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_prod_cpu_float32" time="3.818" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_scatter_reduce_sum_cpu_float32" time="3.434" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_searchsorted_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Expected failure!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Expected failure!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_select_cpu_complex64" time="1.509" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_select_cpu_float32" time="0.759" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_select_scatter_cpu_float32" time="0.780" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sgn_cpu_complex64" time="0.295" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sgn_cpu_float32" time="0.141" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_short_cpu_complex64" time="0.026" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_short_cpu_float32" time="0.027" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sigmoid_cpu_complex64" time="0.889" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sigmoid_cpu_float32" time="0.443" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sign_cpu_float32" time="0.138" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_bartlett_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_blackman_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_cosine_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_exponential_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_gaussian_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_general_cosine_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_general_hamming_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_hamming_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_hann_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_kaiser_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signal_windows_nuttall_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_signbit_cpu_float32" time="0.048" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sin_cpu_complex64" time="0.313" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sin_cpu_float32" time="0.150" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinc_cpu_complex64" time="0.860" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinc_cpu_float32" time="0.452" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinh_cpu_complex64" time="0.313" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sinh_cpu_float32" time="0.151" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_slice_cpu_complex64" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="variant consistency doesn't work on torch.ops">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: variant consistency doesn't work on torch.ops</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_slice_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="variant consistency doesn't work on torch.ops">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: variant consistency doesn't work on torch.ops</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_slice_scatter_cpu_float32" time="1.600" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_softmax_cpu_float32" time="1.108" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_softmax_with_dtype_cpu_complex64" time="2.265" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_softmax_with_dtype_cpu_float32" time="1.140" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sort_cpu_float32" time="9.678" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sparse_mm_reduce_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sparse_sampled_addmm_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sparse_sampled_addmm_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_airy_ai_cpu_float32" time="0.084" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_j0_cpu_float32" time="0.086" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_j1_cpu_float32" time="0.082" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_y0_cpu_float32" time="0.083" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_bessel_y1_cpu_float32" time="0.082" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_t_cpu_float32" time="0.251" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_u_cpu_float32" time="0.268" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_v_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_chebyshev_polynomial_w_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_entr_cpu_float32" time="0.175" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_erfcx_cpu_float32" time="0.255" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_hermite_polynomial_h_cpu_float32" time="0.258" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_hermite_polynomial_he_cpu_float32" time="0.258" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_i0e_cpu_float32" time="0.175" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_i1_cpu_float32" time="0.261" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_i1e_cpu_float32" time="0.258" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_laguerre_polynomial_l_cpu_float32" time="0.257" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_legendre_polynomial_p_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_log_ndtr_cpu_float32" time="0.263" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_i0_cpu_float32" time="0.082" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_i1_cpu_float32" time="0.085" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_k0_cpu_float32" time="0.084" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_modified_bessel_k1_cpu_float32" time="0.087" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_ndtr_cpu_float32" time="0.266" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_ndtri_cpu_float32" time="0.259" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_polygamma_special_polygamma_n_0_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_scaled_modified_bessel_k0_cpu_float32" time="0.084" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_scaled_modified_bessel_k1_cpu_float32" time="0.083" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_t_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_u_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_v_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_shifted_chebyshev_polynomial_w_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_spherical_bessel_j0_cpu_float32" time="0.086" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_xlog1py_cpu_float32" time="0.921" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_special_zeta_cpu_float32" time="0.300" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_cpu_complex64" time="0.971" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_cpu_float32" time="0.463" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_list_args_cpu_complex64" time="1.655" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_list_args_cpu_float32" time="0.785" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_with_sizes_cpu_complex64" time="2.406" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_split_with_sizes_cpu_float32" time="1.162" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sqrt_cpu_complex64" time="0.477" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sqrt_cpu_float32" time="0.235" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_square_cpu_complex64" time="1.394" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_square_cpu_float32" time="0.756" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_cpu_complex64" time="4.549" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_cpu_float32" time="2.781" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_multiple_cpu_complex64" time="4.876" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_squeeze_multiple_cpu_float32" time="2.591" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stack_cpu_complex64" time="4.248" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stack_cpu_float32" time="2.421" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_cpu_complex64" time="9.709" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_cpu_float32" time="4.793" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_cpu_complex64" time="5.122" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_cpu_float32" time="2.474" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_unbiased_cpu_complex64" time="0.953" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_mean_unbiased_cpu_float32" time="0.469" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_unbiased_cpu_complex64" time="1.817" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_std_unbiased_cpu_float32" time="0.898" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stft_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped! stft does not match the native function">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped! stft does not match the native function</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_stft_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped! stft does not match the native function">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped! stft does not match the native function</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sub_cpu_complex64" time="10.995" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sub_cpu_float32" time="5.408" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_cpu_complex64" time="17.773" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_cpu_float32" time="9.303" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_to_size_cpu_complex64" time="7.052" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_sum_to_size_cpu_float32" time="2.341" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_svd_cpu_complex64" time="0.004" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_svd_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_svd_lowrank_cpu_float32" time="0.003" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_t_cpu_complex64" time="2.396" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_t_cpu_float32" time="1.189" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_along_dim_cpu_complex64" time="4.332" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_along_dim_cpu_float32" time="2.093" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_cpu_complex64" time="8.216" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_take_cpu_float32" time="4.282" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tan_cpu_complex64" time="0.940" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tan_cpu_float32" time="0.463" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tanh_cpu_complex64" time="0.893" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tanh_cpu_float32" time="0.441" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensor_split_cpu_complex64" time="9.854" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensor_split_cpu_float32" time="3.497" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensordot_cpu_complex64" time="0.842" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tensordot_cpu_float32" time="0.391" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tile_cpu_complex64" time="12.593" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tile_cpu_float32" time="4.702" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_sparse_cpu_complex64" time="0.135" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_to_sparse_cpu_float32" time="0.225" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_topk_cpu_float32" time="2.414" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trace_cpu_complex64" time="0.282" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trace_cpu_float32" time="0.139" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_transpose_cpu_complex64" time="2.485" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_transpose_cpu_float32" time="1.239" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapezoid_cpu_complex64" time="1.480" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapezoid_cpu_float32" time="0.708" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapz_cpu_complex64" time="1.446" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trapz_cpu_float32" time="0.709" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triangular_solve_cpu_complex64" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triangular_solve_cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="PyTorch compiled without Lapack">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: PyTorch compiled without Lapack</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tril_cpu_complex64" time="4.547" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_tril_cpu_float32" time="2.284" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triu_cpu_complex64" time="4.335" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_triu_cpu_float32" time="2.190" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_true_divide_cpu_complex64" time="3.097" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_true_divide_cpu_float32" time="1.551" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_trunc_cpu_float32" time="0.152" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unbind_cpu_complex64" time="2.356" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unbind_cpu_float32" time="1.103" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unflatten_cpu_complex64" time="3.196" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unflatten_cpu_float32" time="1.575" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_copy_cpu_complex64" time="3.505" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_copy_cpu_float32" time="1.737" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_cpu_complex64" time="3.572" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unfold_cpu_float32" time="1.747" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_uniform_cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_uniform_cpu_float32" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unique_consecutive_cpu_float32" time="0.055" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unique_cpu_float32" time="0.043" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsafe_split_cpu_complex64" time="0.703" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsafe_split_cpu_float32" time="0.335" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsqueeze_cpu_complex64" time="2.775" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_unsqueeze_cpu_float32" time="1.387" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_cpu_complex64" time="3.497" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_cpu_float32" time="1.699" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_cpu_complex64" time="1.775" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_cpu_float32" time="0.860" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_unbiased_cpu_complex64" time="0.341" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_mean_unbiased_cpu_float32" time="0.160" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_unbiased_cpu_complex64" time="0.627" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_var_unbiased_cpu_float32" time="0.314" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vdot_cpu_complex64" time="0.603" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vdot_cpu_float32" time="0.146" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_complex_cpu_float32" time="0.073" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_cpu_complex64" time="0.596" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_cpu_float32" time="0.300" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_as_real_cpu_complex64" time="0.159" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_copy_cpu_float32" time="0.536" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_cpu_complex64" time="1.158" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_view_cpu_float32" time="0.557" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vsplit_cpu_complex64" time="0.744" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vsplit_cpu_float32" time="0.354" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vstack_cpu_complex64" time="0.338" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_vstack_cpu_float32" time="0.157" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_where_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_where_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_xlogy_cpu_float32" time="1.351" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zero__cpu_complex64" time="0.002" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zero__cpu_float32" time="0.001" file="test_ops_jit.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_cpu_complex64" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_cpu_float32" time="0.000" file="test_ops_jit.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_jit.py:40: Skipped!</skipped>
    </testcase>
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_like_cpu_complex64" time="0.346" file="test_ops_jit.py" />
    <testcase classname="TestJitCPU" name="test_variant_consistency_jit_zeros_like_cpu_float32" time="0.185" file="test_ops_jit.py" />
  </testsuite>
</testsuites>