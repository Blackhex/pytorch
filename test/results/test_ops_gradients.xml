<testsuites>
  <testsuite name="pytest" errors="0" failures="10" skipped="3130" tests="5009" time="1005.579" timestamp="2023-05-05T19:50:47.676254" hostname="BartonTest">
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_H_cpu_complex128" time="0.073" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_H_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_T_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_T_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___getitem___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___getitem___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___radd___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___radd___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rdiv___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rdiv___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rmatmul___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rmatmul___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rmod___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rmul___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rmul___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rpow___cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rpow___cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rsub___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad___rsub___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad__native_batch_norm_legit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad__segment_reduce_lengths_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad__segment_reduce_offsets_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad__softmax_backward_data_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad__upsample_bilinear2d_aa_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_abs_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_abs_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_acos_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_acos_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_acosh_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_acosh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_add_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_add_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addbmm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addbmm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addcdiv_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addcdiv_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addcmul_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addcmul_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addmm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addmm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addmm_decomposed_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addmm_decomposed_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addmv_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addmv_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addr_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_addr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_all_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_all_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_allclose_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_allclose_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_amax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_amin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_aminmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_angle_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_angle_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_any_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_any_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_arange_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_argmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_argmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_argsort_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_argwhere_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_argwhere_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_as_strided_cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_as_strided_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_as_strided_partial_views_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_as_strided_partial_views_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_as_strided_scatter_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_as_strided_scatter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_asin_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_asin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_asinh_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_asinh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atan2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atan_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atan_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atanh_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atanh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atleast_1d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atleast_1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atleast_2d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atleast_2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atleast_3d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_atleast_3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_baddbmm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_baddbmm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bernoulli_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bfloat16_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bfloat16_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_block_diag_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_block_diag_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bmm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bmm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bool_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bool_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_broadcast_tensors_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_broadcast_tensors_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_broadcast_to_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_broadcast_to_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_bucketize_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_byte_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_byte_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cartesian_prod_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cartesian_prod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cat_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cat_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cauchy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cdist_cpu_float64" time="0.336" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cdouble_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cdouble_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ceil_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cfloat_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cfloat_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_chalf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_chalf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_char_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_char_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cholesky_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cholesky_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cholesky_inverse_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cholesky_inverse_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cholesky_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cholesky_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_chunk_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_chunk_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_clamp_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_clamp_max_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_clamp_min_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_clone_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_clone_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_column_stack_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_column_stack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_combinations_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_combinations_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_complex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_conj_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_conj_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_conj_physical_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_conj_physical_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_constant_pad_nd_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_constant_pad_nd_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_contiguous_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_contiguous_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_copysign_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_corrcoef_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_corrcoef_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cos_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cos_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cosh_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cosh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_count_nonzero_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_count_nonzero_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cov_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cov_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cross_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cross_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cummax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cummin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cumprod_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cumprod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cumsum_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cumsum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cumulative_trapezoid_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_cumulative_trapezoid_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_deg2rad_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diag_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diag_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diag_embed_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diag_embed_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagflat_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagflat_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagonal_copy_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagonal_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagonal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagonal_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagonal_scatter_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diagonal_scatter_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diff_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_diff_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_digamma_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dist_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dist_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_div_floor_rounding_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_div_no_rounding_mode_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_div_no_rounding_mode_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_div_trunc_rounding_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dot_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dot_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_double_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_double_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dsplit_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dsplit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dstack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_dstack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_einsum_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_einsum_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_empty_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_empty_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_empty_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_empty_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_empty_permuted_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_empty_permuted_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_eq_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_eq_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_equal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_equal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_erf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_erfc_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_erfinv_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_exp2_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_exp2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_exp_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_exp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_expand_as_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_expand_as_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_expand_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_expand_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_expm1_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_expm1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_exponential_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_eye_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_eye_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fft2_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fft2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fft_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fftn_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fftn_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fftshift_cpu_complex128" time="0.012" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_fftshift_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_hfft2_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_hfft2_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_hfft_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_hfft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_hfftn_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_hfftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifft2_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifft2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifft_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifft_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifftn_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifftshift_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ifftshift_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ihfft2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ihfft_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_ihfftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_irfft2_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_irfft2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_irfft_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_irfft_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_irfftn_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_irfftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_rfft2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_rfft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fft_rfftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fill_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fill_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_flatten_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_flatten_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_flip_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_flip_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fliplr_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fliplr_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_flipud_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_flipud_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_float_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_float_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_float_power_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_float_power_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_floor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_floor_divide_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_fmod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_frac_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_frexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_full_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_full_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_full_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_full_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_gather_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_gather_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ge_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_geometric_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_geqrf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_geqrf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_gradient_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_gradient_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_grid_sampler_2d_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_gt_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_half_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_half_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_heaviside_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_histc_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_histogram_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_histogramdd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_hsplit_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_hsplit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_hstack_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_hstack_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_hypot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_i0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_igamma_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_igammac_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_imag_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_add_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_add_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_copy_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_fill_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_fill_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_put_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_put_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_reduce_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_select_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_index_select_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_inner_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_inner_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_int_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_int_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isclose_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isclose_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isfinite_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isfinite_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isinf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isinf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isnan_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isnan_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isneginf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isposinf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isreal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_isreal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_istft_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_2inputs_2outputs_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_2inputs_2outputs_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_4inputs_with_extra_args_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_4inputs_with_extra_args_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_binary_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_binary_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_binary_return_by_ref_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_binary_return_by_ref_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_unary_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_jiterator_unary_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_kron_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_kron_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_kthvalue_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ldexp_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ldexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_le_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lerp_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lerp_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lgamma_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cholesky_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cholesky_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cholesky_ex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cholesky_ex_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cond_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cond_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cross_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_cross_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_det_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_det_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_det_singular_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_det_singular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_diagonal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_diagonal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eig_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eig_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eigh_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eigh_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eigvals_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eigvals_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eigvalsh_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_eigvalsh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_householder_product_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_householder_product_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_inv_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_inv_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_inv_ex_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_inv_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_ldl_factor_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_ldl_factor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_ldl_factor_ex_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_ldl_factor_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_ldl_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_ldl_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lstsq_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lstsq_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lstsq_grad_oriented_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lstsq_grad_oriented_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_factor_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_factor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_factor_ex_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_factor_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_solve_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_lu_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_norm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_norm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_power_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_power_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_rank_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_rank_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_rank_hermitian_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_matrix_rank_hermitian_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_multi_dot_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_multi_dot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_norm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_norm_subgradients_at_zero_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_norm_subgradients_at_zero_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_pinv_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_pinv_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_pinv_hermitian_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_pinv_hermitian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_pinv_singular_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_pinv_singular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_qr_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_qr_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_slogdet_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_slogdet_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_solve_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_solve_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_solve_ex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_solve_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_solve_triangular_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_solve_triangular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_svd_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_svd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_svdvals_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_svdvals_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_vander_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_vander_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_vecdot_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_vecdot_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_vector_norm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linalg_vector_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linspace_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_linspace_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log10_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log10_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log1p_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log1p_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log2_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log_normal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log_softmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log_softmax_with_dtype_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_log_softmax_with_dtype_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logaddexp2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logaddexp_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logaddexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logcumsumexp_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logcumsumexp_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logdet_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logdet_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_and_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_and_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_not_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_not_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_or_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_or_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_xor_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logical_xor_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logit_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logspace_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logspace_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_logsumexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_long_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_long_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lt_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lu_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lu_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lu_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lu_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lu_unpack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_lu_unpack_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mH_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mH_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mT_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mT_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_amax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_amin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_argmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_argmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_cumprod_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_cumprod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_cumsum_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_cumsum_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_fill_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_fill_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_log_softmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_logaddexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_logsumexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_mean_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_median_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_normalize_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_normalize_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_prod_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_prod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_scatter_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_scatter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_select_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_select_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_softmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_softmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_std_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_std_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_sum_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_sum_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_var_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_masked_var_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_matmul_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_matmul_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_matrix_exp_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_matrix_exp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_max_binary_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_max_pool2d_with_indices_backward_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_max_reduction_no_dim_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_max_reduction_with_dim_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_maximum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mean_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_median_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_meshgrid_list_of_tensors_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_meshgrid_list_of_tensors_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_meshgrid_variadic_tensors_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_meshgrid_variadic_tensors_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_min_binary_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_min_reduction_no_dim_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_min_reduction_with_dim_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_minimum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mode_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_movedim_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_movedim_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_msort_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mul_cpu_complex128" time="0.024" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mul_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_multinomial_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mv_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mv_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mvlgamma_mvlgamma_p_1_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mvlgamma_mvlgamma_p_3_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_mvlgamma_mvlgamma_p_5_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nan_to_num_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nanmean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nanmedian_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nanquantile_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nansum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_narrow_copy_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_narrow_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_narrow_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_narrow_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_native_batch_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_native_dropout_backward_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_native_layer_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ne_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ne_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_neg_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_neg_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_empty_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_empty_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_empty_strided_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_empty_strided_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_full_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_full_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_ones_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_ones_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_zeros_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_new_zeros_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nextafter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_adaptive_avg_pool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_adaptive_avg_pool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_adaptive_avg_pool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_adaptive_max_pool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_adaptive_max_pool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_adaptive_max_pool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_alpha_dropout_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_avg_pool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_avg_pool2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_avg_pool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_batch_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_bilinear_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_binary_cross_entropy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_binary_cross_entropy_with_logits_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_celu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv1d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv2d_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv_transpose1d_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv_transpose1d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv_transpose2d_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv_transpose2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv_transpose3d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_conv_transpose3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_cosine_embedding_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_cosine_similarity_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_cross_entropy_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_ctc_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_dropout2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_dropout3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_dropout_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_elu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_embedding_bag_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_embedding_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_feature_alpha_dropout_with_train_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_feature_alpha_dropout_without_train_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_feature_alpha_dropout_without_train_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_fractional_max_pool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_fractional_max_pool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_gaussian_nll_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_gelu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_glu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_grid_sample_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_group_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_hardshrink_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_hardsigmoid_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_hardswish_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_hardtanh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_hinge_embedding_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_huber_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_instance_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_interpolate_area_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_interpolate_bicubic_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_interpolate_bilinear_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_interpolate_linear_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_interpolate_nearest_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_interpolate_trilinear_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_kl_div_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_l1_loss_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_l1_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_layer_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_leaky_relu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_linear_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_linear_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_local_response_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_logsigmoid_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_margin_ranking_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_pool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_pool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_pool3d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_unpool1d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_unpool1d_grad_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_unpool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_unpool2d_grad_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_unpool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_max_unpool3d_grad_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_mish_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_mse_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_multi_margin_loss_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_multilabel_margin_loss_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_multilabel_soft_margin_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_nll_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_normalize_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_normalize_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_circular_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_circular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_constant_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_constant_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_reflect_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_reflect_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_replicate_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pad_replicate_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pairwise_distance_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pairwise_distance_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pdist_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pixel_shuffle_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pixel_shuffle_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pixel_unshuffle_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_pixel_unshuffle_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_poisson_nll_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_prelu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_relu6_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_relu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_rrelu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_scaled_dot_product_attention_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_selu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_silu_complex_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_silu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_smooth_l1_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_soft_margin_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_softmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_softmin_with_dtype_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_softmin_with_dtype_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_softplus_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_softshrink_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_softsign_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_softsign_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_tanhshrink_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_tanhshrink_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_threshold_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_triplet_margin_loss_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_triplet_margin_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_triplet_margin_with_distance_loss_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_triplet_margin_with_distance_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_unfold_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_unfold_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_upsample_bilinear_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nn_functional_upsample_nearest_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nonzero_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nonzero_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nonzero_static_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_nonzero_static_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_fro_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_fro_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_inf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_inf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_nuc_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_norm_nuc_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_normal_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_normal_in_place_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_normal_in_place_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_normal_number_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ones_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ones_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ones_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ones_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ormqr_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ormqr_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_outer_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_outer_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_pca_lowrank_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_permute_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_permute_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_pinverse_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_pinverse_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_polar_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_polygamma_polygamma_n_0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_polygamma_polygamma_n_1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_polygamma_polygamma_n_2_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_polygamma_polygamma_n_3_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_polygamma_polygamma_n_4_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_positive_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_positive_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_pow_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_pow_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_prod_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_prod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_put_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_put_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_qr_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_qr_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_quantile_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rad2deg_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rand_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rand_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_randint_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_randint_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_randn_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_randn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_randn_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_randn_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ravel_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_ravel_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_real_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_real_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_reciprocal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_reciprocal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_remainder_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_renorm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_renorm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_repeat_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_repeat_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_repeat_interleave_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_repeat_interleave_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_reshape_as_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_reshape_as_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_reshape_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_reshape_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resize__cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resize__cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resize_as__cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resize_as__cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resolve_conj_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resolve_conj_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resolve_neg_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_resolve_neg_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_roll_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_roll_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rot90_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rot90_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_round_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_round_decimals_0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_round_decimals_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_round_decimals_neg_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rsqrt_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rsqrt_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rsub_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_rsub_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scalar_tensor_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scalar_tensor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_add_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_add_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_reduce_amax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_reduce_amin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_reduce_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_reduce_prod_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_scatter_reduce_sum_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_searchsorted_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_select_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_select_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_select_scatter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sgn_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sgn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_short_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_short_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sigmoid_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sigmoid_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sign_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_bartlett_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_blackman_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_cosine_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_exponential_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_gaussian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_general_cosine_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_general_hamming_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_hamming_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_hann_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_kaiser_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signal_windows_nuttall_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_signbit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sin_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sinc_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sinc_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sinh_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sinh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_slice_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_slice_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_slice_scatter_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_softmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_softmax_with_dtype_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_softmax_with_dtype_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sort_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sparse_mm_reduce_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sparse_sampled_addmm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="PyTorch is built without MKL support">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: PyTorch is built without MKL support</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sparse_sampled_addmm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="PyTorch is built without MKL support">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: PyTorch is built without MKL support</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_airy_ai_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_bessel_j0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_bessel_j1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_bessel_y0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_bessel_y1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_chebyshev_polynomial_t_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_chebyshev_polynomial_u_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_chebyshev_polynomial_v_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_chebyshev_polynomial_w_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_entr_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_erfcx_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_hermite_polynomial_h_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_hermite_polynomial_he_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_i0e_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_i1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_i1e_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_laguerre_polynomial_l_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_legendre_polynomial_p_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_log_ndtr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_modified_bessel_i0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_modified_bessel_i1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_modified_bessel_k0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_modified_bessel_k1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_ndtr_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_ndtri_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_polygamma_special_polygamma_n_0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_scaled_modified_bessel_k0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_scaled_modified_bessel_k1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_shifted_chebyshev_polynomial_t_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_shifted_chebyshev_polynomial_u_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_shifted_chebyshev_polynomial_v_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_shifted_chebyshev_polynomial_w_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_spherical_bessel_j0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_xlog1py_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_special_zeta_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_split_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_split_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_split_list_args_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_split_list_args_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_split_with_sizes_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_split_with_sizes_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sqrt_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sqrt_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_square_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_square_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_squeeze_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_squeeze_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_squeeze_multiple_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_squeeze_multiple_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_stack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_stack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_mean_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_mean_unbiased_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_mean_unbiased_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_unbiased_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_std_unbiased_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_stft_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_stft_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sub_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sub_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sum_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sum_to_size_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_sum_to_size_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_svd_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_svd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_svd_lowrank_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_t_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_t_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_take_along_dim_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_take_along_dim_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_take_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_take_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tan_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tan_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tanh_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tanh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tensor_split_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tensor_split_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tensordot_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tensordot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tile_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tile_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_to_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_to_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_to_sparse_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_to_sparse_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_topk_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_trace_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_trace_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_transpose_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_transpose_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_trapezoid_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_trapezoid_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_trapz_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_trapz_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_triangular_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_triangular_solve_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tril_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_tril_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_triu_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_triu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_true_divide_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_true_divide_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_trunc_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unbind_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unbind_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unflatten_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unflatten_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unfold_copy_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unfold_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unfold_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unfold_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_uniform_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_uniform_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unique_consecutive_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unique_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unsafe_split_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unsafe_split_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unsqueeze_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_unsqueeze_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_mean_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_mean_unbiased_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_mean_unbiased_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_unbiased_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_var_unbiased_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_vdot_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_vdot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_view_as_complex_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_view_as_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_view_as_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_view_as_real_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_view_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_view_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_view_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_vsplit_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_vsplit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_vstack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_vstack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_where_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_where_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_xlogy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_zero__cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_zero__cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does support gradgrad">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Operation does support gradgrad</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_zeros_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_zeros_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_zeros_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_fail_gradgrad_zeros_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:63: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_H_cpu_complex128" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_H_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_T_cpu_complex128" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_T_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___getitem___cpu_complex128" time="0.156" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___getitem___cpu_float64" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___radd___cpu_complex128" time="0.121" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___radd___cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rdiv___cpu_complex128" time="0.135" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rdiv___cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rmatmul___cpu_complex128" time="0.035" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(0.+0.j, dtype=torch.complex128)&#10;analytical:tensor(7.1715-11.2330j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[-1.5989-6.7025j],&#10;        [-2.4225-7.8474j],&#10;        [-5.7686-5.3318j],&#10;        [ 1.0396-3.0750j],&#10;        [ 2.3002-8.1600j],&#10;        [-6.2199-5.2906j],&#10;        [ 8.6403-5.5545j],&#10;        [ 7.8948-3.4972j],&#10;        [-0.9168-8.6153j],&#10;        [ 4.5745+7.5348j],&#10;        [-0.9053+0.9469j],&#10;        [ 8.5923+2.7133j],&#10;        [-4.2845-0.0554j],&#10;        [ 4.7709+0.1739j],&#10;        [ 4.2301-7.9073j],&#10;        [-8.1944-5.0164j],&#10;        [ 0.2031+4.8537j],&#10;        [ 8.7129-4.2562j],&#10;        [-1.4437+0.6700j],&#10;        [ 6.8153-7.2035j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 10.271714029137112.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 26, in test_fn_grad
    self._grad_test_helper(device, dtype, op, op.get_op())
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4372, in _grad_test_helper
    return self._check_helper(device, dtype, op, variant, 'gradcheck', check_forward_ad=check_forward_ad,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4341, in _check_helper
    self.assertTrue(gradcheck(fn, gradcheck_args,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3896, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.+0.j, dtype=torch.complex128)
analytical:tensor(7.1715-11.2330j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j]], dtype=torch.complex128)
Analytical:
tensor([[-1.5989-6.7025j],
        [-2.4225-7.8474j],
        [-5.7686-5.3318j],
        [ 1.0396-3.0750j],
        [ 2.3002-8.1600j],
        [-6.2199-5.2906j],
        [ 8.6403-5.5545j],
        [ 7.8948-3.4972j],
        [-0.9168-8.6153j],
        [ 4.5745+7.5348j],
        [-0.9053+0.9469j],
        [ 8.5923+2.7133j],
        [-4.2845-0.0554j],
        [ 4.7709+0.1739j],
        [ 4.2301-7.9073j],
        [-8.1944-5.0164j],
        [ 0.2031+4.8537j],
        [ 8.7129-4.2562j],
        [-1.4437+0.6700j],
        [ 6.8153-7.2035j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 10.271714029137112.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rmatmul___cpu_float64" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rmod___cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rmul___cpu_complex128" time="0.123" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rmul___cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rpow___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rpow___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rsub___cpu_complex128" time="0.122" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad___rsub___cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad__native_batch_norm_legit_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad__segment_reduce_lengths_cpu_float64" time="0.201" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad__segment_reduce_offsets_cpu_float64" time="0.162" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad__softmax_backward_data_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad__upsample_bilinear2d_aa_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_abs_cpu_complex128" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_abs_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_acos_cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_acos_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_acosh_cpu_complex128" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_acosh_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_add_cpu_complex128" time="0.146" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_add_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addbmm_cpu_complex128" time="0.289" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addbmm_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addcdiv_cpu_complex128" time="0.241" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addcdiv_cpu_float64" time="0.047" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addcmul_cpu_complex128" time="0.233" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addcmul_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addmm_cpu_complex128" time="0.107" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addmm_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addmm_decomposed_cpu_complex128" time="0.104" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addmm_decomposed_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addmv_cpu_complex128" time="0.122" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addmv_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addr_cpu_complex128" time="0.081" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_addr_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_all_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_all_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_allclose_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_allclose_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_amax_cpu_float64" time="0.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_amin_cpu_float64" time="0.038" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_aminmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_angle_cpu_complex128" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_angle_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_any_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_any_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_arange_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_argmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_argmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_argsort_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_argwhere_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_argwhere_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_as_strided_cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_as_strided_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_as_strided_partial_views_cpu_complex128" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_as_strided_partial_views_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_as_strided_scatter_cpu_complex128" time="0.010" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_as_strided_scatter_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_asin_cpu_complex128" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_asin_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_asinh_cpu_complex128" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_asinh_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atan2_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atan_cpu_complex128" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atan_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atanh_cpu_complex128" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atanh_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atleast_1d_cpu_complex128" time="0.134" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atleast_1d_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atleast_2d_cpu_complex128" time="0.138" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atleast_2d_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atleast_3d_cpu_complex128" time="0.138" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_atleast_3d_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_baddbmm_cpu_complex128" time="0.276" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_baddbmm_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bernoulli_cpu_float64" time="0.066" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bfloat16_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_methods_invocations.py:15241: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Copy.cpp:276.) op=lambda x, *args, **kwargs: x.bfloat16(*args, **kwargs),
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bfloat16_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_block_diag_cpu_complex128" time="0.082" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_block_diag_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bmm_cpu_complex128" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bmm_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bool_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bool_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_broadcast_tensors_cpu_complex128" time="0.070" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_broadcast_tensors_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_broadcast_to_cpu_complex128" time="0.057" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_broadcast_to_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_bucketize_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_byte_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_byte_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cartesian_prod_cpu_complex128" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cartesian_prod_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cat_cpu_complex128" time="0.118" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cat_cpu_float64" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cauchy_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cdist_cpu_float64" time="0.733" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cdouble_cpu_complex128" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cdouble_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ceil_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cfloat_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cfloat_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_chalf_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_methods_invocations.py:15407: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\EmptyTensor.cpp:32.) op=lambda x, *args, **kwargs: x.chalf(*args, **kwargs),
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_chalf_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_char_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_char_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cholesky_cpu_complex128" time="0.233" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\opinfo\core.py:2703: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.
L = torch.cholesky(A)
should be replaced with
L = torch.linalg.cholesky(A)
and
U = torch.cholesky(A, upper=True)
should be replaced with
U = torch.linalg.cholesky(A).mH().
This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:1702.)
  return op(input + input.mH, *args, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cholesky_cpu_float64" time="0.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cholesky_inverse_cpu_complex128" time="0.234" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cholesky_inverse_cpu_float64" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cholesky_solve_cpu_complex128" time="0.316" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cholesky_solve_cpu_float64" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_chunk_cpu_complex128" time="0.091" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_chunk_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_clamp_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_clamp_max_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_clamp_min_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_clone_cpu_complex128" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_clone_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_column_stack_cpu_complex128" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_column_stack_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_combinations_cpu_complex128" time="0.241" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_combinations_cpu_float64" time="0.057" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_complex_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_conj_cpu_complex128" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_conj_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_conj_physical_cpu_complex128" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_conj_physical_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_constant_pad_nd_cpu_complex128" time="0.412" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_constant_pad_nd_cpu_float64" time="0.090" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_contiguous_cpu_complex128" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_contiguous_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_copysign_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_corrcoef_cpu_complex128" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_corrcoef_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cos_cpu_complex128" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cos_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cosh_cpu_complex128" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cosh_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_count_nonzero_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_count_nonzero_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cov_cpu_complex128" time="0.036" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cov_cpu_float64" time="0.016" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cross_cpu_complex128" time="0.140" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cross_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cummax_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cummin_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cumprod_cpu_complex128" time="5.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cumprod_cpu_float64" time="0.921" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cumsum_cpu_complex128" time="0.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cumsum_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cumulative_trapezoid_cpu_complex128" time="0.149" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_cumulative_trapezoid_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_deg2rad_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diag_cpu_complex128" time="0.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diag_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diag_embed_cpu_complex128" time="0.126" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diag_embed_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagflat_cpu_complex128" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagflat_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagonal_copy_cpu_complex128" time="0.122" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagonal_copy_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagonal_cpu_complex128" time="0.117" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagonal_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagonal_scatter_cpu_complex128" time="0.211" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diagonal_scatter_cpu_float64" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diff_cpu_complex128" time="1.184" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_diff_cpu_float64" time="0.235" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_digamma_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dist_cpu_complex128" time="0.437" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dist_cpu_float64" time="0.154" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_div_floor_rounding_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_div_no_rounding_mode_cpu_complex128" time="0.130" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_div_no_rounding_mode_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_div_trunc_rounding_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dot_cpu_complex128" time="0.014" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(0.+0.j, dtype=torch.complex128)&#10;analytical:tensor(8.4992+3.1575j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 0.5886-6.1278j],&#10;        [ 6.3505-8.0167j],&#10;        [-8.5019+0.3712j],&#10;        [ 5.0913+8.8816j],&#10;        [ 7.9659+2.2683j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 10.237428780948914.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 26, in test_fn_grad
    self._grad_test_helper(device, dtype, op, op.get_op())
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4372, in _grad_test_helper
    return self._check_helper(device, dtype, op, variant, 'gradcheck', check_forward_ad=check_forward_ad,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4341, in _check_helper
    self.assertTrue(gradcheck(fn, gradcheck_args,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3896, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.+0.j, dtype=torch.complex128)
analytical:tensor(8.4992+3.1575j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j]], dtype=torch.complex128)
Analytical:
tensor([[ 0.5886-6.1278j],
        [ 6.3505-8.0167j],
        [-8.5019+0.3712j],
        [ 5.0913+8.8816j],
        [ 7.9659+2.2683j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 10.237428780948914.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dot_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_double_cpu_complex128" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_double_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dsplit_cpu_complex128" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dsplit_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dstack_cpu_complex128" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_dstack_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_einsum_cpu_complex128" time="0.169" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_einsum_cpu_float64" time="0.035" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_empty_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_empty_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_empty_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_empty_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_empty_permuted_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_empty_permuted_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_eq_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_eq_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_equal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_equal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_erf_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_erfc_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_erfinv_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_exp2_cpu_complex128" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_exp2_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_exp_cpu_complex128" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_exp_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_expand_as_cpu_complex128" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_expand_as_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_expand_cpu_complex128" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_expand_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_expm1_cpu_complex128" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_expm1_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_exponential_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_eye_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_eye_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fft2_cpu_complex128" time="0.066" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fft2_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fft_cpu_complex128" time="0.066" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fft_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fftn_cpu_complex128" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fftn_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fftshift_cpu_complex128" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_fftshift_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_hfft2_cpu_complex128" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_hfft2_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_hfft_cpu_complex128" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_hfft_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_hfftn_cpu_complex128" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_hfftn_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifft2_cpu_complex128" time="0.059" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifft2_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifft_cpu_complex128" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifft_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifftn_cpu_complex128" time="0.075" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifftn_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifftshift_cpu_complex128" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ifftshift_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ihfft2_cpu_float64" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ihfft_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_ihfftn_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_irfft2_cpu_complex128" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_irfft2_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_irfft_cpu_complex128" time="0.038" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_irfft_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_irfftn_cpu_complex128" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_irfftn_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_rfft2_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_rfft_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fft_rfftn_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fill_cpu_complex128" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fill_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_flatten_cpu_complex128" time="0.047" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_flatten_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_flip_cpu_complex128" time="0.080" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_flip_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fliplr_cpu_complex128" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fliplr_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_flipud_cpu_complex128" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_flipud_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_float_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_float_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_float_power_cpu_complex128" time="0.157" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_float_power_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_floor_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_floor_divide_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fmax_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fmin_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_fmod_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_frac_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_frexp_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_full_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_full_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_full_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_full_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_gather_cpu_complex128" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_gather_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ge_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_geometric_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_geqrf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_geqrf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_gradient_cpu_complex128" time="0.293" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_gradient_cpu_float64" time="0.073" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_grid_sampler_2d_cpu_float64" time="0.068" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_gt_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_half_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_half_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_heaviside_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_histc_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_histogram_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_histogramdd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_hsplit_cpu_complex128" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_hsplit_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_hstack_cpu_complex128" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_hstack_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_hypot_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_i0_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_igamma_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_igammac_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_imag_cpu_complex128" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_add_cpu_complex128" time="0.126" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_add_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_copy_cpu_complex128" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_copy_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_fill_cpu_complex128" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_fill_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_put_cpu_complex128" time="0.062" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_put_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_reduce_cpu_float64" time="0.109" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\opinfo\core.py:769: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\TensorAdvancedIndexing.cpp:1110.)
  gradcheck_wrapper: Callable = lambda op, *args, **kwargs: op(*args, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_select_cpu_complex128" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_index_select_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_inner_cpu_complex128" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_inner_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_int_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_int_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isclose_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isclose_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isfinite_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isfinite_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isinf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isinf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isnan_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isnan_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isneginf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isposinf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isreal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_isreal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_istft_cpu_complex128" time="1.803" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_2inputs_2outputs_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_2inputs_2outputs_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_4inputs_with_extra_args_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_4inputs_with_extra_args_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_binary_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_binary_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_binary_return_by_ref_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_binary_return_by_ref_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_unary_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_jiterator_unary_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_kron_cpu_complex128" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_kron_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_kthvalue_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ldexp_cpu_complex128" time="0.141" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ldexp_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_le_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lerp_cpu_complex128" time="0.327" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lerp_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lgamma_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cholesky_cpu_complex128" time="0.211" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cholesky_cpu_float64" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cholesky_ex_cpu_complex128" time="0.311" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cholesky_ex_cpu_float64" time="0.068" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cond_cpu_complex128" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cond_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cross_cpu_complex128" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_cross_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_det_cpu_complex128" time="0.102" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_det_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_det_singular_cpu_complex128" time="0.483" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_det_singular_cpu_float64" time="0.161" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_diagonal_cpu_complex128" time="0.151" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_diagonal_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eig_cpu_complex128" time="0.182" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eig_cpu_float64" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eigh_cpu_complex128" time="0.050" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(0.3990-0.1056j, dtype=torch.complex128)&#10;analytical:tensor(0.7521-0.0346j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[ 0.0202+0.0000e+00j,  0.2888+0.0000e+00j, -0.4259+0.0000e+00j,&#10;          0.0023+0.0000e+00j, -0.5525+0.0000e+00j],&#10;        [ 0.1746-2.5466e-01j, -0.0333+7.0177e-02j, -0.5365+2.6133e-01j,&#10;         -0.4325+2.3378e-01j,  0.1053-1.9071e-01j],&#10;        [-0.7213-2.4699e-01j,  0.3124-4.1262e-01j,  0.7561-8.6546e-01j,&#10;          0.1952+2.6030e-01j, -0.0758-1.5681e-01j],&#10;        [ 0.2911+8.5448e-01j, -0.2082+1.8356e-01j,  0.1499-1.6156e-01j,&#10;         -0.2664+2.2936e-01j, -0.2817+2.3091e-01j],&#10;        [-0.5040+6.5719e-02j,  0.3375+5.9683e-01j,  0.1650+5.9426e-02j,&#10;          0.2865-2.0423e-01j,  0.1468-1.5021e-01j],&#10;        [ 0.1746+2.5466e-01j, -0.0333-7.0177e-02j, -0.5365-2.6133e-01j,&#10;         -0.4325-2.3378e-01j,  0.1053+1.9071e-01j],&#10;        [ 0.1588+0.0000e+00j, -0.0451+0.0000e+00j,  0.3203+0.0000e+00j,&#10;          0.4820+0.0000e+00j,  0.6604+0.0000e+00j],&#10;        [-0.1669-3.6367e-01j, -0.0643-1.7582e-03j, -0.8777-2.2834e-02j,&#10;          0.2214-2.2282e-01j, -0.2991+9.1943e-04j],&#10;        [-0.0575+1.8015e-01j,  0.0456-4.3202e-02j,  0.0083-7.8788e-02j,&#10;          0.6243+2.8269e-01j,  0.6265-6.4893e-01j],&#10;        [ 0.0432+4.8867e-02j,  0.0205+4.9290e-02j,  0.2016+8.2021e-01j,&#10;         -0.0450+1.8569e-02j,  0.6356+3.1921e-01j],&#10;        [-0.7213+2.4699e-01j,  0.3124+4.1262e-01j,  0.7561+8.6546e-01j,&#10;          0.1952-2.6030e-01j, -0.0758+1.5681e-01j],&#10;        [-0.1669+3.6367e-01j, -0.0643+1.7582e-03j, -0.8777+2.2834e-02j,&#10;          0.2214+2.2282e-01j, -0.2991-9.1943e-04j],&#10;        [ 0.4669+0.0000e+00j,  0.4948+0.0000e+00j,  1.2889+0.0000e+00j,&#10;          1.1115+0.0000e+00j,  0.3293+0.0000e+00j],&#10;        [-0.3685-1.1092e-01j, -0.1280+4.7656e-02j,  0.8396-4.6199e-02j,&#10;          0.4707+2.0184e-01j, -0.1525+3.0488e-01j],&#10;        [ 0.5194-3.2356e-01j,  0.1062+5.4941e-01j,  0.1868-5.4443e-01j,&#10;         -0.2559-3.3784e-01j, -0.0965-2.7128e-01j],&#10;        [ 0.2911-8.5448e-01j, -0.2082-1.8356e-01j,  0.1499+1.6156e-01j,&#10;         -0.2664-2.2936e-01j, -0.2817-2.3091e-01j],&#10;        [-0.0575-1.8015e-01j,  0.0456+4.3202e-02j,  0.0083+7.8788e-02j,&#10;          0.6243-2.8269e-01j,  0.6265+6.4893e-01j],&#10;        [-0.3685+1.1092e-01j, -0.1280-4.7656e-02j,  0.8396+4.6199e-02j,&#10;          0.4707-2.0184e-01j, -0.1525-3.0488e-01j],&#10;        [ 0.4287+0.0000e+00j,  0.0268+0.0000e+00j,  0.0075+0.0000e+00j,&#10;          0.0195+0.0000e+00j,  0.3307+0.0000e+00j],&#10;        [-0.4244+2.3993e-01j, -0.2338-2.2296e-01j, -0.7383-1.0534e+00j,&#10;         -0.6087+7.4201e-02j, -0.1313+1.0581e-01j],&#10;        [-0.5040-6.5719e-02j,  0.3375-5.9683e-01j,  0.1650-5.9426e-02j,&#10;          0.2865+2.0423e-01j,  0.1468+1.5021e-01j],&#10;        [ 0.0432-4.8867e-02j,  0.0205-4.9290e-02j,  0.2016-8.2021e-01j,&#10;         -0.0450-1.8569e-02j,  0.6356-3.1921e-01j],&#10;        [ 0.5194+3.2356e-01j,  0.1062-5.4941e-01j,  0.1868+5.4443e-01j,&#10;         -0.2559+3.3784e-01j, -0.0965+2.7128e-01j],&#10;        [-0.4244-2.3993e-01j, -0.2338+2.2296e-01j, -0.7383+1.0534e+00j,&#10;         -0.6087-7.4201e-02j, -0.1313-1.0581e-01j],&#10;        [ 0.2324+0.0000e+00j,  0.8400+0.0000e+00j,  0.4049+0.0000e+00j,&#10;          0.1963+0.0000e+00j,  0.3263+0.0000e+00j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 0.6067+0.0000j,  0.5878+0.0000j,  0.1853+0.0000j,  0.4324+0.0000j,&#10;          0.1878+0.0000j],&#10;        [ 0.1136-0.3217j, -0.0781-0.0045j, -0.0647+0.2185j, -0.0350+0.5145j,&#10;          0.0642-0.4067j],&#10;        [-0.4660-0.0994j,  0.4587-0.3210j, -0.0157-0.2454j, -0.0194+0.5373j,&#10;          0.0424+0.1286j],&#10;        [ 0.3637+0.4781j, -0.1292+0.0058j,  0.0822-0.3769j, -0.1385+0.1370j,&#10;         -0.1782-0.2439j],&#10;        [-0.3719+0.0521j,  0.4109+0.5700j, -0.2431-0.1261j,  0.1348-0.2583j,&#10;          0.0693-0.2377j],&#10;        [ 0.1136+0.3217j, -0.0781+0.0045j, -0.0647-0.2185j, -0.0350-0.5145j,&#10;          0.0642+0.4067j],&#10;        [ 0.1919+0.0000j,  0.0104+0.0000j,  0.2802+0.0000j,  0.6150+0.0000j,&#10;          0.9025+0.0000j],&#10;        [-0.0346-0.2657j, -0.0585+0.0462j, -0.2839+0.1043j,  0.6409-0.0204j,&#10;         -0.2639+0.1357j],&#10;        [-0.1854+0.2824j,  0.0171-0.0018j, -0.4731+0.0348j,  0.1742+0.1537j,&#10;          0.4672-0.4692j],&#10;        [-0.0973-0.1875j, -0.0590-0.0726j, -0.0637+0.3307j, -0.3183-0.1395j,&#10;          0.5383+0.0688j],&#10;        [-0.4660+0.0994j,  0.4587+0.3210j, -0.0157+0.2454j, -0.0194-0.5373j,&#10;          0.0424-0.1286j],&#10;        [-0.0346+0.2657j, -0.0585-0.0462j, -0.2839-0.1043j,  0.6409+0.0204j,&#10;         -0.2639-0.1357j],&#10;        [ 0.3742+0.0000j,  0.5334+0.0000j,  0.3264+0.0000j,  0.6685+0.0000j,&#10;          0.0976+0.0000j],&#10;        [-0.3577-0.3076j, -0.1039-0.0661j,  0.4923+0.1407j,  0.1764+0.1659j,&#10;         -0.2071+0.0670j],&#10;        [ 0.2771-0.1010j,  0.0094+0.6693j,  0.1876-0.3114j, -0.3270-0.1559j,&#10;         -0.1471-0.1010j],&#10;        [ 0.3637-0.4781j, -0.1292-0.0058j,  0.0822+0.3769j, -0.1385-0.1370j,&#10;         -0.1782+0.2439j],&#10;        [-0.1854-0.2824j,  0.0171+0.0018j, -0.4731-0.0348j,  0.1742-0.1537j,&#10;          0.4672+0.4692j],&#10;        [-0.3577+0.3076j, -0.1039+0.0661j,  0.4923-0.1407j,  0.1764-0.1659j,&#10;         -0.2071-0.0670j],&#10;        [ 0.5948+0.0000j,  0.0284+0.0000j,  0.8032+0.0000j,  0.0878+0.0000j,&#10;          0.4858+0.0000j],&#10;        [-0.1819+0.3243j, -0.0847-0.1293j,  0.1487-0.5505j, -0.1250+0.0400j,&#10;          0.2429+0.3155j],&#10;        [-0.3719-0.0521j,  0.4109-0.5700j, -0.2431+0.1261j,  0.1348+0.2583j,&#10;          0.0693+0.2377j],&#10;        [-0.0973+0.1875j, -0.0590+0.0726j, -0.0637-0.3307j, -0.3183+0.1395j,&#10;          0.5383-0.0688j],&#10;        [ 0.2771+0.1010j,  0.0094-0.6693j,  0.1876+0.3114j, -0.3270+0.1559j,&#10;         -0.1471+0.1010j],&#10;        [-0.1819-0.3243j, -0.0847+0.1293j,  0.1487+0.5505j, -0.1250-0.0400j,&#10;          0.2429-0.3155j],&#10;        [ 0.2324+0.0000j,  0.8400+0.0000j,  0.4049+0.0000j,  0.1963+0.0000j,&#10;          0.3263+0.0000j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 1.019707469700251.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 26, in test_fn_grad
    self._grad_test_helper(device, dtype, op, op.get_op())
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4372, in _grad_test_helper
    return self._check_helper(device, dtype, op, variant, 'gradcheck', check_forward_ad=check_forward_ad,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4341, in _check_helper
    self.assertTrue(gradcheck(fn, gradcheck_args,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3896, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1163, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.3990-0.1056j, dtype=torch.complex128)
analytical:tensor(0.7521-0.0346j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0202+0.0000e+00j,  0.2888+0.0000e+00j, -0.4259+0.0000e+00j,
          0.0023+0.0000e+00j, -0.5525+0.0000e+00j],
        [ 0.1746-2.5466e-01j, -0.0333+7.0177e-02j, -0.5365+2.6133e-01j,
         -0.4325+2.3378e-01j,  0.1053-1.9071e-01j],
        [-0.7213-2.4699e-01j,  0.3124-4.1262e-01j,  0.7561-8.6546e-01j,
          0.1952+2.6030e-01j, -0.0758-1.5681e-01j],
        [ 0.2911+8.5448e-01j, -0.2082+1.8356e-01j,  0.1499-1.6156e-01j,
         -0.2664+2.2936e-01j, -0.2817+2.3091e-01j],
        [-0.5040+6.5719e-02j,  0.3375+5.9683e-01j,  0.1650+5.9426e-02j,
          0.2865-2.0423e-01j,  0.1468-1.5021e-01j],
        [ 0.1746+2.5466e-01j, -0.0333-7.0177e-02j, -0.5365-2.6133e-01j,
         -0.4325-2.3378e-01j,  0.1053+1.9071e-01j],
        [ 0.1588+0.0000e+00j, -0.0451+0.0000e+00j,  0.3203+0.0000e+00j,
          0.4820+0.0000e+00j,  0.6604+0.0000e+00j],
        [-0.1669-3.6367e-01j, -0.0643-1.7582e-03j, -0.8777-2.2834e-02j,
          0.2214-2.2282e-01j, -0.2991+9.1943e-04j],
        [-0.0575+1.8015e-01j,  0.0456-4.3202e-02j,  0.0083-7.8788e-02j,
          0.6243+2.8269e-01j,  0.6265-6.4893e-01j],
        [ 0.0432+4.8867e-02j,  0.0205+4.9290e-02j,  0.2016+8.2021e-01j,
         -0.0450+1.8569e-02j,  0.6356+3.1921e-01j],
        [-0.7213+2.4699e-01j,  0.3124+4.1262e-01j,  0.7561+8.6546e-01j,
          0.1952-2.6030e-01j, -0.0758+1.5681e-01j],
        [-0.1669+3.6367e-01j, -0.0643+1.7582e-03j, -0.8777+2.2834e-02j,
          0.2214+2.2282e-01j, -0.2991-9.1943e-04j],
        [ 0.4669+0.0000e+00j,  0.4948+0.0000e+00j,  1.2889+0.0000e+00j,
          1.1115+0.0000e+00j,  0.3293+0.0000e+00j],
        [-0.3685-1.1092e-01j, -0.1280+4.7656e-02j,  0.8396-4.6199e-02j,
          0.4707+2.0184e-01j, -0.1525+3.0488e-01j],
        [ 0.5194-3.2356e-01j,  0.1062+5.4941e-01j,  0.1868-5.4443e-01j,
         -0.2559-3.3784e-01j, -0.0965-2.7128e-01j],
        [ 0.2911-8.5448e-01j, -0.2082-1.8356e-01j,  0.1499+1.6156e-01j,
         -0.2664-2.2936e-01j, -0.2817-2.3091e-01j],
        [-0.0575-1.8015e-01j,  0.0456+4.3202e-02j,  0.0083+7.8788e-02j,
          0.6243-2.8269e-01j,  0.6265+6.4893e-01j],
        [-0.3685+1.1092e-01j, -0.1280-4.7656e-02j,  0.8396+4.6199e-02j,
          0.4707-2.0184e-01j, -0.1525-3.0488e-01j],
        [ 0.4287+0.0000e+00j,  0.0268+0.0000e+00j,  0.0075+0.0000e+00j,
          0.0195+0.0000e+00j,  0.3307+0.0000e+00j],
        [-0.4244+2.3993e-01j, -0.2338-2.2296e-01j, -0.7383-1.0534e+00j,
         -0.6087+7.4201e-02j, -0.1313+1.0581e-01j],
        [-0.5040-6.5719e-02j,  0.3375-5.9683e-01j,  0.1650-5.9426e-02j,
          0.2865+2.0423e-01j,  0.1468+1.5021e-01j],
        [ 0.0432-4.8867e-02j,  0.0205-4.9290e-02j,  0.2016-8.2021e-01j,
         -0.0450-1.8569e-02j,  0.6356-3.1921e-01j],
        [ 0.5194+3.2356e-01j,  0.1062-5.4941e-01j,  0.1868+5.4443e-01j,
         -0.2559+3.3784e-01j, -0.0965+2.7128e-01j],
        [-0.4244-2.3993e-01j, -0.2338+2.2296e-01j, -0.7383+1.0534e+00j,
         -0.6087-7.4201e-02j, -0.1313-1.0581e-01j],
        [ 0.2324+0.0000e+00j,  0.8400+0.0000e+00j,  0.4049+0.0000e+00j,
          0.1963+0.0000e+00j,  0.3263+0.0000e+00j]], dtype=torch.complex128)
Analytical:
tensor([[ 0.6067+0.0000j,  0.5878+0.0000j,  0.1853+0.0000j,  0.4324+0.0000j,
          0.1878+0.0000j],
        [ 0.1136-0.3217j, -0.0781-0.0045j, -0.0647+0.2185j, -0.0350+0.5145j,
          0.0642-0.4067j],
        [-0.4660-0.0994j,  0.4587-0.3210j, -0.0157-0.2454j, -0.0194+0.5373j,
          0.0424+0.1286j],
        [ 0.3637+0.4781j, -0.1292+0.0058j,  0.0822-0.3769j, -0.1385+0.1370j,
         -0.1782-0.2439j],
        [-0.3719+0.0521j,  0.4109+0.5700j, -0.2431-0.1261j,  0.1348-0.2583j,
          0.0693-0.2377j],
        [ 0.1136+0.3217j, -0.0781+0.0045j, -0.0647-0.2185j, -0.0350-0.5145j,
          0.0642+0.4067j],
        [ 0.1919+0.0000j,  0.0104+0.0000j,  0.2802+0.0000j,  0.6150+0.0000j,
          0.9025+0.0000j],
        [-0.0346-0.2657j, -0.0585+0.0462j, -0.2839+0.1043j,  0.6409-0.0204j,
         -0.2639+0.1357j],
        [-0.1854+0.2824j,  0.0171-0.0018j, -0.4731+0.0348j,  0.1742+0.1537j,
          0.4672-0.4692j],
        [-0.0973-0.1875j, -0.0590-0.0726j, -0.0637+0.3307j, -0.3183-0.1395j,
          0.5383+0.0688j],
        [-0.4660+0.0994j,  0.4587+0.3210j, -0.0157+0.2454j, -0.0194-0.5373j,
          0.0424-0.1286j],
        [-0.0346+0.2657j, -0.0585-0.0462j, -0.2839-0.1043j,  0.6409+0.0204j,
         -0.2639-0.1357j],
        [ 0.3742+0.0000j,  0.5334+0.0000j,  0.3264+0.0000j,  0.6685+0.0000j,
          0.0976+0.0000j],
        [-0.3577-0.3076j, -0.1039-0.0661j,  0.4923+0.1407j,  0.1764+0.1659j,
         -0.2071+0.0670j],
        [ 0.2771-0.1010j,  0.0094+0.6693j,  0.1876-0.3114j, -0.3270-0.1559j,
         -0.1471-0.1010j],
        [ 0.3637-0.4781j, -0.1292-0.0058j,  0.0822+0.3769j, -0.1385-0.1370j,
         -0.1782+0.2439j],
        [-0.1854-0.2824j,  0.0171+0.0018j, -0.4731-0.0348j,  0.1742-0.1537j,
          0.4672+0.4692j],
        [-0.3577+0.3076j, -0.1039+0.0661j,  0.4923-0.1407j,  0.1764-0.1659j,
         -0.2071-0.0670j],
        [ 0.5948+0.0000j,  0.0284+0.0000j,  0.8032+0.0000j,  0.0878+0.0000j,
          0.4858+0.0000j],
        [-0.1819+0.3243j, -0.0847-0.1293j,  0.1487-0.5505j, -0.1250+0.0400j,
          0.2429+0.3155j],
        [-0.3719-0.0521j,  0.4109-0.5700j, -0.2431+0.1261j,  0.1348+0.2583j,
          0.0693+0.2377j],
        [-0.0973+0.1875j, -0.0590+0.0726j, -0.0637-0.3307j, -0.3183+0.1395j,
          0.5383-0.0688j],
        [ 0.2771+0.1010j,  0.0094-0.6693j,  0.1876+0.3114j, -0.3270+0.1559j,
         -0.1471+0.1010j],
        [-0.1819-0.3243j, -0.0847+0.1293j,  0.1487+0.5505j, -0.1250-0.0400j,
          0.2429-0.3155j],
        [ 0.2324+0.0000j,  0.8400+0.0000j,  0.4049+0.0000j,  0.1963+0.0000j,
          0.3263+0.0000j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 1.019707469700251.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eigh_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eigvals_cpu_complex128" time="0.097" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eigvals_cpu_float64" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eigvalsh_cpu_complex128" time="0.040" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(0.3990-0.1056j, dtype=torch.complex128)&#10;analytical:tensor(0.7521-0.0346j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[ 0.0202+0.0000e+00j,  0.2888+0.0000e+00j, -0.4259+0.0000e+00j,&#10;          0.0023+0.0000e+00j, -0.5525+0.0000e+00j],&#10;        [ 0.1746-2.5466e-01j, -0.0333+7.0177e-02j, -0.5365+2.6133e-01j,&#10;         -0.4325+2.3378e-01j,  0.1053-1.9071e-01j],&#10;        [-0.7213-2.4699e-01j,  0.3124-4.1262e-01j,  0.7561-8.6546e-01j,&#10;          0.1952+2.6030e-01j, -0.0758-1.5681e-01j],&#10;        [ 0.2911+8.5448e-01j, -0.2082+1.8356e-01j,  0.1499-1.6156e-01j,&#10;         -0.2664+2.2936e-01j, -0.2817+2.3091e-01j],&#10;        [-0.5040+6.5719e-02j,  0.3375+5.9683e-01j,  0.1650+5.9426e-02j,&#10;          0.2865-2.0423e-01j,  0.1468-1.5021e-01j],&#10;        [ 0.1746+2.5466e-01j, -0.0333-7.0177e-02j, -0.5365-2.6133e-01j,&#10;         -0.4325-2.3378e-01j,  0.1053+1.9071e-01j],&#10;        [ 0.1588+0.0000e+00j, -0.0451+0.0000e+00j,  0.3203+0.0000e+00j,&#10;          0.4820+0.0000e+00j,  0.6604+0.0000e+00j],&#10;        [-0.1669-3.6367e-01j, -0.0643-1.7582e-03j, -0.8777-2.2834e-02j,&#10;          0.2214-2.2282e-01j, -0.2991+9.1943e-04j],&#10;        [-0.0575+1.8015e-01j,  0.0456-4.3202e-02j,  0.0083-7.8788e-02j,&#10;          0.6243+2.8269e-01j,  0.6265-6.4893e-01j],&#10;        [ 0.0432+4.8867e-02j,  0.0205+4.9290e-02j,  0.2016+8.2021e-01j,&#10;         -0.0450+1.8569e-02j,  0.6356+3.1921e-01j],&#10;        [-0.7213+2.4699e-01j,  0.3124+4.1262e-01j,  0.7561+8.6546e-01j,&#10;          0.1952-2.6030e-01j, -0.0758+1.5681e-01j],&#10;        [-0.1669+3.6367e-01j, -0.0643+1.7582e-03j, -0.8777+2.2834e-02j,&#10;          0.2214+2.2282e-01j, -0.2991-9.1943e-04j],&#10;        [ 0.4669+0.0000e+00j,  0.4948+0.0000e+00j,  1.2889+0.0000e+00j,&#10;          1.1115+0.0000e+00j,  0.3293+0.0000e+00j],&#10;        [-0.3685-1.1092e-01j, -0.1280+4.7656e-02j,  0.8396-4.6199e-02j,&#10;          0.4707+2.0184e-01j, -0.1525+3.0488e-01j],&#10;        [ 0.5194-3.2356e-01j,  0.1062+5.4941e-01j,  0.1868-5.4443e-01j,&#10;         -0.2559-3.3784e-01j, -0.0965-2.7128e-01j],&#10;        [ 0.2911-8.5448e-01j, -0.2082-1.8356e-01j,  0.1499+1.6156e-01j,&#10;         -0.2664-2.2936e-01j, -0.2817-2.3091e-01j],&#10;        [-0.0575-1.8015e-01j,  0.0456+4.3202e-02j,  0.0083+7.8788e-02j,&#10;          0.6243-2.8269e-01j,  0.6265+6.4893e-01j],&#10;        [-0.3685+1.1092e-01j, -0.1280-4.7656e-02j,  0.8396+4.6199e-02j,&#10;          0.4707-2.0184e-01j, -0.1525-3.0488e-01j],&#10;        [ 0.4287+0.0000e+00j,  0.0268+0.0000e+00j,  0.0075+0.0000e+00j,&#10;          0.0195+0.0000e+00j,  0.3307+0.0000e+00j],&#10;        [-0.4244+2.3993e-01j, -0.2338-2.2296e-01j, -0.7383-1.0534e+00j,&#10;         -0.6087+7.4201e-02j, -0.1313+1.0581e-01j],&#10;        [-0.5040-6.5719e-02j,  0.3375-5.9683e-01j,  0.1650-5.9426e-02j,&#10;          0.2865+2.0423e-01j,  0.1468+1.5021e-01j],&#10;        [ 0.0432-4.8867e-02j,  0.0205-4.9290e-02j,  0.2016-8.2021e-01j,&#10;         -0.0450-1.8569e-02j,  0.6356-3.1921e-01j],&#10;        [ 0.5194+3.2356e-01j,  0.1062-5.4941e-01j,  0.1868+5.4443e-01j,&#10;         -0.2559+3.3784e-01j, -0.0965+2.7128e-01j],&#10;        [-0.4244-2.3993e-01j, -0.2338+2.2296e-01j, -0.7383+1.0534e+00j,&#10;         -0.6087-7.4201e-02j, -0.1313-1.0581e-01j],&#10;        [ 0.2324+0.0000e+00j,  0.8400+0.0000e+00j,  0.4049+0.0000e+00j,&#10;          0.1963+0.0000e+00j,  0.3263+0.0000e+00j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 0.6067+0.0000j,  0.5878+0.0000j,  0.1853+0.0000j,  0.4324+0.0000j,&#10;          0.1878+0.0000j],&#10;        [ 0.1136-0.3217j, -0.0781-0.0045j, -0.0647+0.2185j, -0.0350+0.5145j,&#10;          0.0642-0.4067j],&#10;        [-0.4660-0.0994j,  0.4587-0.3210j, -0.0157-0.2454j, -0.0194+0.5373j,&#10;          0.0424+0.1286j],&#10;        [ 0.3637+0.4781j, -0.1292+0.0058j,  0.0822-0.3769j, -0.1385+0.1370j,&#10;         -0.1782-0.2439j],&#10;        [-0.3719+0.0521j,  0.4109+0.5700j, -0.2431-0.1261j,  0.1348-0.2583j,&#10;          0.0693-0.2377j],&#10;        [ 0.1136+0.3217j, -0.0781+0.0045j, -0.0647-0.2185j, -0.0350-0.5145j,&#10;          0.0642+0.4067j],&#10;        [ 0.1919+0.0000j,  0.0104+0.0000j,  0.2802+0.0000j,  0.6150+0.0000j,&#10;          0.9025+0.0000j],&#10;        [-0.0346-0.2657j, -0.0585+0.0462j, -0.2839+0.1043j,  0.6409-0.0204j,&#10;         -0.2639+0.1357j],&#10;        [-0.1854+0.2824j,  0.0171-0.0018j, -0.4731+0.0348j,  0.1742+0.1537j,&#10;          0.4672-0.4692j],&#10;        [-0.0973-0.1875j, -0.0590-0.0726j, -0.0637+0.3307j, -0.3183-0.1395j,&#10;          0.5383+0.0688j],&#10;        [-0.4660+0.0994j,  0.4587+0.3210j, -0.0157+0.2454j, -0.0194-0.5373j,&#10;          0.0424-0.1286j],&#10;        [-0.0346+0.2657j, -0.0585-0.0462j, -0.2839-0.1043j,  0.6409+0.0204j,&#10;         -0.2639-0.1357j],&#10;        [ 0.3742+0.0000j,  0.5334+0.0000j,  0.3264+0.0000j,  0.6685+0.0000j,&#10;          0.0976+0.0000j],&#10;        [-0.3577-0.3076j, -0.1039-0.0661j,  0.4923+0.1407j,  0.1764+0.1659j,&#10;         -0.2071+0.0670j],&#10;        [ 0.2771-0.1010j,  0.0094+0.6693j,  0.1876-0.3114j, -0.3270-0.1559j,&#10;         -0.1471-0.1010j],&#10;        [ 0.3637-0.4781j, -0.1292-0.0058j,  0.0822+0.3769j, -0.1385-0.1370j,&#10;         -0.1782+0.2439j],&#10;        [-0.1854-0.2824j,  0.0171+0.0018j, -0.4731-0.0348j,  0.1742-0.1537j,&#10;          0.4672+0.4692j],&#10;        [-0.3577+0.3076j, -0.1039+0.0661j,  0.4923-0.1407j,  0.1764-0.1659j,&#10;         -0.2071-0.0670j],&#10;        [ 0.5948+0.0000j,  0.0284+0.0000j,  0.8032+0.0000j,  0.0878+0.0000j,&#10;          0.4858+0.0000j],&#10;        [-0.1819+0.3243j, -0.0847-0.1293j,  0.1487-0.5505j, -0.1250+0.0400j,&#10;          0.2429+0.3155j],&#10;        [-0.3719-0.0521j,  0.4109-0.5700j, -0.2431+0.1261j,  0.1348+0.2583j,&#10;          0.0693+0.2377j],&#10;        [-0.0973+0.1875j, -0.0590+0.0726j, -0.0637-0.3307j, -0.3183+0.1395j,&#10;          0.5383-0.0688j],&#10;        [ 0.2771+0.1010j,  0.0094-0.6693j,  0.1876+0.3114j, -0.3270+0.1559j,&#10;         -0.1471+0.1010j],&#10;        [-0.1819-0.3243j, -0.0847+0.1293j,  0.1487+0.5505j, -0.1250-0.0400j,&#10;          0.2429-0.3155j],&#10;        [ 0.2324+0.0000j,  0.8400+0.0000j,  0.4049+0.0000j,  0.1963+0.0000j,&#10;          0.3263+0.0000j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 1.019707469700251.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 26, in test_fn_grad
    self._grad_test_helper(device, dtype, op, op.get_op())
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4372, in _grad_test_helper
    return self._check_helper(device, dtype, op, variant, 'gradcheck', check_forward_ad=check_forward_ad,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4341, in _check_helper
    self.assertTrue(gradcheck(fn, gradcheck_args,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3896, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1163, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.3990-0.1056j, dtype=torch.complex128)
analytical:tensor(0.7521-0.0346j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0202+0.0000e+00j,  0.2888+0.0000e+00j, -0.4259+0.0000e+00j,
          0.0023+0.0000e+00j, -0.5525+0.0000e+00j],
        [ 0.1746-2.5466e-01j, -0.0333+7.0177e-02j, -0.5365+2.6133e-01j,
         -0.4325+2.3378e-01j,  0.1053-1.9071e-01j],
        [-0.7213-2.4699e-01j,  0.3124-4.1262e-01j,  0.7561-8.6546e-01j,
          0.1952+2.6030e-01j, -0.0758-1.5681e-01j],
        [ 0.2911+8.5448e-01j, -0.2082+1.8356e-01j,  0.1499-1.6156e-01j,
         -0.2664+2.2936e-01j, -0.2817+2.3091e-01j],
        [-0.5040+6.5719e-02j,  0.3375+5.9683e-01j,  0.1650+5.9426e-02j,
          0.2865-2.0423e-01j,  0.1468-1.5021e-01j],
        [ 0.1746+2.5466e-01j, -0.0333-7.0177e-02j, -0.5365-2.6133e-01j,
         -0.4325-2.3378e-01j,  0.1053+1.9071e-01j],
        [ 0.1588+0.0000e+00j, -0.0451+0.0000e+00j,  0.3203+0.0000e+00j,
          0.4820+0.0000e+00j,  0.6604+0.0000e+00j],
        [-0.1669-3.6367e-01j, -0.0643-1.7582e-03j, -0.8777-2.2834e-02j,
          0.2214-2.2282e-01j, -0.2991+9.1943e-04j],
        [-0.0575+1.8015e-01j,  0.0456-4.3202e-02j,  0.0083-7.8788e-02j,
          0.6243+2.8269e-01j,  0.6265-6.4893e-01j],
        [ 0.0432+4.8867e-02j,  0.0205+4.9290e-02j,  0.2016+8.2021e-01j,
         -0.0450+1.8569e-02j,  0.6356+3.1921e-01j],
        [-0.7213+2.4699e-01j,  0.3124+4.1262e-01j,  0.7561+8.6546e-01j,
          0.1952-2.6030e-01j, -0.0758+1.5681e-01j],
        [-0.1669+3.6367e-01j, -0.0643+1.7582e-03j, -0.8777+2.2834e-02j,
          0.2214+2.2282e-01j, -0.2991-9.1943e-04j],
        [ 0.4669+0.0000e+00j,  0.4948+0.0000e+00j,  1.2889+0.0000e+00j,
          1.1115+0.0000e+00j,  0.3293+0.0000e+00j],
        [-0.3685-1.1092e-01j, -0.1280+4.7656e-02j,  0.8396-4.6199e-02j,
          0.4707+2.0184e-01j, -0.1525+3.0488e-01j],
        [ 0.5194-3.2356e-01j,  0.1062+5.4941e-01j,  0.1868-5.4443e-01j,
         -0.2559-3.3784e-01j, -0.0965-2.7128e-01j],
        [ 0.2911-8.5448e-01j, -0.2082-1.8356e-01j,  0.1499+1.6156e-01j,
         -0.2664-2.2936e-01j, -0.2817-2.3091e-01j],
        [-0.0575-1.8015e-01j,  0.0456+4.3202e-02j,  0.0083+7.8788e-02j,
          0.6243-2.8269e-01j,  0.6265+6.4893e-01j],
        [-0.3685+1.1092e-01j, -0.1280-4.7656e-02j,  0.8396+4.6199e-02j,
          0.4707-2.0184e-01j, -0.1525-3.0488e-01j],
        [ 0.4287+0.0000e+00j,  0.0268+0.0000e+00j,  0.0075+0.0000e+00j,
          0.0195+0.0000e+00j,  0.3307+0.0000e+00j],
        [-0.4244+2.3993e-01j, -0.2338-2.2296e-01j, -0.7383-1.0534e+00j,
         -0.6087+7.4201e-02j, -0.1313+1.0581e-01j],
        [-0.5040-6.5719e-02j,  0.3375-5.9683e-01j,  0.1650-5.9426e-02j,
          0.2865+2.0423e-01j,  0.1468+1.5021e-01j],
        [ 0.0432-4.8867e-02j,  0.0205-4.9290e-02j,  0.2016-8.2021e-01j,
         -0.0450-1.8569e-02j,  0.6356-3.1921e-01j],
        [ 0.5194+3.2356e-01j,  0.1062-5.4941e-01j,  0.1868+5.4443e-01j,
         -0.2559+3.3784e-01j, -0.0965+2.7128e-01j],
        [-0.4244-2.3993e-01j, -0.2338+2.2296e-01j, -0.7383+1.0534e+00j,
         -0.6087-7.4201e-02j, -0.1313-1.0581e-01j],
        [ 0.2324+0.0000e+00j,  0.8400+0.0000e+00j,  0.4049+0.0000e+00j,
          0.1963+0.0000e+00j,  0.3263+0.0000e+00j]], dtype=torch.complex128)
Analytical:
tensor([[ 0.6067+0.0000j,  0.5878+0.0000j,  0.1853+0.0000j,  0.4324+0.0000j,
          0.1878+0.0000j],
        [ 0.1136-0.3217j, -0.0781-0.0045j, -0.0647+0.2185j, -0.0350+0.5145j,
          0.0642-0.4067j],
        [-0.4660-0.0994j,  0.4587-0.3210j, -0.0157-0.2454j, -0.0194+0.5373j,
          0.0424+0.1286j],
        [ 0.3637+0.4781j, -0.1292+0.0058j,  0.0822-0.3769j, -0.1385+0.1370j,
         -0.1782-0.2439j],
        [-0.3719+0.0521j,  0.4109+0.5700j, -0.2431-0.1261j,  0.1348-0.2583j,
          0.0693-0.2377j],
        [ 0.1136+0.3217j, -0.0781+0.0045j, -0.0647-0.2185j, -0.0350-0.5145j,
          0.0642+0.4067j],
        [ 0.1919+0.0000j,  0.0104+0.0000j,  0.2802+0.0000j,  0.6150+0.0000j,
          0.9025+0.0000j],
        [-0.0346-0.2657j, -0.0585+0.0462j, -0.2839+0.1043j,  0.6409-0.0204j,
         -0.2639+0.1357j],
        [-0.1854+0.2824j,  0.0171-0.0018j, -0.4731+0.0348j,  0.1742+0.1537j,
          0.4672-0.4692j],
        [-0.0973-0.1875j, -0.0590-0.0726j, -0.0637+0.3307j, -0.3183-0.1395j,
          0.5383+0.0688j],
        [-0.4660+0.0994j,  0.4587+0.3210j, -0.0157+0.2454j, -0.0194-0.5373j,
          0.0424-0.1286j],
        [-0.0346+0.2657j, -0.0585-0.0462j, -0.2839-0.1043j,  0.6409+0.0204j,
         -0.2639-0.1357j],
        [ 0.3742+0.0000j,  0.5334+0.0000j,  0.3264+0.0000j,  0.6685+0.0000j,
          0.0976+0.0000j],
        [-0.3577-0.3076j, -0.1039-0.0661j,  0.4923+0.1407j,  0.1764+0.1659j,
         -0.2071+0.0670j],
        [ 0.2771-0.1010j,  0.0094+0.6693j,  0.1876-0.3114j, -0.3270-0.1559j,
         -0.1471-0.1010j],
        [ 0.3637-0.4781j, -0.1292-0.0058j,  0.0822+0.3769j, -0.1385-0.1370j,
         -0.1782+0.2439j],
        [-0.1854-0.2824j,  0.0171+0.0018j, -0.4731-0.0348j,  0.1742-0.1537j,
          0.4672+0.4692j],
        [-0.3577+0.3076j, -0.1039+0.0661j,  0.4923-0.1407j,  0.1764-0.1659j,
         -0.2071-0.0670j],
        [ 0.5948+0.0000j,  0.0284+0.0000j,  0.8032+0.0000j,  0.0878+0.0000j,
          0.4858+0.0000j],
        [-0.1819+0.3243j, -0.0847-0.1293j,  0.1487-0.5505j, -0.1250+0.0400j,
          0.2429+0.3155j],
        [-0.3719-0.0521j,  0.4109-0.5700j, -0.2431+0.1261j,  0.1348+0.2583j,
          0.0693+0.2377j],
        [-0.0973+0.1875j, -0.0590+0.0726j, -0.0637-0.3307j, -0.3183+0.1395j,
          0.5383-0.0688j],
        [ 0.2771+0.1010j,  0.0094-0.6693j,  0.1876+0.3114j, -0.3270+0.1559j,
         -0.1471+0.1010j],
        [-0.1819-0.3243j, -0.0847+0.1293j,  0.1487+0.5505j, -0.1250-0.0400j,
          0.2429-0.3155j],
        [ 0.2324+0.0000j,  0.8400+0.0000j,  0.4049+0.0000j,  0.1963+0.0000j,
          0.3263+0.0000j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 1.019707469700251.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_eigvalsh_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_householder_product_cpu_complex128" time="0.199" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_householder_product_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_inv_cpu_complex128" time="0.121" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_inv_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_inv_ex_cpu_complex128" time="0.097" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_inv_ex_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_ldl_factor_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_ldl_factor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_ldl_factor_ex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_ldl_factor_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_ldl_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_ldl_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lstsq_cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lstsq_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lstsq_grad_oriented_cpu_complex128" time="1.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lstsq_grad_oriented_cpu_float64" time="0.206" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lu_cpu_float64" time="0.118" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lu_factor_cpu_float64" time="0.070" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lu_factor_ex_cpu_float64" time="0.067" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_lu_solve_cpu_float64" time="1.087" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_norm_cpu_complex128" time="0.371" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_norm_cpu_float64" time="0.148" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_power_cpu_complex128" time="0.198" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_power_cpu_float64" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_rank_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_rank_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_rank_hermitian_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_matrix_rank_hermitian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_multi_dot_cpu_complex128" time="0.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_multi_dot_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_norm_cpu_complex128" time="0.489" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_norm_cpu_float64" time="0.193" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_norm_subgradients_at_zero_cpu_complex128" time="0.120" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_norm_subgradients_at_zero_cpu_float64" time="0.084" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_pinv_cpu_complex128" time="0.274" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_pinv_cpu_float64" time="0.051" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_pinv_hermitian_cpu_complex128" time="0.077" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(0.0108+0.0115j, dtype=torch.complex128)&#10;analytical:tensor(0.0040+0.0008j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[ 0.0000e+00+0.0000e+00j,  2.4185e-02+0.0000e+00j,&#10;          2.2108e-02+0.0000e+00j, -2.7478e-02+0.0000e+00j,&#10;         -5.1414e-02+0.0000e+00j, -2.4185e-02+0.0000e+00j,&#10;          1.3878e-14+0.0000e+00j,  3.4838e-02+0.0000e+00j,&#10;         -3.4504e-02+0.0000e+00j, -9.7587e-02+0.0000e+00j,&#10;         -2.2108e-02+0.0000e+00j, -3.4838e-02+0.0000e+00j,&#10;         -6.9389e-15+0.0000e+00j,  8.0398e-03+0.0000e+00j,&#10;         -1.5147e-02+0.0000e+00j,  2.7478e-02+0.0000e+00j,&#10;          3.4504e-02+0.0000e+00j, -8.0398e-03+0.0000e+00j,&#10;         -3.4694e-15+0.0000e+00j,  3.7522e-02+0.0000e+00j,&#10;          5.1414e-02+0.0000e+00j,  9.7587e-02+0.0000e+00j,&#10;          1.5147e-02+0.0000e+00j, -3.7522e-02+0.0000e+00j,&#10;          4.3368e-15+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.2534e-01+5.4792e-03j,&#10;          1.2344e-02-2.7246e-02j, -5.1346e-02+3.0802e-02j,&#10;          5.2087e-02+1.0986e-01j, -1.2534e-01-5.4792e-03j,&#10;          2.7756e-14+1.3878e-14j, -2.7025e-01-1.6388e-01j,&#10;          1.5549e-01-5.4318e-02j,  6.4643e-02-8.6568e-02j,&#10;         -1.2344e-02+2.7246e-02j,  2.7025e-01+1.6388e-01j,&#10;          0.0000e+00-3.4694e-15j,  5.2836e-02+8.0600e-02j,&#10;          8.0959e-02-4.1466e-02j,  5.1346e-02-3.0802e-02j,&#10;         -1.5549e-01+5.4318e-02j, -5.2836e-02-8.0600e-02j,&#10;          3.4694e-15-3.4694e-15j, -1.1395e-01-9.8322e-03j,&#10;         -5.2087e-02-1.0986e-01j, -6.4643e-02+8.6568e-02j,&#10;         -8.0959e-02+4.1466e-02j,  1.1395e-01+9.8322e-03j,&#10;         -1.3010e-14-2.1684e-14j],&#10;        [ 0.0000e+00+0.0000e+00j, -2.1127e-02-1.3775e-01j,&#10;         -7.0653e-02-4.5179e-03j,  6.4627e-02+1.3951e-01j,&#10;         -1.4797e-01+6.2596e-02j,  2.1127e-02+1.3775e-01j,&#10;          1.2143e-14+1.3878e-14j,  1.2066e-01+4.7849e-02j,&#10;          1.1351e-02-3.2387e-02j, -7.3993e-03+1.2773e-01j,&#10;          7.0653e-02+4.5179e-03j, -1.2066e-01-4.7849e-02j,&#10;         -3.4694e-15+3.4694e-15j, -5.3122e-02-8.1531e-02j,&#10;         -6.3177e-02+4.0576e-02j, -6.4627e-02-1.3951e-01j,&#10;         -1.1351e-02+3.2387e-02j,  5.3122e-02+8.1531e-02j,&#10;          3.4694e-15+3.4694e-15j,  3.8820e-01-6.8107e-02j,&#10;          1.4797e-01-6.2596e-02j,  7.3993e-03-1.2773e-01j,&#10;          6.3177e-02-4.0576e-02j, -3.8820e-01+6.8107e-02j,&#10;          1.6480e-14+1.7347e-14j],&#10;        [ 0.0000e+00+0.0000e+00j,  2.3711e-02+8.9950e-02j,&#10;         -2.9123e-02+7.6115e-02j,  1.3087e-02-2.7653e-02j,&#10;         -3.2091e-02-1.0933e-01j, -2.3711e-02-8.9950e-02j,&#10;         -1.3878e-14-3.4694e-15j, -3.6351e-02+4.2963e-02j,&#10;          5.7895e-02-4.2211e-02j, -6.8415e-02+3.5458e-02j,&#10;          2.9123e-02-7.6115e-02j,  3.6351e-02-4.2963e-02j,&#10;          0.0000e+00+6.9389e-15j,  6.2486e-02+5.3987e-02j,&#10;          2.1848e-01+5.1598e-02j, -1.3087e-02+2.7653e-02j,&#10;         -5.7895e-02+4.2211e-02j, -6.2486e-02-5.3987e-02j,&#10;         -3.4694e-15-3.4694e-15j,  4.6686e-02-1.0818e-01j,&#10;          3.2091e-02+1.0933e-01j,  6.8415e-02-3.5458e-02j,&#10;         -2.1848e-01-5.1598e-02j, -4.6686e-02+1.0818e-01j,&#10;         -6.9389e-15-5.2042e-15j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.8850e-02-4.1843e-02j,&#10;          4.0606e-02+8.7621e-02j, -6.6075e-03-3.7577e-02j,&#10;         -1.1381e-01-2.0988e-01j,  1.8850e-02+4.1843e-02j,&#10;          0.0000e+00+0.0000e+00j, -5.4406e-02-4.7033e-02j,&#10;          1.2015e-02-3.3954e-02j, -2.7040e-02+1.1824e-01j,&#10;         -4.0606e-02-8.7621e-02j,  5.4406e-02+4.7033e-02j,&#10;          3.4694e-15-3.4694e-15j,  4.8488e-02-1.1741e-01j,&#10;         -1.2292e-01-1.8591e-01j,  6.6075e-03+3.7577e-02j,&#10;         -1.2015e-02+3.3954e-02j, -4.8488e-02+1.1741e-01j,&#10;          3.4694e-15-3.4694e-15j,  1.5616e-01+9.7069e-02j,&#10;          1.1381e-01+2.0988e-01j,  2.7040e-02-1.1824e-01j,&#10;          1.2292e-01+1.8591e-01j, -1.5616e-01-9.7069e-02j,&#10;          2.9490e-14-8.6736e-16j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.2534e-01-5.4792e-03j,&#10;          1.2344e-02+2.7246e-02j, -5.1346e-02-3.0802e-02j,&#10;          5.2087e-02-1.0986e-01j, -1.2534e-01+5.4792e-03j,&#10;          2.7756e-14-1.3878e-14j, -2.7025e-01+1.6388e-01j,&#10;          1.5549e-01+5.4318e-02j,  6.4643e-02+8.6568e-02j,&#10;         -1.2344e-02-2.7246e-02j,  2.7025e-01-1.6388e-01j,&#10;          0.0000e+00+3.4694e-15j,  5.2836e-02-8.0600e-02j,&#10;          8.0959e-02+4.1466e-02j,  5.1346e-02+3.0802e-02j,&#10;         -1.5549e-01-5.4318e-02j, -5.2836e-02+8.0600e-02j,&#10;          3.4694e-15+3.4694e-15j, -1.1395e-01+9.8322e-03j,&#10;         -5.2087e-02+1.0986e-01j, -6.4643e-02-8.6568e-02j,&#10;         -8.0959e-02-4.1466e-02j,  1.1395e-01-9.8322e-03j,&#10;         -1.3010e-14+2.1684e-14j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.9647e-01+0.0000e+00j,&#10;          3.6944e-02+0.0000e+00j,  2.9153e-03+0.0000e+00j,&#10;          3.2298e-03+0.0000e+00j,  1.9647e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -3.0017e-01+0.0000e+00j,&#10;         -2.4747e-02+0.0000e+00j, -1.0378e-01+0.0000e+00j,&#10;         -3.6944e-02+0.0000e+00j,  3.0017e-01+0.0000e+00j,&#10;          3.4694e-15+0.0000e+00j,  1.4353e-01+0.0000e+00j,&#10;          4.7219e-02+0.0000e+00j, -2.9153e-03+0.0000e+00j,&#10;          2.4747e-02+0.0000e+00j, -1.4353e-01+0.0000e+00j,&#10;         -3.4694e-15+0.0000e+00j, -3.3618e-02+0.0000e+00j,&#10;         -3.2298e-03+0.0000e+00j,  1.0378e-01+0.0000e+00j,&#10;         -4.7219e-02+0.0000e+00j,  3.3618e-02+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.1049e-01-8.9766e-02j,&#10;         -1.8417e-02+1.0929e-02j, -3.8467e-02+8.5511e-02j,&#10;         -2.0914e-02-6.2460e-02j,  1.1049e-01+8.9766e-02j,&#10;          0.0000e+00+1.7347e-15j,  2.4702e-02-9.9040e-02j,&#10;         -8.9543e-02-1.6300e-01j,  1.7443e-01+1.6046e-03j,&#10;          1.8417e-02-1.0929e-02j, -2.4702e-02+9.9040e-02j,&#10;          1.7347e-14-6.9389e-15j,  2.1295e-02+2.6183e-02j,&#10;         -1.6405e-02+4.9376e-02j,  3.8467e-02-8.5511e-02j,&#10;          8.9543e-02+1.6300e-01j, -2.1295e-02-2.6183e-02j,&#10;          3.4694e-15+1.3878e-14j, -6.0786e-02+5.1747e-03j,&#10;          2.0914e-02+6.2460e-02j, -1.7443e-01-1.6046e-03j,&#10;          1.6405e-02-4.9376e-02j,  6.0786e-02-5.1747e-03j,&#10;          4.3368e-15-2.6021e-15j],&#10;        [ 0.0000e+00+0.0000e+00j,  9.4690e-02+5.8784e-02j,&#10;         -7.0230e-02+1.2213e-02j, -4.1632e-02-8.7655e-03j,&#10;         -6.3692e-02-2.4691e-02j, -9.4690e-02-5.8784e-02j,&#10;          6.9389e-15+1.5613e-14j,  1.6877e-01+5.1070e-03j,&#10;          2.7717e-02-7.0114e-02j,  5.4621e-02-3.4658e-03j,&#10;          7.0230e-02-1.2213e-02j, -1.6877e-01-5.1070e-03j,&#10;         -3.4694e-15+1.0408e-14j, -1.0933e-03-1.1128e-02j,&#10;         -5.8889e-02-6.2365e-02j,  4.1632e-02+8.7655e-03j,&#10;         -2.7717e-02+7.0114e-02j,  1.0933e-03+1.1128e-02j,&#10;          3.4694e-15+0.0000e+00j,  2.9731e-02-8.1489e-02j,&#10;          6.3692e-02+2.4691e-02j, -5.4621e-02+3.4658e-03j,&#10;          5.8889e-02+6.2365e-02j, -2.9731e-02+8.1489e-02j,&#10;          6.0715e-15-9.5410e-15j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.8532e-01-3.0080e-02j,&#10;          8.4701e-02+9.4624e-02j, -6.0144e-02+5.7607e-03j,&#10;          7.7787e-02-2.7179e-02j, -1.8532e-01+3.0080e-02j,&#10;          0.0000e+00-1.5613e-14j, -2.1639e-01+1.1039e-01j,&#10;         -3.6814e-03-1.1197e-01j, -1.8773e-02+1.1194e-01j,&#10;         -8.4701e-02-9.4624e-02j,  2.1639e-01-1.1039e-01j,&#10;          1.0408e-14-3.4694e-15j,  5.2729e-02-7.4484e-02j,&#10;          1.8518e-02+5.0199e-02j,  6.0144e-02-5.7607e-03j,&#10;          3.6814e-03+1.1197e-01j, -5.2729e-02+7.4484e-02j,&#10;          0.0000e+00-1.0408e-14j, -6.7874e-02+9.8892e-02j,&#10;         -7.7787e-02+2.7179e-02j,  1.8773e-02-1.1194e-01j,&#10;         -1.8518e-02-5.0199e-02j,  6.7874e-02-9.8892e-02j,&#10;          0.0000e+00+1.4745e-14j],&#10;        [ 0.0000e+00+0.0000e+00j, -2.1127e-02+1.3775e-01j,&#10;         -7.0653e-02+4.5179e-03j,  6.4627e-02-1.3951e-01j,&#10;         -1.4797e-01-6.2596e-02j,  2.1127e-02-1.3775e-01j,&#10;          1.2143e-14-1.3878e-14j,  1.2066e-01-4.7849e-02j,&#10;          1.1351e-02+3.2387e-02j, -7.3993e-03-1.2773e-01j,&#10;          7.0653e-02-4.5179e-03j, -1.2066e-01+4.7849e-02j,&#10;         -3.4694e-15-3.4694e-15j, -5.3122e-02+8.1531e-02j,&#10;         -6.3177e-02-4.0576e-02j, -6.4627e-02+1.3951e-01j,&#10;         -1.1351e-02-3.2387e-02j,  5.3122e-02-8.1531e-02j,&#10;          3.4694e-15-3.4694e-15j,  3.8820e-01+6.8107e-02j,&#10;          1.4797e-01+6.2596e-02j,  7.3993e-03+1.2773e-01j,&#10;          6.3177e-02+4.0576e-02j, -3.8820e-01-6.8107e-02j,&#10;          1.6480e-14-1.7347e-14j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.1049e-01+8.9766e-02j,&#10;         -1.8417e-02-1.0929e-02j, -3.8467e-02-8.5511e-02j,&#10;         -2.0914e-02+6.2460e-02j,  1.1049e-01-8.9766e-02j,&#10;          0.0000e+00-1.7347e-15j,  2.4702e-02+9.9040e-02j,&#10;         -8.9543e-02+1.6300e-01j,  1.7443e-01-1.6046e-03j,&#10;          1.8417e-02+1.0929e-02j, -2.4702e-02-9.9040e-02j,&#10;          1.7347e-14+6.9389e-15j,  2.1295e-02-2.6183e-02j,&#10;         -1.6405e-02-4.9376e-02j,  3.8467e-02+8.5511e-02j,&#10;          8.9543e-02-1.6300e-01j, -2.1295e-02+2.6183e-02j,&#10;          3.4694e-15-1.3878e-14j, -6.0786e-02-5.1747e-03j,&#10;          2.0914e-02-6.2460e-02j, -1.7443e-01+1.6046e-03j,&#10;          1.6405e-02+4.9376e-02j,  6.0786e-02+5.1747e-03j,&#10;          4.3368e-15+2.6021e-15j],&#10;        [ 0.0000e+00+0.0000e+00j,  7.3858e-02+0.0000e+00j,&#10;         -3.4152e-02+0.0000e+00j, -1.5022e-01+0.0000e+00j,&#10;          5.6199e-02+0.0000e+00j, -7.3858e-02+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -3.8496e-02+0.0000e+00j,&#10;         -2.0765e-03+0.0000e+00j,  6.6066e-02+0.0000e+00j,&#10;          3.4152e-02+0.0000e+00j,  3.8496e-02+0.0000e+00j,&#10;         -1.3878e-14+0.0000e+00j,  4.5471e-03+0.0000e+00j,&#10;          5.8472e-02+0.0000e+00j,  1.5022e-01+0.0000e+00j,&#10;          2.0765e-03+0.0000e+00j, -4.5471e-03+0.0000e+00j,&#10;          1.0408e-14+0.0000e+00j, -1.2826e-01+0.0000e+00j,&#10;         -5.6199e-02+0.0000e+00j, -6.6066e-02+0.0000e+00j,&#10;         -5.8472e-02+0.0000e+00j,  1.2826e-01+0.0000e+00j,&#10;         -3.4694e-15+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -9.2220e-02-4.6866e-02j,&#10;         -4.0561e-02-1.2922e-02j,  2.7880e-02+3.6133e-02j,&#10;         -5.7898e-02-1.1198e-01j,  9.2220e-02+4.6866e-02j,&#10;         -8.6736e-16+0.0000e+00j,  1.9090e-01+6.1904e-02j,&#10;          1.8668e-02+1.2074e-02j, -2.3069e-02+2.1950e-02j,&#10;          4.0561e-02+1.2922e-02j, -1.9090e-01-6.1904e-02j,&#10;          1.0408e-14-3.4694e-15j, -1.7523e-01+5.1556e-02j,&#10;          3.5944e-02-1.2803e-02j, -2.7880e-02-3.6133e-02j,&#10;         -1.8668e-02-1.2074e-02j,  1.7523e-01-5.1556e-02j,&#10;         -6.9389e-15-1.0408e-14j,  2.3236e-01-1.5847e-01j,&#10;          5.7898e-02+1.1198e-01j,  2.3069e-02-2.1950e-02j,&#10;         -3.5944e-02+1.2803e-02j, -2.3236e-01+1.5847e-01j,&#10;          3.4694e-15-4.3368e-15j],&#10;        [ 0.0000e+00+0.0000e+00j, -8.8142e-02-1.1636e-01j,&#10;          7.9055e-02+7.3960e-02j,  8.2109e-02+7.3500e-02j,&#10;          6.4162e-03-1.5509e-01j,  8.8142e-02+1.1636e-01j,&#10;         -1.3878e-14+1.3878e-14j,  3.9992e-02+3.0838e-02j,&#10;         -7.3964e-02-9.2800e-02j,  5.2277e-02+1.2231e-01j,&#10;         -7.9055e-02-7.3960e-02j, -3.9992e-02-3.0838e-02j,&#10;          3.4694e-15+0.0000e+00j,  1.5790e-01+6.7970e-02j,&#10;         -1.1784e-01-1.1086e-01j, -8.2109e-02-7.3500e-02j,&#10;          7.3964e-02+9.2800e-02j, -1.5790e-01-6.7970e-02j,&#10;          6.9389e-15+0.0000e+00j,  1.1975e-02-2.9938e-02j,&#10;         -6.4162e-03+1.5509e-01j, -5.2277e-02-1.2231e-01j,&#10;          1.1784e-01+1.1086e-01j, -1.1975e-02+2.9938e-02j,&#10;          0.0000e+00-1.4745e-14j],&#10;        [ 0.0000e+00+0.0000e+00j,  2.3711e-02-8.9950e-02j,&#10;         -2.9123e-02-7.6115e-02j,  1.3087e-02+2.7653e-02j,&#10;         -3.2091e-02+1.0933e-01j, -2.3711e-02+8.9950e-02j,&#10;         -1.3878e-14+3.4694e-15j, -3.6351e-02-4.2963e-02j,&#10;          5.7895e-02+4.2211e-02j, -6.8415e-02-3.5458e-02j,&#10;          2.9123e-02+7.6115e-02j,  3.6351e-02+4.2963e-02j,&#10;          0.0000e+00-6.9389e-15j,  6.2486e-02-5.3987e-02j,&#10;          2.1848e-01-5.1598e-02j, -1.3087e-02-2.7653e-02j,&#10;         -5.7895e-02-4.2211e-02j, -6.2486e-02+5.3987e-02j,&#10;         -3.4694e-15+3.4694e-15j,  4.6686e-02+1.0818e-01j,&#10;          3.2091e-02-1.0933e-01j,  6.8415e-02+3.5458e-02j,&#10;         -2.1848e-01+5.1598e-02j, -4.6686e-02-1.0818e-01j,&#10;         -6.9389e-15+5.2042e-15j],&#10;        [ 0.0000e+00+0.0000e+00j,  9.4690e-02-5.8784e-02j,&#10;         -7.0230e-02-1.2213e-02j, -4.1632e-02+8.7655e-03j,&#10;         -6.3692e-02+2.4691e-02j, -9.4690e-02+5.8784e-02j,&#10;          6.9389e-15-1.5613e-14j,  1.6877e-01-5.1070e-03j,&#10;          2.7717e-02+7.0114e-02j,  5.4621e-02+3.4658e-03j,&#10;          7.0230e-02+1.2213e-02j, -1.6877e-01+5.1070e-03j,&#10;         -3.4694e-15-1.0408e-14j, -1.0933e-03+1.1128e-02j,&#10;         -5.8889e-02+6.2365e-02j,  4.1632e-02-8.7655e-03j,&#10;         -2.7717e-02-7.0114e-02j,  1.0933e-03-1.1128e-02j,&#10;          3.4694e-15+0.0000e+00j,  2.9731e-02+8.1489e-02j,&#10;          6.3692e-02-2.4691e-02j, -5.4621e-02-3.4658e-03j,&#10;          5.8889e-02-6.2365e-02j, -2.9731e-02-8.1489e-02j,&#10;          6.0715e-15+9.5410e-15j],&#10;        [ 0.0000e+00+0.0000e+00j, -9.2220e-02+4.6866e-02j,&#10;         -4.0561e-02+1.2922e-02j,  2.7880e-02-3.6133e-02j,&#10;         -5.7898e-02+1.1198e-01j,  9.2220e-02-4.6866e-02j,&#10;         -8.6736e-16+0.0000e+00j,  1.9090e-01-6.1904e-02j,&#10;          1.8668e-02-1.2074e-02j, -2.3069e-02-2.1950e-02j,&#10;          4.0561e-02-1.2922e-02j, -1.9090e-01+6.1904e-02j,&#10;          1.0408e-14+3.4694e-15j, -1.7523e-01-5.1556e-02j,&#10;          3.5944e-02+1.2803e-02j, -2.7880e-02+3.6133e-02j,&#10;         -1.8668e-02+1.2074e-02j,  1.7523e-01+5.1556e-02j,&#10;         -6.9389e-15+1.0408e-14j,  2.3236e-01+1.5847e-01j,&#10;          5.7898e-02-1.1198e-01j,  2.3069e-02+2.1950e-02j,&#10;         -3.5944e-02-1.2803e-02j, -2.3236e-01-1.5847e-01j,&#10;          3.4694e-15+4.3368e-15j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.0824e-01+0.0000e+00j,&#10;          1.2047e-01+0.0000e+00j,  7.5822e-02+0.0000e+00j,&#10;          1.1865e-01+0.0000e+00j, -1.0824e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  6.3181e-02+0.0000e+00j,&#10;          1.7813e-01+0.0000e+00j,  1.2376e-02+0.0000e+00j,&#10;         -1.2047e-01+0.0000e+00j, -6.3181e-02+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -4.4015e-02+0.0000e+00j,&#10;         -1.1136e-04+0.0000e+00j, -7.5822e-02+0.0000e+00j,&#10;         -1.7813e-01+0.0000e+00j,  4.4015e-02+0.0000e+00j,&#10;          3.4694e-15+0.0000e+00j, -1.7683e-01+0.0000e+00j,&#10;         -1.1865e-01+0.0000e+00j, -1.2376e-02+0.0000e+00j,&#10;          1.1136e-04+0.0000e+00j,  1.7683e-01+0.0000e+00j,&#10;          1.3878e-14+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.1528e-01+5.7277e-02j,&#10;          4.0272e-02-1.4201e-01j,  1.7558e-01-3.0177e-02j,&#10;         -1.7120e-02-6.6412e-02j, -1.1528e-01-5.7277e-02j,&#10;         -1.9949e-14-4.1633e-14j, -1.1823e-01+8.9500e-03j,&#10;          6.0147e-03+1.2263e-03j, -1.2874e-01+8.6963e-02j,&#10;         -4.0272e-02+1.4201e-01j,  1.1823e-01-8.9500e-03j,&#10;         -6.9389e-15+1.3878e-14j, -6.5222e-03-6.9675e-02j,&#10;          1.0972e-01-1.8816e-02j, -1.7558e-01+3.0177e-02j,&#10;         -6.0147e-03-1.2263e-03j,  6.5222e-03+6.9675e-02j,&#10;          3.4694e-15-3.4694e-15j,  1.5384e-01+4.6781e-02j,&#10;          1.7120e-02+6.6412e-02j,  1.2874e-01-8.6963e-02j,&#10;         -1.0972e-01+1.8816e-02j, -1.5384e-01-4.6781e-02j,&#10;          1.4745e-14+1.4745e-14j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.8850e-02+4.1843e-02j,&#10;          4.0606e-02-8.7621e-02j, -6.6075e-03+3.7577e-02j,&#10;         -1.1381e-01+2.0988e-01j,  1.8850e-02-4.1843e-02j,&#10;          0.0000e+00+0.0000e+00j, -5.4406e-02+4.7033e-02j,&#10;          1.2015e-02+3.3954e-02j, -2.7040e-02-1.1824e-01j,&#10;         -4.0606e-02+8.7621e-02j,  5.4406e-02-4.7033e-02j,&#10;          3.4694e-15+3.4694e-15j,  4.8488e-02+1.1741e-01j,&#10;         -1.2292e-01+1.8591e-01j,  6.6075e-03-3.7577e-02j,&#10;         -1.2015e-02-3.3954e-02j, -4.8488e-02-1.1741e-01j,&#10;          3.4694e-15+3.4694e-15j,  1.5616e-01-9.7069e-02j,&#10;          1.1381e-01-2.0988e-01j,  2.7040e-02+1.1824e-01j,&#10;          1.2292e-01-1.8591e-01j, -1.5616e-01+9.7069e-02j,&#10;          2.9490e-14+8.6736e-16j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.8532e-01+3.0080e-02j,&#10;          8.4701e-02-9.4624e-02j, -6.0144e-02-5.7607e-03j,&#10;          7.7787e-02+2.7179e-02j, -1.8532e-01-3.0080e-02j,&#10;          0.0000e+00+1.5613e-14j, -2.1639e-01-1.1039e-01j,&#10;         -3.6814e-03+1.1197e-01j, -1.8773e-02-1.1194e-01j,&#10;         -8.4701e-02+9.4624e-02j,  2.1639e-01+1.1039e-01j,&#10;          1.0408e-14+3.4694e-15j,  5.2729e-02+7.4484e-02j,&#10;          1.8518e-02-5.0199e-02j,  6.0144e-02+5.7607e-03j,&#10;          3.6814e-03-1.1197e-01j, -5.2729e-02-7.4484e-02j,&#10;          0.0000e+00+1.0408e-14j, -6.7874e-02-9.8892e-02j,&#10;         -7.7787e-02-2.7179e-02j,  1.8773e-02+1.1194e-01j,&#10;         -1.8518e-02+5.0199e-02j,  6.7874e-02+9.8892e-02j,&#10;          0.0000e+00-1.4745e-14j],&#10;        [ 0.0000e+00+0.0000e+00j, -8.8142e-02+1.1636e-01j,&#10;          7.9055e-02-7.3960e-02j,  8.2109e-02-7.3500e-02j,&#10;          6.4162e-03+1.5509e-01j,  8.8142e-02-1.1636e-01j,&#10;         -1.3878e-14-1.3878e-14j,  3.9992e-02-3.0838e-02j,&#10;         -7.3964e-02+9.2800e-02j,  5.2277e-02-1.2231e-01j,&#10;         -7.9055e-02+7.3960e-02j, -3.9992e-02+3.0838e-02j,&#10;          3.4694e-15+0.0000e+00j,  1.5790e-01-6.7970e-02j,&#10;         -1.1784e-01+1.1086e-01j, -8.2109e-02+7.3500e-02j,&#10;          7.3964e-02-9.2800e-02j, -1.5790e-01+6.7970e-02j,&#10;          6.9389e-15+0.0000e+00j,  1.1975e-02+2.9938e-02j,&#10;         -6.4162e-03-1.5509e-01j, -5.2277e-02+1.2231e-01j,&#10;          1.1784e-01-1.1086e-01j, -1.1975e-02-2.9938e-02j,&#10;          0.0000e+00+1.4745e-14j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.1528e-01-5.7277e-02j,&#10;          4.0272e-02+1.4201e-01j,  1.7558e-01+3.0177e-02j,&#10;         -1.7120e-02+6.6412e-02j, -1.1528e-01+5.7277e-02j,&#10;         -1.9949e-14+4.1633e-14j, -1.1823e-01-8.9500e-03j,&#10;          6.0147e-03-1.2263e-03j, -1.2874e-01-8.6963e-02j,&#10;         -4.0272e-02-1.4201e-01j,  1.1823e-01+8.9500e-03j,&#10;         -6.9389e-15-1.3878e-14j, -6.5222e-03+6.9675e-02j,&#10;          1.0972e-01+1.8816e-02j, -1.7558e-01-3.0177e-02j,&#10;         -6.0147e-03+1.2263e-03j,  6.5222e-03-6.9675e-02j,&#10;          3.4694e-15+3.4694e-15j,  1.5384e-01-4.6781e-02j,&#10;          1.7120e-02-6.6412e-02j,  1.2874e-01+8.6963e-02j,&#10;         -1.0972e-01-1.8816e-02j, -1.5384e-01+4.6781e-02j,&#10;          1.4745e-14-1.4745e-14j],&#10;        [ 0.0000e+00+0.0000e+00j,  6.1134e-02+0.0000e+00j,&#10;         -1.1745e-01+0.0000e+00j,  2.4050e-01+0.0000e+00j,&#10;         -2.3005e-01+0.0000e+00j, -6.1134e-02+0.0000e+00j,&#10;         -3.4694e-15+0.0000e+00j,  8.8855e-02+0.0000e+00j,&#10;         -8.8702e-02+0.0000e+00j,  1.1027e-03+0.0000e+00j,&#10;          1.1745e-01+0.0000e+00j, -8.8855e-02+0.0000e+00j,&#10;         -3.4694e-15+0.0000e+00j,  6.2620e-02+0.0000e+00j,&#10;         -1.2451e-01+0.0000e+00j, -2.4050e-01+0.0000e+00j,&#10;          8.8702e-02+0.0000e+00j, -6.2620e-02+0.0000e+00j,&#10;         -1.0408e-14+0.0000e+00j,  2.6309e-01+0.0000e+00j,&#10;          2.3005e-01+0.0000e+00j, -1.1027e-03+0.0000e+00j,&#10;          1.2451e-01+0.0000e+00j, -2.6309e-01+0.0000e+00j,&#10;          2.6021e-15+0.0000e+00j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 9.4151e-18+0.0000e+00j,  2.4185e-02+0.0000e+00j,&#10;          2.2108e-02+0.0000e+00j, -2.7478e-02+0.0000e+00j,&#10;         -5.1414e-02+0.0000e+00j, -2.4185e-02+0.0000e+00j,&#10;          6.1507e-18+0.0000e+00j,  3.4838e-02+0.0000e+00j,&#10;         -3.4504e-02+0.0000e+00j, -9.7587e-02+0.0000e+00j,&#10;         -2.2108e-02+0.0000e+00j, -3.4838e-02+0.0000e+00j,&#10;         -1.3134e-17+0.0000e+00j,  8.0398e-03+0.0000e+00j,&#10;         -1.5147e-02+0.0000e+00j,  2.7478e-02+0.0000e+00j,&#10;          3.4504e-02+0.0000e+00j, -8.0398e-03+0.0000e+00j,&#10;          1.8727e-18+0.0000e+00j,  3.7522e-02+0.0000e+00j,&#10;          5.1414e-02+0.0000e+00j,  9.7587e-02+0.0000e+00j,&#10;          1.5147e-02+0.0000e+00j, -3.7522e-02+0.0000e+00j,&#10;          2.2577e-17+0.0000e+00j],&#10;        [-1.9082e-17+0.0000e+00j,  4.4597e-02-5.1490e-03j,&#10;          1.5518e-02-4.6360e-02j, -3.7950e-02+1.1778e-02j,&#10;          2.8747e-02+1.0827e-01j, -4.4597e-02+5.1490e-03j,&#10;         -1.3878e-17+3.4694e-18j, -7.5315e-02-1.1588e-02j,&#10;          1.1788e-01+3.1135e-02j,  2.0142e-01-7.3199e-02j,&#10;         -1.5518e-02+4.6360e-02j,  7.5315e-02+1.1588e-02j,&#10;         -6.0715e-18+6.9389e-18j,  6.1024e-03-1.6169e-02j,&#10;          8.3156e-03-8.8745e-02j,  3.7950e-02-1.1778e-02j,&#10;         -1.1788e-01-3.1135e-02j, -6.1024e-03+1.6169e-02j,&#10;          1.0408e-17+1.7347e-17j,  3.1742e-02+9.0681e-02j,&#10;         -2.8747e-02-1.0827e-01j, -2.0142e-01+7.3199e-02j,&#10;         -8.3156e-03+8.8745e-02j, -3.1742e-02-9.0681e-02j,&#10;         -1.3878e-17+1.3878e-17j],&#10;        [ 0.0000e+00+0.0000e+00j, -4.3593e-02-5.7957e-02j,&#10;         -3.0060e-02-2.1465e-02j,  7.2283e-02+1.6159e-01j,&#10;         -1.3125e-01+5.7877e-02j,  4.3593e-02+5.7957e-02j,&#10;          6.9389e-18+0.0000e+00j,  2.4607e-02-2.4344e-02j,&#10;          3.7373e-02+5.9157e-03j,  5.0255e-03+7.1835e-02j,&#10;          3.0060e-02+2.1465e-02j, -2.4607e-02+2.4344e-02j,&#10;          6.9389e-18+5.1174e-17j,  9.4182e-02-1.2057e-02j,&#10;         -3.2556e-02+7.2616e-02j, -7.2283e-02-1.6159e-01j,&#10;         -3.7373e-02-5.9157e-03j, -9.4182e-02+1.2057e-02j,&#10;          0.0000e+00-6.9389e-18j,  1.2473e-01-1.4288e-01j,&#10;          1.3125e-01-5.7877e-02j, -5.0255e-03-7.1835e-02j,&#10;          3.2556e-02-7.2616e-02j, -1.2473e-01+1.4288e-01j,&#10;         -6.9389e-18+0.0000e+00j],&#10;        [ 1.0408e-17-8.6736e-18j, -1.0254e-02+5.1909e-02j,&#10;         -1.4988e-02+7.0141e-02j,  3.2192e-02-2.3254e-02j,&#10;         -7.1570e-02-6.5956e-02j,  1.0254e-02-5.1909e-02j,&#10;         -3.4694e-18-1.3878e-17j,  4.4784e-02+6.6121e-02j,&#10;          2.8896e-02-8.0023e-03j,  5.4034e-02-4.1865e-02j,&#10;          1.4988e-02-7.0141e-02j, -4.4784e-02-6.6121e-02j,&#10;          1.3878e-17-3.4694e-18j,  1.1106e-01+2.9736e-02j,&#10;          1.7417e-01+5.4374e-02j, -3.2192e-02+2.3254e-02j,&#10;         -2.8896e-02+8.0023e-03j, -1.1106e-01-2.9736e-02j,&#10;         -6.9389e-18+1.7347e-18j,  1.6651e-02-1.4813e-02j,&#10;          7.1570e-02+6.5956e-02j, -5.4034e-02+4.1865e-02j,&#10;         -1.7417e-01-5.4374e-02j, -1.6651e-02+1.4813e-02j,&#10;          0.0000e+00+1.2143e-17j],&#10;        [ 0.0000e+00+1.3878e-17j, -3.7573e-02+7.7907e-02j,&#10;          4.6035e-02+6.6814e-02j, -2.1693e-02-4.8489e-02j,&#10;         -9.9979e-02-2.3255e-01j,  3.7573e-02-7.7907e-02j,&#10;          0.0000e+00-6.9389e-18j,  6.0520e-03-1.1633e-01j,&#10;          4.8529e-02+4.3703e-02j, -1.5943e-03+7.8042e-02j,&#10;         -4.6035e-02-6.6814e-02j, -6.0520e-03+1.1633e-01j,&#10;          0.0000e+00+0.0000e+00j,  2.2297e-02-8.6667e-02j,&#10;         -1.2852e-01-1.5376e-01j,  2.1693e-02+4.8489e-02j,&#10;         -4.8529e-02-4.3703e-02j, -2.2297e-02+8.6667e-02j,&#10;          1.3878e-17+3.4694e-18j,  1.3523e-01-4.3699e-02j,&#10;          9.9979e-02+2.3255e-01j,  1.5943e-03-7.8042e-02j,&#10;          1.2852e-01+1.5376e-01j, -1.3523e-01+4.3699e-02j,&#10;          4.1633e-17-6.9389e-17j],&#10;        [-1.9082e-17+0.0000e+00j,  4.4597e-02+5.1490e-03j,&#10;          1.5518e-02+4.6360e-02j, -3.7950e-02-1.1778e-02j,&#10;          2.8747e-02-1.0827e-01j, -4.4597e-02-5.1490e-03j,&#10;         -1.3878e-17-3.4694e-18j, -7.5315e-02+1.1588e-02j,&#10;          1.1788e-01-3.1135e-02j,  2.0142e-01+7.3199e-02j,&#10;         -1.5518e-02-4.6360e-02j,  7.5315e-02-1.1588e-02j,&#10;         -6.0715e-18-6.9389e-18j,  6.1024e-03+1.6169e-02j,&#10;          8.3156e-03+8.8745e-02j,  3.7950e-02+1.1778e-02j,&#10;         -1.1788e-01+3.1135e-02j, -6.1024e-03-1.6169e-02j,&#10;          1.0408e-17-1.7347e-17j,  3.1742e-02-9.0681e-02j,&#10;         -2.8747e-02+1.0827e-01j, -2.0142e-01-7.3199e-02j,&#10;         -8.3156e-03-8.8745e-02j, -3.1742e-02+9.0681e-02j,&#10;         -1.3878e-17-1.3878e-17j],&#10;        [ 6.9389e-18+0.0000e+00j, -1.8958e-01+0.0000e+00j,&#10;         -1.5739e-04+0.0000e+00j, -4.3528e-02+0.0000e+00j,&#10;          3.6484e-02+0.0000e+00j,  1.8958e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.0759e-01+0.0000e+00j,&#10;          9.0444e-02+0.0000e+00j, -1.1793e-01+0.0000e+00j,&#10;          1.5739e-04+0.0000e+00j,  1.0759e-01+0.0000e+00j,&#10;          1.3010e-18+0.0000e+00j,  7.2366e-03+0.0000e+00j,&#10;         -2.1112e-02+0.0000e+00j,  4.3528e-02+0.0000e+00j,&#10;         -9.0444e-02+0.0000e+00j, -7.2366e-03+0.0000e+00j,&#10;         -1.7347e-18+0.0000e+00j, -3.2737e-02+0.0000e+00j,&#10;         -3.6484e-02+0.0000e+00j,  1.1793e-01+0.0000e+00j,&#10;          2.1112e-02+0.0000e+00j,  3.2737e-02+0.0000e+00j,&#10;         -6.9389e-18+0.0000e+00j],&#10;        [-1.3878e-17+0.0000e+00j, -1.0786e-01+1.4100e-02j,&#10;         -1.1987e-02+1.1119e-05j, -3.0054e-02+4.6212e-02j,&#10;          3.2615e-02-8.8762e-02j,  1.0786e-01-1.4100e-02j,&#10;          0.0000e+00+2.6021e-18j, -3.9304e-02-4.3558e-02j,&#10;         -1.6432e-02-2.4273e-02j,  2.0503e-02+2.8073e-02j,&#10;          1.1987e-02-1.1119e-05j,  3.9304e-02+4.3558e-02j,&#10;          1.7347e-18-1.3878e-17j,  2.6494e-02-2.6615e-05j,&#10;          1.6579e-02+4.6121e-02j,  3.0054e-02-4.6212e-02j,&#10;          1.6432e-02+2.4273e-02j, -2.6494e-02+2.6615e-05j,&#10;          1.7347e-17-6.9389e-18j,  9.9819e-03-1.8046e-02j,&#10;         -3.2615e-02+8.8762e-02j, -2.0503e-02-2.8073e-02j,&#10;         -1.6579e-02-4.6121e-02j, -9.9819e-03+1.8046e-02j,&#10;          1.3878e-17-4.1633e-17j],&#10;        [-5.2042e-18+6.9389e-18j,  1.1476e-01+1.5870e-02j,&#10;         -5.2279e-02+1.9017e-02j, -2.1577e-02-1.6481e-02j,&#10;         -5.4579e-02+6.0388e-02j, -1.1476e-01-1.5870e-02j,&#10;         -2.7756e-17+1.2143e-17j,  5.6335e-02-1.0330e-01j,&#10;          2.7058e-02-8.3079e-02j, -3.3456e-02-8.0641e-02j,&#10;          5.2279e-02-1.9017e-02j, -5.6335e-02+1.0330e-01j,&#10;          2.0817e-17-3.4694e-18j,  5.8635e-02+1.4922e-02j,&#10;         -1.7083e-02-3.7584e-02j,  2.1577e-02+1.6481e-02j,&#10;         -2.7058e-02+8.3079e-02j, -5.8635e-02-1.4922e-02j,&#10;         -2.4286e-17-1.3878e-17j, -1.4714e-02-3.4101e-02j,&#10;          5.4579e-02-6.0388e-02j,  3.3456e-02+8.0641e-02j,&#10;          1.7083e-02+3.7584e-02j,  1.4714e-02+3.4101e-02j,&#10;         -6.9389e-18-6.9389e-18j],&#10;        [ 1.3878e-17+1.3878e-17j,  1.8553e-01-7.3818e-02j,&#10;          7.2875e-02+1.1586e-01j, -3.4771e-02-2.5431e-02j,&#10;          3.5099e-02+1.0438e-01j, -1.8553e-01+7.3818e-02j,&#10;         -1.3878e-17+1.3878e-17j, -1.7220e-01+2.6094e-02j,&#10;         -4.3429e-02-7.2823e-02j, -4.2235e-02-2.9622e-03j,&#10;         -7.2875e-02-1.1586e-01j,  1.7220e-01-2.6094e-02j,&#10;         -1.3878e-17-1.3878e-17j,  1.4762e-02-6.2783e-02j,&#10;          7.8392e-03+8.1334e-02j,  3.4771e-02+2.5431e-02j,&#10;          4.3429e-02+7.2823e-02j, -1.4762e-02+6.2783e-02j,&#10;         -1.0408e-17+1.2143e-17j, -1.2245e-02-4.2899e-02j,&#10;         -3.5099e-02-1.0438e-01j,  4.2235e-02+2.9622e-03j,&#10;         -7.8392e-03-8.1334e-02j,  1.2245e-02+4.2899e-02j,&#10;         -1.0408e-17+3.4694e-18j],&#10;        [ 0.0000e+00+0.0000e+00j, -4.3593e-02+5.7957e-02j,&#10;         -3.0060e-02+2.1465e-02j,  7.2283e-02-1.6159e-01j,&#10;         -1.3125e-01-5.7877e-02j,  4.3593e-02-5.7957e-02j,&#10;          6.9389e-18+0.0000e+00j,  2.4607e-02+2.4344e-02j,&#10;          3.7373e-02-5.9157e-03j,  5.0255e-03-7.1835e-02j,&#10;          3.0060e-02-2.1465e-02j, -2.4607e-02-2.4344e-02j,&#10;          6.9389e-18-5.1174e-17j,  9.4182e-02+1.2057e-02j,&#10;         -3.2556e-02-7.2616e-02j, -7.2283e-02+1.6159e-01j,&#10;         -3.7373e-02+5.9157e-03j, -9.4182e-02-1.2057e-02j,&#10;          0.0000e+00+6.9389e-18j,  1.2473e-01+1.4288e-01j,&#10;          1.3125e-01+5.7877e-02j, -5.0255e-03+7.1835e-02j,&#10;          3.2556e-02+7.2616e-02j, -1.2473e-01-1.4288e-01j,&#10;         -6.9389e-18+0.0000e+00j],&#10;        [-1.3878e-17+0.0000e+00j, -1.0786e-01-1.4100e-02j,&#10;         -1.1987e-02-1.1119e-05j, -3.0054e-02-4.6212e-02j,&#10;          3.2615e-02+8.8762e-02j,  1.0786e-01+1.4100e-02j,&#10;          0.0000e+00-2.6021e-18j, -3.9304e-02+4.3558e-02j,&#10;         -1.6432e-02+2.4273e-02j,  2.0503e-02-2.8073e-02j,&#10;          1.1987e-02+1.1119e-05j,  3.9304e-02-4.3558e-02j,&#10;          1.7347e-18+1.3878e-17j,  2.6494e-02+2.6615e-05j,&#10;          1.6579e-02-4.6121e-02j,  3.0054e-02+4.6212e-02j,&#10;          1.6432e-02-2.4273e-02j, -2.6494e-02-2.6615e-05j,&#10;          1.7347e-17+6.9389e-18j,  9.9819e-03+1.8046e-02j,&#10;         -3.2615e-02-8.8762e-02j, -2.0503e-02+2.8073e-02j,&#10;         -1.6579e-02+4.6121e-02j, -9.9819e-03-1.8046e-02j,&#10;          1.3878e-17+4.1633e-17j],&#10;        [-6.9389e-18+0.0000e+00j, -3.2992e-02+0.0000e+00j,&#10;         -6.6083e-02+0.0000e+00j, -9.0341e-02+0.0000e+00j,&#10;         -2.7061e-02+0.0000e+00j,  3.2992e-02+0.0000e+00j,&#10;         -6.9389e-18+0.0000e+00j,  6.7713e-02+0.0000e+00j,&#10;         -9.2829e-02+0.0000e+00j,  8.0577e-02+0.0000e+00j,&#10;          6.6083e-02+0.0000e+00j, -6.7713e-02+0.0000e+00j,&#10;          2.0817e-17+0.0000e+00j,  7.8642e-02+0.0000e+00j,&#10;         -1.8514e-01+0.0000e+00j,  9.0341e-02+0.0000e+00j,&#10;          9.2829e-02+0.0000e+00j, -7.8642e-02+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  1.8803e-01+0.0000e+00j,&#10;          2.7061e-02+0.0000e+00j, -8.0577e-02+0.0000e+00j,&#10;          1.8514e-01+0.0000e+00j, -1.8803e-01+0.0000e+00j,&#10;          1.7347e-17+0.0000e+00j],&#10;        [ 4.3368e-18-6.9389e-18j,  6.8702e-03+7.3241e-03j,&#10;         -4.0615e-02-2.5865e-02j,  2.9369e-03+1.4148e-02j,&#10;         -9.0543e-02-6.9655e-02j, -6.8702e-03-7.3241e-03j,&#10;          2.0600e-18+1.7347e-18j, -1.8620e-02-3.7599e-02j,&#10;          4.0754e-02+2.9696e-02j, -1.0373e-02-6.6466e-02j,&#10;          4.0615e-02+2.5865e-02j,  1.8620e-02+3.7599e-02j,&#10;         -3.4694e-18-6.9389e-18j, -6.0356e-02+5.3712e-02j,&#10;          8.9665e-02+5.2901e-02j, -2.9369e-03-1.4148e-02j,&#10;         -4.0754e-02-2.9696e-02j,  6.0356e-02-5.3712e-02j,&#10;          1.3878e-17-1.3878e-17j, -1.2334e-02-9.3802e-02j,&#10;          9.0543e-02+6.9655e-02j,  1.0373e-02+6.6466e-02j,&#10;         -8.9665e-02-5.2901e-02j,  1.2334e-02+9.3802e-02j,&#10;         -1.3878e-17+1.7347e-17j],&#10;        [ 3.4694e-18+1.3878e-17j,  1.0497e-02-9.2706e-02j,&#10;          4.5012e-02+6.2518e-02j,  7.1832e-02+4.8118e-02j,&#10;         -9.9208e-02-1.6916e-01j, -1.0497e-02+9.2706e-02j,&#10;          3.4694e-18+0.0000e+00j,  1.2097e-02+6.4037e-02j,&#10;         -8.2413e-02-3.1812e-02j,  1.2173e-01+4.2776e-02j,&#10;         -4.5012e-02-6.2518e-02j, -1.2097e-02-6.4037e-02j,&#10;          3.4694e-18+0.0000e+00j,  1.4039e-01+2.4822e-02j,&#10;         -1.1078e-01-1.5962e-01j, -7.1832e-02-4.8118e-02j,&#10;          8.2413e-02+3.1812e-02j, -1.4039e-01-2.4822e-02j,&#10;         -6.9389e-18+0.0000e+00j, -5.3048e-03+1.6784e-01j,&#10;          9.9208e-02+1.6916e-01j, -1.2173e-01-4.2776e-02j,&#10;          1.1078e-01+1.5962e-01j,  5.3048e-03-1.6784e-01j,&#10;         -5.5511e-17+1.0408e-17j],&#10;        [ 1.0408e-17+8.6736e-18j, -1.0254e-02-5.1909e-02j,&#10;         -1.4988e-02-7.0141e-02j,  3.2192e-02+2.3254e-02j,&#10;         -7.1570e-02+6.5956e-02j,  1.0254e-02+5.1909e-02j,&#10;         -3.4694e-18+1.3878e-17j,  4.4784e-02-6.6121e-02j,&#10;          2.8896e-02+8.0023e-03j,  5.4034e-02+4.1865e-02j,&#10;          1.4988e-02+7.0141e-02j, -4.4784e-02+6.6121e-02j,&#10;          1.3878e-17+3.4694e-18j,  1.1106e-01-2.9736e-02j,&#10;          1.7417e-01-5.4374e-02j, -3.2192e-02-2.3254e-02j,&#10;         -2.8896e-02-8.0023e-03j, -1.1106e-01+2.9736e-02j,&#10;         -6.9389e-18-1.7347e-18j,  1.6651e-02+1.4813e-02j,&#10;          7.1570e-02-6.5956e-02j, -5.4034e-02-4.1865e-02j,&#10;         -1.7417e-01+5.4374e-02j, -1.6651e-02-1.4813e-02j,&#10;          0.0000e+00-1.2143e-17j],&#10;        [-5.2042e-18-6.9389e-18j,  1.1476e-01-1.5870e-02j,&#10;         -5.2279e-02-1.9017e-02j, -2.1577e-02+1.6481e-02j,&#10;         -5.4579e-02-6.0388e-02j, -1.1476e-01+1.5870e-02j,&#10;         -2.7756e-17-1.2143e-17j,  5.6335e-02+1.0330e-01j,&#10;          2.7058e-02+8.3079e-02j, -3.3456e-02+8.0641e-02j,&#10;          5.2279e-02+1.9017e-02j, -5.6335e-02-1.0330e-01j,&#10;          2.0817e-17+3.4694e-18j,  5.8635e-02-1.4922e-02j,&#10;         -1.7083e-02+3.7584e-02j,  2.1577e-02-1.6481e-02j,&#10;         -2.7058e-02-8.3079e-02j, -5.8635e-02+1.4922e-02j,&#10;         -2.4286e-17+1.3878e-17j, -1.4714e-02+3.4101e-02j,&#10;          5.4579e-02+6.0388e-02j,  3.3456e-02-8.0641e-02j,&#10;          1.7083e-02-3.7584e-02j,  1.4714e-02-3.4101e-02j,&#10;         -6.9389e-18+6.9389e-18j],&#10;        [ 4.3368e-18+6.9389e-18j,  6.8702e-03-7.3241e-03j,&#10;         -4.0615e-02+2.5865e-02j,  2.9369e-03-1.4148e-02j,&#10;         -9.0543e-02+6.9655e-02j, -6.8702e-03+7.3241e-03j,&#10;          2.0600e-18-1.7347e-18j, -1.8620e-02+3.7599e-02j,&#10;          4.0754e-02-2.9696e-02j, -1.0373e-02+6.6466e-02j,&#10;          4.0615e-02-2.5865e-02j,  1.8620e-02-3.7599e-02j,&#10;         -3.4694e-18+6.9389e-18j, -6.0356e-02-5.3712e-02j,&#10;          8.9665e-02-5.2901e-02j, -2.9369e-03+1.4148e-02j,&#10;         -4.0754e-02+2.9696e-02j,  6.0356e-02+5.3712e-02j,&#10;          1.3878e-17+1.3878e-17j, -1.2334e-02+9.3802e-02j,&#10;          9.0543e-02-6.9655e-02j,  1.0373e-02-6.6466e-02j,&#10;         -8.9665e-02+5.2901e-02j,  1.2334e-02-9.3802e-02j,&#10;         -1.3878e-17-1.7347e-17j],&#10;        [ 1.0408e-17+0.0000e+00j,  8.0146e-03+0.0000e+00j,&#10;          1.2755e-01+0.0000e+00j,  8.0794e-02+0.0000e+00j,&#10;          1.1286e-01+0.0000e+00j, -8.0146e-03+0.0000e+00j,&#10;          3.1442e-18+0.0000e+00j,  7.8845e-02+0.0000e+00j,&#10;          3.7743e-02+0.0000e+00j,  8.6193e-02+0.0000e+00j,&#10;         -1.2755e-01+0.0000e+00j, -7.8845e-02+0.0000e+00j,&#10;          2.6021e-18+0.0000e+00j, -4.3793e-02+0.0000e+00j,&#10;         -6.3452e-02+0.0000e+00j, -8.0794e-02+0.0000e+00j,&#10;         -3.7743e-02+0.0000e+00j,  4.3793e-02+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -7.1973e-02+0.0000e+00j,&#10;         -1.1286e-01+0.0000e+00j, -8.6193e-02+0.0000e+00j,&#10;          6.3452e-02+0.0000e+00j,  7.1973e-02+0.0000e+00j,&#10;         -1.5613e-17+0.0000e+00j],&#10;        [ 0.0000e+00-1.3878e-17j,  1.7191e-02+9.2885e-02j,&#10;          7.9089e-02-1.7069e-01j,  1.3416e-01-3.1222e-02j,&#10;          9.0563e-02-4.3217e-02j, -1.7191e-02-9.2885e-02j,&#10;          2.6021e-18-3.4694e-18j, -8.3212e-02-1.2963e-02j,&#10;          6.0296e-03-1.0190e-03j, -5.3545e-02+1.0717e-02j,&#10;         -7.9089e-02+1.7069e-01j,  8.3212e-02+1.2963e-02j,&#10;         -1.3878e-17+1.3878e-17j,  1.3266e-02-8.7509e-02j,&#10;          1.3995e-01-1.5477e-02j, -1.3416e-01+3.1222e-02j,&#10;         -6.0296e-03+1.0190e-03j, -1.3266e-02+8.7509e-02j,&#10;         -1.7347e-17-1.3878e-17j, -5.8809e-02+1.0701e-01j,&#10;         -9.0563e-02+4.3217e-02j,  5.3545e-02-1.0717e-02j,&#10;         -1.3995e-01+1.5477e-02j,  5.8809e-02-1.0701e-01j,&#10;          7.6328e-17-8.6736e-18j],&#10;        [ 0.0000e+00-1.3878e-17j, -3.7573e-02-7.7907e-02j,&#10;          4.6035e-02-6.6814e-02j, -2.1693e-02+4.8489e-02j,&#10;         -9.9979e-02+2.3255e-01j,  3.7573e-02+7.7907e-02j,&#10;          0.0000e+00+6.9389e-18j,  6.0520e-03+1.1633e-01j,&#10;          4.8529e-02-4.3703e-02j, -1.5943e-03-7.8042e-02j,&#10;         -4.6035e-02+6.6814e-02j, -6.0520e-03-1.1633e-01j,&#10;          0.0000e+00+0.0000e+00j,  2.2297e-02+8.6667e-02j,&#10;         -1.2852e-01+1.5376e-01j,  2.1693e-02-4.8489e-02j,&#10;         -4.8529e-02+4.3703e-02j, -2.2297e-02-8.6667e-02j,&#10;          1.3878e-17-3.4694e-18j,  1.3523e-01+4.3699e-02j,&#10;          9.9979e-02-2.3255e-01j,  1.5943e-03+7.8042e-02j,&#10;          1.2852e-01-1.5376e-01j, -1.3523e-01-4.3699e-02j,&#10;          4.1633e-17+6.9389e-17j],&#10;        [ 1.3878e-17-1.3878e-17j,  1.8553e-01+7.3818e-02j,&#10;          7.2875e-02-1.1586e-01j, -3.4771e-02+2.5431e-02j,&#10;          3.5099e-02-1.0438e-01j, -1.8553e-01-7.3818e-02j,&#10;         -1.3878e-17-1.3878e-17j, -1.7220e-01-2.6094e-02j,&#10;         -4.3429e-02+7.2823e-02j, -4.2235e-02+2.9622e-03j,&#10;         -7.2875e-02+1.1586e-01j,  1.7220e-01+2.6094e-02j,&#10;         -1.3878e-17+1.3878e-17j,  1.4762e-02+6.2783e-02j,&#10;          7.8392e-03-8.1334e-02j,  3.4771e-02-2.5431e-02j,&#10;          4.3429e-02-7.2823e-02j, -1.4762e-02-6.2783e-02j,&#10;         -1.0408e-17-1.2143e-17j, -1.2245e-02+4.2899e-02j,&#10;         -3.5099e-02+1.0438e-01j,  4.2235e-02-2.9622e-03j,&#10;         -7.8392e-03+8.1334e-02j,  1.2245e-02-4.2899e-02j,&#10;         -1.0408e-17-3.4694e-18j],&#10;        [ 3.4694e-18-1.3878e-17j,  1.0497e-02+9.2706e-02j,&#10;          4.5012e-02-6.2518e-02j,  7.1832e-02-4.8118e-02j,&#10;         -9.9208e-02+1.6916e-01j, -1.0497e-02-9.2706e-02j,&#10;          3.4694e-18+0.0000e+00j,  1.2097e-02-6.4037e-02j,&#10;         -8.2413e-02+3.1812e-02j,  1.2173e-01-4.2776e-02j,&#10;         -4.5012e-02+6.2518e-02j, -1.2097e-02+6.4037e-02j,&#10;          3.4694e-18+0.0000e+00j,  1.4039e-01-2.4822e-02j,&#10;         -1.1078e-01+1.5962e-01j, -7.1832e-02+4.8118e-02j,&#10;          8.2413e-02-3.1812e-02j, -1.4039e-01+2.4822e-02j,&#10;         -6.9389e-18+0.0000e+00j, -5.3048e-03-1.6784e-01j,&#10;          9.9208e-02-1.6916e-01j, -1.2173e-01+4.2776e-02j,&#10;          1.1078e-01-1.5962e-01j,  5.3048e-03+1.6784e-01j,&#10;         -5.5511e-17-1.0408e-17j],&#10;        [ 0.0000e+00+1.3878e-17j,  1.7191e-02-9.2885e-02j,&#10;          7.9089e-02+1.7069e-01j,  1.3416e-01+3.1222e-02j,&#10;          9.0563e-02+4.3217e-02j, -1.7191e-02+9.2885e-02j,&#10;          2.6021e-18+3.4694e-18j, -8.3212e-02+1.2963e-02j,&#10;          6.0296e-03+1.0190e-03j, -5.3545e-02-1.0717e-02j,&#10;         -7.9089e-02-1.7069e-01j,  8.3212e-02-1.2963e-02j,&#10;         -1.3878e-17-1.3878e-17j,  1.3266e-02+8.7509e-02j,&#10;          1.3995e-01+1.5477e-02j, -1.3416e-01-3.1222e-02j,&#10;         -6.0296e-03-1.0190e-03j, -1.3266e-02-8.7509e-02j,&#10;         -1.7347e-17+1.3878e-17j, -5.8809e-02-1.0701e-01j,&#10;         -9.0563e-02-4.3217e-02j,  5.3545e-02+1.0717e-02j,&#10;         -1.3995e-01-1.5477e-02j,  5.8809e-02+1.0701e-01j,&#10;          7.6328e-17+8.6736e-18j],&#10;        [ 1.2360e-17+0.0000e+00j, -4.8360e-02+0.0000e+00j,&#10;         -5.4196e-02+0.0000e+00j,  2.3771e-01+0.0000e+00j,&#10;         -1.3484e-01+0.0000e+00j,  4.8360e-02+0.0000e+00j,&#10;          1.1276e-17+0.0000e+00j,  7.2984e-02+0.0000e+00j,&#10;         -1.0166e-01+0.0000e+00j,  8.4516e-02+0.0000e+00j,&#10;          5.4196e-02+0.0000e+00j, -7.2984e-02+0.0000e+00j,&#10;          2.1684e-17+0.0000e+00j,  2.1986e-01+0.0000e+00j,&#10;         -1.3013e-01+0.0000e+00j, -2.3771e-01+0.0000e+00j,&#10;          1.0166e-01+0.0000e+00j, -2.1986e-01+0.0000e+00j,&#10;         -1.0408e-17+0.0000e+00j,  2.4268e-02+0.0000e+00j,&#10;          1.3484e-01+0.0000e+00j, -8.4516e-02+0.0000e+00j,&#10;          1.3013e-01+0.0000e+00j, -2.4268e-02+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 0.31628528141966716.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 26, in test_fn_grad
    self._grad_test_helper(device, dtype, op, op.get_op())
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4372, in _grad_test_helper
    return self._check_helper(device, dtype, op, variant, 'gradcheck', check_forward_ad=check_forward_ad,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4341, in _check_helper
    self.assertTrue(gradcheck(fn, gradcheck_args,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3896, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0108+0.0115j, dtype=torch.complex128)
analytical:tensor(0.0040+0.0008j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000e+00+0.0000e+00j,  2.4185e-02+0.0000e+00j,
          2.2108e-02+0.0000e+00j, -2.7478e-02+0.0000e+00j,
         -5.1414e-02+0.0000e+00j, -2.4185e-02+0.0000e+00j,
          1.3878e-14+0.0000e+00j,  3.4838e-02+0.0000e+00j,
         -3.4504e-02+0.0000e+00j, -9.7587e-02+0.0000e+00j,
         -2.2108e-02+0.0000e+00j, -3.4838e-02+0.0000e+00j,
         -6.9389e-15+0.0000e+00j,  8.0398e-03+0.0000e+00j,
         -1.5147e-02+0.0000e+00j,  2.7478e-02+0.0000e+00j,
          3.4504e-02+0.0000e+00j, -8.0398e-03+0.0000e+00j,
         -3.4694e-15+0.0000e+00j,  3.7522e-02+0.0000e+00j,
          5.1414e-02+0.0000e+00j,  9.7587e-02+0.0000e+00j,
          1.5147e-02+0.0000e+00j, -3.7522e-02+0.0000e+00j,
          4.3368e-15+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.2534e-01+5.4792e-03j,
          1.2344e-02-2.7246e-02j, -5.1346e-02+3.0802e-02j,
          5.2087e-02+1.0986e-01j, -1.2534e-01-5.4792e-03j,
          2.7756e-14+1.3878e-14j, -2.7025e-01-1.6388e-01j,
          1.5549e-01-5.4318e-02j,  6.4643e-02-8.6568e-02j,
         -1.2344e-02+2.7246e-02j,  2.7025e-01+1.6388e-01j,
          0.0000e+00-3.4694e-15j,  5.2836e-02+8.0600e-02j,
          8.0959e-02-4.1466e-02j,  5.1346e-02-3.0802e-02j,
         -1.5549e-01+5.4318e-02j, -5.2836e-02-8.0600e-02j,
          3.4694e-15-3.4694e-15j, -1.1395e-01-9.8322e-03j,
         -5.2087e-02-1.0986e-01j, -6.4643e-02+8.6568e-02j,
         -8.0959e-02+4.1466e-02j,  1.1395e-01+9.8322e-03j,
         -1.3010e-14-2.1684e-14j],
        [ 0.0000e+00+0.0000e+00j, -2.1127e-02-1.3775e-01j,
         -7.0653e-02-4.5179e-03j,  6.4627e-02+1.3951e-01j,
         -1.4797e-01+6.2596e-02j,  2.1127e-02+1.3775e-01j,
          1.2143e-14+1.3878e-14j,  1.2066e-01+4.7849e-02j,
          1.1351e-02-3.2387e-02j, -7.3993e-03+1.2773e-01j,
          7.0653e-02+4.5179e-03j, -1.2066e-01-4.7849e-02j,
         -3.4694e-15+3.4694e-15j, -5.3122e-02-8.1531e-02j,
         -6.3177e-02+4.0576e-02j, -6.4627e-02-1.3951e-01j,
         -1.1351e-02+3.2387e-02j,  5.3122e-02+8.1531e-02j,
          3.4694e-15+3.4694e-15j,  3.8820e-01-6.8107e-02j,
          1.4797e-01-6.2596e-02j,  7.3993e-03-1.2773e-01j,
          6.3177e-02-4.0576e-02j, -3.8820e-01+6.8107e-02j,
          1.6480e-14+1.7347e-14j],
        [ 0.0000e+00+0.0000e+00j,  2.3711e-02+8.9950e-02j,
         -2.9123e-02+7.6115e-02j,  1.3087e-02-2.7653e-02j,
         -3.2091e-02-1.0933e-01j, -2.3711e-02-8.9950e-02j,
         -1.3878e-14-3.4694e-15j, -3.6351e-02+4.2963e-02j,
          5.7895e-02-4.2211e-02j, -6.8415e-02+3.5458e-02j,
          2.9123e-02-7.6115e-02j,  3.6351e-02-4.2963e-02j,
          0.0000e+00+6.9389e-15j,  6.2486e-02+5.3987e-02j,
          2.1848e-01+5.1598e-02j, -1.3087e-02+2.7653e-02j,
         -5.7895e-02+4.2211e-02j, -6.2486e-02-5.3987e-02j,
         -3.4694e-15-3.4694e-15j,  4.6686e-02-1.0818e-01j,
          3.2091e-02+1.0933e-01j,  6.8415e-02-3.5458e-02j,
         -2.1848e-01-5.1598e-02j, -4.6686e-02+1.0818e-01j,
         -6.9389e-15-5.2042e-15j],
        [ 0.0000e+00+0.0000e+00j, -1.8850e-02-4.1843e-02j,
          4.0606e-02+8.7621e-02j, -6.6075e-03-3.7577e-02j,
         -1.1381e-01-2.0988e-01j,  1.8850e-02+4.1843e-02j,
          0.0000e+00+0.0000e+00j, -5.4406e-02-4.7033e-02j,
          1.2015e-02-3.3954e-02j, -2.7040e-02+1.1824e-01j,
         -4.0606e-02-8.7621e-02j,  5.4406e-02+4.7033e-02j,
          3.4694e-15-3.4694e-15j,  4.8488e-02-1.1741e-01j,
         -1.2292e-01-1.8591e-01j,  6.6075e-03+3.7577e-02j,
         -1.2015e-02+3.3954e-02j, -4.8488e-02+1.1741e-01j,
          3.4694e-15-3.4694e-15j,  1.5616e-01+9.7069e-02j,
          1.1381e-01+2.0988e-01j,  2.7040e-02-1.1824e-01j,
          1.2292e-01+1.8591e-01j, -1.5616e-01-9.7069e-02j,
          2.9490e-14-8.6736e-16j],
        [ 0.0000e+00+0.0000e+00j,  1.2534e-01-5.4792e-03j,
          1.2344e-02+2.7246e-02j, -5.1346e-02-3.0802e-02j,
          5.2087e-02-1.0986e-01j, -1.2534e-01+5.4792e-03j,
          2.7756e-14-1.3878e-14j, -2.7025e-01+1.6388e-01j,
          1.5549e-01+5.4318e-02j,  6.4643e-02+8.6568e-02j,
         -1.2344e-02-2.7246e-02j,  2.7025e-01-1.6388e-01j,
          0.0000e+00+3.4694e-15j,  5.2836e-02-8.0600e-02j,
          8.0959e-02+4.1466e-02j,  5.1346e-02+3.0802e-02j,
         -1.5549e-01-5.4318e-02j, -5.2836e-02+8.0600e-02j,
          3.4694e-15+3.4694e-15j, -1.1395e-01+9.8322e-03j,
         -5.2087e-02+1.0986e-01j, -6.4643e-02-8.6568e-02j,
         -8.0959e-02-4.1466e-02j,  1.1395e-01-9.8322e-03j,
         -1.3010e-14+2.1684e-14j],
        [ 0.0000e+00+0.0000e+00j, -1.9647e-01+0.0000e+00j,
          3.6944e-02+0.0000e+00j,  2.9153e-03+0.0000e+00j,
          3.2298e-03+0.0000e+00j,  1.9647e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -3.0017e-01+0.0000e+00j,
         -2.4747e-02+0.0000e+00j, -1.0378e-01+0.0000e+00j,
         -3.6944e-02+0.0000e+00j,  3.0017e-01+0.0000e+00j,
          3.4694e-15+0.0000e+00j,  1.4353e-01+0.0000e+00j,
          4.7219e-02+0.0000e+00j, -2.9153e-03+0.0000e+00j,
          2.4747e-02+0.0000e+00j, -1.4353e-01+0.0000e+00j,
         -3.4694e-15+0.0000e+00j, -3.3618e-02+0.0000e+00j,
         -3.2298e-03+0.0000e+00j,  1.0378e-01+0.0000e+00j,
         -4.7219e-02+0.0000e+00j,  3.3618e-02+0.0000e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -1.1049e-01-8.9766e-02j,
         -1.8417e-02+1.0929e-02j, -3.8467e-02+8.5511e-02j,
         -2.0914e-02-6.2460e-02j,  1.1049e-01+8.9766e-02j,
          0.0000e+00+1.7347e-15j,  2.4702e-02-9.9040e-02j,
         -8.9543e-02-1.6300e-01j,  1.7443e-01+1.6046e-03j,
          1.8417e-02-1.0929e-02j, -2.4702e-02+9.9040e-02j,
          1.7347e-14-6.9389e-15j,  2.1295e-02+2.6183e-02j,
         -1.6405e-02+4.9376e-02j,  3.8467e-02-8.5511e-02j,
          8.9543e-02+1.6300e-01j, -2.1295e-02-2.6183e-02j,
          3.4694e-15+1.3878e-14j, -6.0786e-02+5.1747e-03j,
          2.0914e-02+6.2460e-02j, -1.7443e-01-1.6046e-03j,
          1.6405e-02-4.9376e-02j,  6.0786e-02-5.1747e-03j,
          4.3368e-15-2.6021e-15j],
        [ 0.0000e+00+0.0000e+00j,  9.4690e-02+5.8784e-02j,
         -7.0230e-02+1.2213e-02j, -4.1632e-02-8.7655e-03j,
         -6.3692e-02-2.4691e-02j, -9.4690e-02-5.8784e-02j,
          6.9389e-15+1.5613e-14j,  1.6877e-01+5.1070e-03j,
          2.7717e-02-7.0114e-02j,  5.4621e-02-3.4658e-03j,
          7.0230e-02-1.2213e-02j, -1.6877e-01-5.1070e-03j,
         -3.4694e-15+1.0408e-14j, -1.0933e-03-1.1128e-02j,
         -5.8889e-02-6.2365e-02j,  4.1632e-02+8.7655e-03j,
         -2.7717e-02+7.0114e-02j,  1.0933e-03+1.1128e-02j,
          3.4694e-15+0.0000e+00j,  2.9731e-02-8.1489e-02j,
          6.3692e-02+2.4691e-02j, -5.4621e-02+3.4658e-03j,
          5.8889e-02+6.2365e-02j, -2.9731e-02+8.1489e-02j,
          6.0715e-15-9.5410e-15j],
        [ 0.0000e+00+0.0000e+00j,  1.8532e-01-3.0080e-02j,
          8.4701e-02+9.4624e-02j, -6.0144e-02+5.7607e-03j,
          7.7787e-02-2.7179e-02j, -1.8532e-01+3.0080e-02j,
          0.0000e+00-1.5613e-14j, -2.1639e-01+1.1039e-01j,
         -3.6814e-03-1.1197e-01j, -1.8773e-02+1.1194e-01j,
         -8.4701e-02-9.4624e-02j,  2.1639e-01-1.1039e-01j,
          1.0408e-14-3.4694e-15j,  5.2729e-02-7.4484e-02j,
          1.8518e-02+5.0199e-02j,  6.0144e-02-5.7607e-03j,
          3.6814e-03+1.1197e-01j, -5.2729e-02+7.4484e-02j,
          0.0000e+00-1.0408e-14j, -6.7874e-02+9.8892e-02j,
         -7.7787e-02+2.7179e-02j,  1.8773e-02-1.1194e-01j,
         -1.8518e-02-5.0199e-02j,  6.7874e-02-9.8892e-02j,
          0.0000e+00+1.4745e-14j],
        [ 0.0000e+00+0.0000e+00j, -2.1127e-02+1.3775e-01j,
         -7.0653e-02+4.5179e-03j,  6.4627e-02-1.3951e-01j,
         -1.4797e-01-6.2596e-02j,  2.1127e-02-1.3775e-01j,
          1.2143e-14-1.3878e-14j,  1.2066e-01-4.7849e-02j,
          1.1351e-02+3.2387e-02j, -7.3993e-03-1.2773e-01j,
          7.0653e-02-4.5179e-03j, -1.2066e-01+4.7849e-02j,
         -3.4694e-15-3.4694e-15j, -5.3122e-02+8.1531e-02j,
         -6.3177e-02-4.0576e-02j, -6.4627e-02+1.3951e-01j,
         -1.1351e-02-3.2387e-02j,  5.3122e-02-8.1531e-02j,
          3.4694e-15-3.4694e-15j,  3.8820e-01+6.8107e-02j,
          1.4797e-01+6.2596e-02j,  7.3993e-03+1.2773e-01j,
          6.3177e-02+4.0576e-02j, -3.8820e-01-6.8107e-02j,
          1.6480e-14-1.7347e-14j],
        [ 0.0000e+00+0.0000e+00j, -1.1049e-01+8.9766e-02j,
         -1.8417e-02-1.0929e-02j, -3.8467e-02-8.5511e-02j,
         -2.0914e-02+6.2460e-02j,  1.1049e-01-8.9766e-02j,
          0.0000e+00-1.7347e-15j,  2.4702e-02+9.9040e-02j,
         -8.9543e-02+1.6300e-01j,  1.7443e-01-1.6046e-03j,
          1.8417e-02+1.0929e-02j, -2.4702e-02-9.9040e-02j,
          1.7347e-14+6.9389e-15j,  2.1295e-02-2.6183e-02j,
         -1.6405e-02-4.9376e-02j,  3.8467e-02+8.5511e-02j,
          8.9543e-02-1.6300e-01j, -2.1295e-02+2.6183e-02j,
          3.4694e-15-1.3878e-14j, -6.0786e-02-5.1747e-03j,
          2.0914e-02-6.2460e-02j, -1.7443e-01+1.6046e-03j,
          1.6405e-02+4.9376e-02j,  6.0786e-02+5.1747e-03j,
          4.3368e-15+2.6021e-15j],
        [ 0.0000e+00+0.0000e+00j,  7.3858e-02+0.0000e+00j,
         -3.4152e-02+0.0000e+00j, -1.5022e-01+0.0000e+00j,
          5.6199e-02+0.0000e+00j, -7.3858e-02+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -3.8496e-02+0.0000e+00j,
         -2.0765e-03+0.0000e+00j,  6.6066e-02+0.0000e+00j,
          3.4152e-02+0.0000e+00j,  3.8496e-02+0.0000e+00j,
         -1.3878e-14+0.0000e+00j,  4.5471e-03+0.0000e+00j,
          5.8472e-02+0.0000e+00j,  1.5022e-01+0.0000e+00j,
          2.0765e-03+0.0000e+00j, -4.5471e-03+0.0000e+00j,
          1.0408e-14+0.0000e+00j, -1.2826e-01+0.0000e+00j,
         -5.6199e-02+0.0000e+00j, -6.6066e-02+0.0000e+00j,
         -5.8472e-02+0.0000e+00j,  1.2826e-01+0.0000e+00j,
         -3.4694e-15+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -9.2220e-02-4.6866e-02j,
         -4.0561e-02-1.2922e-02j,  2.7880e-02+3.6133e-02j,
         -5.7898e-02-1.1198e-01j,  9.2220e-02+4.6866e-02j,
         -8.6736e-16+0.0000e+00j,  1.9090e-01+6.1904e-02j,
          1.8668e-02+1.2074e-02j, -2.3069e-02+2.1950e-02j,
          4.0561e-02+1.2922e-02j, -1.9090e-01-6.1904e-02j,
          1.0408e-14-3.4694e-15j, -1.7523e-01+5.1556e-02j,
          3.5944e-02-1.2803e-02j, -2.7880e-02-3.6133e-02j,
         -1.8668e-02-1.2074e-02j,  1.7523e-01-5.1556e-02j,
         -6.9389e-15-1.0408e-14j,  2.3236e-01-1.5847e-01j,
          5.7898e-02+1.1198e-01j,  2.3069e-02-2.1950e-02j,
         -3.5944e-02+1.2803e-02j, -2.3236e-01+1.5847e-01j,
          3.4694e-15-4.3368e-15j],
        [ 0.0000e+00+0.0000e+00j, -8.8142e-02-1.1636e-01j,
          7.9055e-02+7.3960e-02j,  8.2109e-02+7.3500e-02j,
          6.4162e-03-1.5509e-01j,  8.8142e-02+1.1636e-01j,
         -1.3878e-14+1.3878e-14j,  3.9992e-02+3.0838e-02j,
         -7.3964e-02-9.2800e-02j,  5.2277e-02+1.2231e-01j,
         -7.9055e-02-7.3960e-02j, -3.9992e-02-3.0838e-02j,
          3.4694e-15+0.0000e+00j,  1.5790e-01+6.7970e-02j,
         -1.1784e-01-1.1086e-01j, -8.2109e-02-7.3500e-02j,
          7.3964e-02+9.2800e-02j, -1.5790e-01-6.7970e-02j,
          6.9389e-15+0.0000e+00j,  1.1975e-02-2.9938e-02j,
         -6.4162e-03+1.5509e-01j, -5.2277e-02-1.2231e-01j,
          1.1784e-01+1.1086e-01j, -1.1975e-02+2.9938e-02j,
          0.0000e+00-1.4745e-14j],
        [ 0.0000e+00+0.0000e+00j,  2.3711e-02-8.9950e-02j,
         -2.9123e-02-7.6115e-02j,  1.3087e-02+2.7653e-02j,
         -3.2091e-02+1.0933e-01j, -2.3711e-02+8.9950e-02j,
         -1.3878e-14+3.4694e-15j, -3.6351e-02-4.2963e-02j,
          5.7895e-02+4.2211e-02j, -6.8415e-02-3.5458e-02j,
          2.9123e-02+7.6115e-02j,  3.6351e-02+4.2963e-02j,
          0.0000e+00-6.9389e-15j,  6.2486e-02-5.3987e-02j,
          2.1848e-01-5.1598e-02j, -1.3087e-02-2.7653e-02j,
         -5.7895e-02-4.2211e-02j, -6.2486e-02+5.3987e-02j,
         -3.4694e-15+3.4694e-15j,  4.6686e-02+1.0818e-01j,
          3.2091e-02-1.0933e-01j,  6.8415e-02+3.5458e-02j,
         -2.1848e-01+5.1598e-02j, -4.6686e-02-1.0818e-01j,
         -6.9389e-15+5.2042e-15j],
        [ 0.0000e+00+0.0000e+00j,  9.4690e-02-5.8784e-02j,
         -7.0230e-02-1.2213e-02j, -4.1632e-02+8.7655e-03j,
         -6.3692e-02+2.4691e-02j, -9.4690e-02+5.8784e-02j,
          6.9389e-15-1.5613e-14j,  1.6877e-01-5.1070e-03j,
          2.7717e-02+7.0114e-02j,  5.4621e-02+3.4658e-03j,
          7.0230e-02+1.2213e-02j, -1.6877e-01+5.1070e-03j,
         -3.4694e-15-1.0408e-14j, -1.0933e-03+1.1128e-02j,
         -5.8889e-02+6.2365e-02j,  4.1632e-02-8.7655e-03j,
         -2.7717e-02-7.0114e-02j,  1.0933e-03-1.1128e-02j,
          3.4694e-15+0.0000e+00j,  2.9731e-02+8.1489e-02j,
          6.3692e-02-2.4691e-02j, -5.4621e-02-3.4658e-03j,
          5.8889e-02-6.2365e-02j, -2.9731e-02-8.1489e-02j,
          6.0715e-15+9.5410e-15j],
        [ 0.0000e+00+0.0000e+00j, -9.2220e-02+4.6866e-02j,
         -4.0561e-02+1.2922e-02j,  2.7880e-02-3.6133e-02j,
         -5.7898e-02+1.1198e-01j,  9.2220e-02-4.6866e-02j,
         -8.6736e-16+0.0000e+00j,  1.9090e-01-6.1904e-02j,
          1.8668e-02-1.2074e-02j, -2.3069e-02-2.1950e-02j,
          4.0561e-02-1.2922e-02j, -1.9090e-01+6.1904e-02j,
          1.0408e-14+3.4694e-15j, -1.7523e-01-5.1556e-02j,
          3.5944e-02+1.2803e-02j, -2.7880e-02+3.6133e-02j,
         -1.8668e-02+1.2074e-02j,  1.7523e-01+5.1556e-02j,
         -6.9389e-15+1.0408e-14j,  2.3236e-01+1.5847e-01j,
          5.7898e-02-1.1198e-01j,  2.3069e-02+2.1950e-02j,
         -3.5944e-02-1.2803e-02j, -2.3236e-01-1.5847e-01j,
          3.4694e-15+4.3368e-15j],
        [ 0.0000e+00+0.0000e+00j,  1.0824e-01+0.0000e+00j,
          1.2047e-01+0.0000e+00j,  7.5822e-02+0.0000e+00j,
          1.1865e-01+0.0000e+00j, -1.0824e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  6.3181e-02+0.0000e+00j,
          1.7813e-01+0.0000e+00j,  1.2376e-02+0.0000e+00j,
         -1.2047e-01+0.0000e+00j, -6.3181e-02+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -4.4015e-02+0.0000e+00j,
         -1.1136e-04+0.0000e+00j, -7.5822e-02+0.0000e+00j,
         -1.7813e-01+0.0000e+00j,  4.4015e-02+0.0000e+00j,
          3.4694e-15+0.0000e+00j, -1.7683e-01+0.0000e+00j,
         -1.1865e-01+0.0000e+00j, -1.2376e-02+0.0000e+00j,
          1.1136e-04+0.0000e+00j,  1.7683e-01+0.0000e+00j,
          1.3878e-14+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.1528e-01+5.7277e-02j,
          4.0272e-02-1.4201e-01j,  1.7558e-01-3.0177e-02j,
         -1.7120e-02-6.6412e-02j, -1.1528e-01-5.7277e-02j,
         -1.9949e-14-4.1633e-14j, -1.1823e-01+8.9500e-03j,
          6.0147e-03+1.2263e-03j, -1.2874e-01+8.6963e-02j,
         -4.0272e-02+1.4201e-01j,  1.1823e-01-8.9500e-03j,
         -6.9389e-15+1.3878e-14j, -6.5222e-03-6.9675e-02j,
          1.0972e-01-1.8816e-02j, -1.7558e-01+3.0177e-02j,
         -6.0147e-03-1.2263e-03j,  6.5222e-03+6.9675e-02j,
          3.4694e-15-3.4694e-15j,  1.5384e-01+4.6781e-02j,
          1.7120e-02+6.6412e-02j,  1.2874e-01-8.6963e-02j,
         -1.0972e-01+1.8816e-02j, -1.5384e-01-4.6781e-02j,
          1.4745e-14+1.4745e-14j],
        [ 0.0000e+00+0.0000e+00j, -1.8850e-02+4.1843e-02j,
          4.0606e-02-8.7621e-02j, -6.6075e-03+3.7577e-02j,
         -1.1381e-01+2.0988e-01j,  1.8850e-02-4.1843e-02j,
          0.0000e+00+0.0000e+00j, -5.4406e-02+4.7033e-02j,
          1.2015e-02+3.3954e-02j, -2.7040e-02-1.1824e-01j,
         -4.0606e-02+8.7621e-02j,  5.4406e-02-4.7033e-02j,
          3.4694e-15+3.4694e-15j,  4.8488e-02+1.1741e-01j,
         -1.2292e-01+1.8591e-01j,  6.6075e-03-3.7577e-02j,
         -1.2015e-02-3.3954e-02j, -4.8488e-02-1.1741e-01j,
          3.4694e-15+3.4694e-15j,  1.5616e-01-9.7069e-02j,
          1.1381e-01-2.0988e-01j,  2.7040e-02+1.1824e-01j,
          1.2292e-01-1.8591e-01j, -1.5616e-01+9.7069e-02j,
          2.9490e-14+8.6736e-16j],
        [ 0.0000e+00+0.0000e+00j,  1.8532e-01+3.0080e-02j,
          8.4701e-02-9.4624e-02j, -6.0144e-02-5.7607e-03j,
          7.7787e-02+2.7179e-02j, -1.8532e-01-3.0080e-02j,
          0.0000e+00+1.5613e-14j, -2.1639e-01-1.1039e-01j,
         -3.6814e-03+1.1197e-01j, -1.8773e-02-1.1194e-01j,
         -8.4701e-02+9.4624e-02j,  2.1639e-01+1.1039e-01j,
          1.0408e-14+3.4694e-15j,  5.2729e-02+7.4484e-02j,
          1.8518e-02-5.0199e-02j,  6.0144e-02+5.7607e-03j,
          3.6814e-03-1.1197e-01j, -5.2729e-02-7.4484e-02j,
          0.0000e+00+1.0408e-14j, -6.7874e-02-9.8892e-02j,
         -7.7787e-02-2.7179e-02j,  1.8773e-02+1.1194e-01j,
         -1.8518e-02+5.0199e-02j,  6.7874e-02+9.8892e-02j,
          0.0000e+00-1.4745e-14j],
        [ 0.0000e+00+0.0000e+00j, -8.8142e-02+1.1636e-01j,
          7.9055e-02-7.3960e-02j,  8.2109e-02-7.3500e-02j,
          6.4162e-03+1.5509e-01j,  8.8142e-02-1.1636e-01j,
         -1.3878e-14-1.3878e-14j,  3.9992e-02-3.0838e-02j,
         -7.3964e-02+9.2800e-02j,  5.2277e-02-1.2231e-01j,
         -7.9055e-02+7.3960e-02j, -3.9992e-02+3.0838e-02j,
          3.4694e-15+0.0000e+00j,  1.5790e-01-6.7970e-02j,
         -1.1784e-01+1.1086e-01j, -8.2109e-02+7.3500e-02j,
          7.3964e-02-9.2800e-02j, -1.5790e-01+6.7970e-02j,
          6.9389e-15+0.0000e+00j,  1.1975e-02+2.9938e-02j,
         -6.4162e-03-1.5509e-01j, -5.2277e-02+1.2231e-01j,
          1.1784e-01-1.1086e-01j, -1.1975e-02-2.9938e-02j,
          0.0000e+00+1.4745e-14j],
        [ 0.0000e+00+0.0000e+00j,  1.1528e-01-5.7277e-02j,
          4.0272e-02+1.4201e-01j,  1.7558e-01+3.0177e-02j,
         -1.7120e-02+6.6412e-02j, -1.1528e-01+5.7277e-02j,
         -1.9949e-14+4.1633e-14j, -1.1823e-01-8.9500e-03j,
          6.0147e-03-1.2263e-03j, -1.2874e-01-8.6963e-02j,
         -4.0272e-02-1.4201e-01j,  1.1823e-01+8.9500e-03j,
         -6.9389e-15-1.3878e-14j, -6.5222e-03+6.9675e-02j,
          1.0972e-01+1.8816e-02j, -1.7558e-01-3.0177e-02j,
         -6.0147e-03+1.2263e-03j,  6.5222e-03-6.9675e-02j,
          3.4694e-15+3.4694e-15j,  1.5384e-01-4.6781e-02j,
          1.7120e-02-6.6412e-02j,  1.2874e-01+8.6963e-02j,
         -1.0972e-01-1.8816e-02j, -1.5384e-01+4.6781e-02j,
          1.4745e-14-1.4745e-14j],
        [ 0.0000e+00+0.0000e+00j,  6.1134e-02+0.0000e+00j,
         -1.1745e-01+0.0000e+00j,  2.4050e-01+0.0000e+00j,
         -2.3005e-01+0.0000e+00j, -6.1134e-02+0.0000e+00j,
         -3.4694e-15+0.0000e+00j,  8.8855e-02+0.0000e+00j,
         -8.8702e-02+0.0000e+00j,  1.1027e-03+0.0000e+00j,
          1.1745e-01+0.0000e+00j, -8.8855e-02+0.0000e+00j,
         -3.4694e-15+0.0000e+00j,  6.2620e-02+0.0000e+00j,
         -1.2451e-01+0.0000e+00j, -2.4050e-01+0.0000e+00j,
          8.8702e-02+0.0000e+00j, -6.2620e-02+0.0000e+00j,
         -1.0408e-14+0.0000e+00j,  2.6309e-01+0.0000e+00j,
          2.3005e-01+0.0000e+00j, -1.1027e-03+0.0000e+00j,
          1.2451e-01+0.0000e+00j, -2.6309e-01+0.0000e+00j,
          2.6021e-15+0.0000e+00j]], dtype=torch.complex128)
Analytical:
tensor([[ 9.4151e-18+0.0000e+00j,  2.4185e-02+0.0000e+00j,
          2.2108e-02+0.0000e+00j, -2.7478e-02+0.0000e+00j,
         -5.1414e-02+0.0000e+00j, -2.4185e-02+0.0000e+00j,
          6.1507e-18+0.0000e+00j,  3.4838e-02+0.0000e+00j,
         -3.4504e-02+0.0000e+00j, -9.7587e-02+0.0000e+00j,
         -2.2108e-02+0.0000e+00j, -3.4838e-02+0.0000e+00j,
         -1.3134e-17+0.0000e+00j,  8.0398e-03+0.0000e+00j,
         -1.5147e-02+0.0000e+00j,  2.7478e-02+0.0000e+00j,
          3.4504e-02+0.0000e+00j, -8.0398e-03+0.0000e+00j,
          1.8727e-18+0.0000e+00j,  3.7522e-02+0.0000e+00j,
          5.1414e-02+0.0000e+00j,  9.7587e-02+0.0000e+00j,
          1.5147e-02+0.0000e+00j, -3.7522e-02+0.0000e+00j,
          2.2577e-17+0.0000e+00j],
        [-1.9082e-17+0.0000e+00j,  4.4597e-02-5.1490e-03j,
          1.5518e-02-4.6360e-02j, -3.7950e-02+1.1778e-02j,
          2.8747e-02+1.0827e-01j, -4.4597e-02+5.1490e-03j,
         -1.3878e-17+3.4694e-18j, -7.5315e-02-1.1588e-02j,
          1.1788e-01+3.1135e-02j,  2.0142e-01-7.3199e-02j,
         -1.5518e-02+4.6360e-02j,  7.5315e-02+1.1588e-02j,
         -6.0715e-18+6.9389e-18j,  6.1024e-03-1.6169e-02j,
          8.3156e-03-8.8745e-02j,  3.7950e-02-1.1778e-02j,
         -1.1788e-01-3.1135e-02j, -6.1024e-03+1.6169e-02j,
          1.0408e-17+1.7347e-17j,  3.1742e-02+9.0681e-02j,
         -2.8747e-02-1.0827e-01j, -2.0142e-01+7.3199e-02j,
         -8.3156e-03+8.8745e-02j, -3.1742e-02-9.0681e-02j,
         -1.3878e-17+1.3878e-17j],
        [ 0.0000e+00+0.0000e+00j, -4.3593e-02-5.7957e-02j,
         -3.0060e-02-2.1465e-02j,  7.2283e-02+1.6159e-01j,
         -1.3125e-01+5.7877e-02j,  4.3593e-02+5.7957e-02j,
          6.9389e-18+0.0000e+00j,  2.4607e-02-2.4344e-02j,
          3.7373e-02+5.9157e-03j,  5.0255e-03+7.1835e-02j,
          3.0060e-02+2.1465e-02j, -2.4607e-02+2.4344e-02j,
          6.9389e-18+5.1174e-17j,  9.4182e-02-1.2057e-02j,
         -3.2556e-02+7.2616e-02j, -7.2283e-02-1.6159e-01j,
         -3.7373e-02-5.9157e-03j, -9.4182e-02+1.2057e-02j,
          0.0000e+00-6.9389e-18j,  1.2473e-01-1.4288e-01j,
          1.3125e-01-5.7877e-02j, -5.0255e-03-7.1835e-02j,
          3.2556e-02-7.2616e-02j, -1.2473e-01+1.4288e-01j,
         -6.9389e-18+0.0000e+00j],
        [ 1.0408e-17-8.6736e-18j, -1.0254e-02+5.1909e-02j,
         -1.4988e-02+7.0141e-02j,  3.2192e-02-2.3254e-02j,
         -7.1570e-02-6.5956e-02j,  1.0254e-02-5.1909e-02j,
         -3.4694e-18-1.3878e-17j,  4.4784e-02+6.6121e-02j,
          2.8896e-02-8.0023e-03j,  5.4034e-02-4.1865e-02j,
          1.4988e-02-7.0141e-02j, -4.4784e-02-6.6121e-02j,
          1.3878e-17-3.4694e-18j,  1.1106e-01+2.9736e-02j,
          1.7417e-01+5.4374e-02j, -3.2192e-02+2.3254e-02j,
         -2.8896e-02+8.0023e-03j, -1.1106e-01-2.9736e-02j,
         -6.9389e-18+1.7347e-18j,  1.6651e-02-1.4813e-02j,
          7.1570e-02+6.5956e-02j, -5.4034e-02+4.1865e-02j,
         -1.7417e-01-5.4374e-02j, -1.6651e-02+1.4813e-02j,
          0.0000e+00+1.2143e-17j],
        [ 0.0000e+00+1.3878e-17j, -3.7573e-02+7.7907e-02j,
          4.6035e-02+6.6814e-02j, -2.1693e-02-4.8489e-02j,
         -9.9979e-02-2.3255e-01j,  3.7573e-02-7.7907e-02j,
          0.0000e+00-6.9389e-18j,  6.0520e-03-1.1633e-01j,
          4.8529e-02+4.3703e-02j, -1.5943e-03+7.8042e-02j,
         -4.6035e-02-6.6814e-02j, -6.0520e-03+1.1633e-01j,
          0.0000e+00+0.0000e+00j,  2.2297e-02-8.6667e-02j,
         -1.2852e-01-1.5376e-01j,  2.1693e-02+4.8489e-02j,
         -4.8529e-02-4.3703e-02j, -2.2297e-02+8.6667e-02j,
          1.3878e-17+3.4694e-18j,  1.3523e-01-4.3699e-02j,
          9.9979e-02+2.3255e-01j,  1.5943e-03-7.8042e-02j,
          1.2852e-01+1.5376e-01j, -1.3523e-01+4.3699e-02j,
          4.1633e-17-6.9389e-17j],
        [-1.9082e-17+0.0000e+00j,  4.4597e-02+5.1490e-03j,
          1.5518e-02+4.6360e-02j, -3.7950e-02-1.1778e-02j,
          2.8747e-02-1.0827e-01j, -4.4597e-02-5.1490e-03j,
         -1.3878e-17-3.4694e-18j, -7.5315e-02+1.1588e-02j,
          1.1788e-01-3.1135e-02j,  2.0142e-01+7.3199e-02j,
         -1.5518e-02-4.6360e-02j,  7.5315e-02-1.1588e-02j,
         -6.0715e-18-6.9389e-18j,  6.1024e-03+1.6169e-02j,
          8.3156e-03+8.8745e-02j,  3.7950e-02+1.1778e-02j,
         -1.1788e-01+3.1135e-02j, -6.1024e-03-1.6169e-02j,
          1.0408e-17-1.7347e-17j,  3.1742e-02-9.0681e-02j,
         -2.8747e-02+1.0827e-01j, -2.0142e-01-7.3199e-02j,
         -8.3156e-03-8.8745e-02j, -3.1742e-02+9.0681e-02j,
         -1.3878e-17-1.3878e-17j],
        [ 6.9389e-18+0.0000e+00j, -1.8958e-01+0.0000e+00j,
         -1.5739e-04+0.0000e+00j, -4.3528e-02+0.0000e+00j,
          3.6484e-02+0.0000e+00j,  1.8958e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -1.0759e-01+0.0000e+00j,
          9.0444e-02+0.0000e+00j, -1.1793e-01+0.0000e+00j,
          1.5739e-04+0.0000e+00j,  1.0759e-01+0.0000e+00j,
          1.3010e-18+0.0000e+00j,  7.2366e-03+0.0000e+00j,
         -2.1112e-02+0.0000e+00j,  4.3528e-02+0.0000e+00j,
         -9.0444e-02+0.0000e+00j, -7.2366e-03+0.0000e+00j,
         -1.7347e-18+0.0000e+00j, -3.2737e-02+0.0000e+00j,
         -3.6484e-02+0.0000e+00j,  1.1793e-01+0.0000e+00j,
          2.1112e-02+0.0000e+00j,  3.2737e-02+0.0000e+00j,
         -6.9389e-18+0.0000e+00j],
        [-1.3878e-17+0.0000e+00j, -1.0786e-01+1.4100e-02j,
         -1.1987e-02+1.1119e-05j, -3.0054e-02+4.6212e-02j,
          3.2615e-02-8.8762e-02j,  1.0786e-01-1.4100e-02j,
          0.0000e+00+2.6021e-18j, -3.9304e-02-4.3558e-02j,
         -1.6432e-02-2.4273e-02j,  2.0503e-02+2.8073e-02j,
          1.1987e-02-1.1119e-05j,  3.9304e-02+4.3558e-02j,
          1.7347e-18-1.3878e-17j,  2.6494e-02-2.6615e-05j,
          1.6579e-02+4.6121e-02j,  3.0054e-02-4.6212e-02j,
          1.6432e-02+2.4273e-02j, -2.6494e-02+2.6615e-05j,
          1.7347e-17-6.9389e-18j,  9.9819e-03-1.8046e-02j,
         -3.2615e-02+8.8762e-02j, -2.0503e-02-2.8073e-02j,
         -1.6579e-02-4.6121e-02j, -9.9819e-03+1.8046e-02j,
          1.3878e-17-4.1633e-17j],
        [-5.2042e-18+6.9389e-18j,  1.1476e-01+1.5870e-02j,
         -5.2279e-02+1.9017e-02j, -2.1577e-02-1.6481e-02j,
         -5.4579e-02+6.0388e-02j, -1.1476e-01-1.5870e-02j,
         -2.7756e-17+1.2143e-17j,  5.6335e-02-1.0330e-01j,
          2.7058e-02-8.3079e-02j, -3.3456e-02-8.0641e-02j,
          5.2279e-02-1.9017e-02j, -5.6335e-02+1.0330e-01j,
          2.0817e-17-3.4694e-18j,  5.8635e-02+1.4922e-02j,
         -1.7083e-02-3.7584e-02j,  2.1577e-02+1.6481e-02j,
         -2.7058e-02+8.3079e-02j, -5.8635e-02-1.4922e-02j,
         -2.4286e-17-1.3878e-17j, -1.4714e-02-3.4101e-02j,
          5.4579e-02-6.0388e-02j,  3.3456e-02+8.0641e-02j,
          1.7083e-02+3.7584e-02j,  1.4714e-02+3.4101e-02j,
         -6.9389e-18-6.9389e-18j],
        [ 1.3878e-17+1.3878e-17j,  1.8553e-01-7.3818e-02j,
          7.2875e-02+1.1586e-01j, -3.4771e-02-2.5431e-02j,
          3.5099e-02+1.0438e-01j, -1.8553e-01+7.3818e-02j,
         -1.3878e-17+1.3878e-17j, -1.7220e-01+2.6094e-02j,
         -4.3429e-02-7.2823e-02j, -4.2235e-02-2.9622e-03j,
         -7.2875e-02-1.1586e-01j,  1.7220e-01-2.6094e-02j,
         -1.3878e-17-1.3878e-17j,  1.4762e-02-6.2783e-02j,
          7.8392e-03+8.1334e-02j,  3.4771e-02+2.5431e-02j,
          4.3429e-02+7.2823e-02j, -1.4762e-02+6.2783e-02j,
         -1.0408e-17+1.2143e-17j, -1.2245e-02-4.2899e-02j,
         -3.5099e-02-1.0438e-01j,  4.2235e-02+2.9622e-03j,
         -7.8392e-03-8.1334e-02j,  1.2245e-02+4.2899e-02j,
         -1.0408e-17+3.4694e-18j],
        [ 0.0000e+00+0.0000e+00j, -4.3593e-02+5.7957e-02j,
         -3.0060e-02+2.1465e-02j,  7.2283e-02-1.6159e-01j,
         -1.3125e-01-5.7877e-02j,  4.3593e-02-5.7957e-02j,
          6.9389e-18+0.0000e+00j,  2.4607e-02+2.4344e-02j,
          3.7373e-02-5.9157e-03j,  5.0255e-03-7.1835e-02j,
          3.0060e-02-2.1465e-02j, -2.4607e-02-2.4344e-02j,
          6.9389e-18-5.1174e-17j,  9.4182e-02+1.2057e-02j,
         -3.2556e-02-7.2616e-02j, -7.2283e-02+1.6159e-01j,
         -3.7373e-02+5.9157e-03j, -9.4182e-02-1.2057e-02j,
          0.0000e+00+6.9389e-18j,  1.2473e-01+1.4288e-01j,
          1.3125e-01+5.7877e-02j, -5.0255e-03+7.1835e-02j,
          3.2556e-02+7.2616e-02j, -1.2473e-01-1.4288e-01j,
         -6.9389e-18+0.0000e+00j],
        [-1.3878e-17+0.0000e+00j, -1.0786e-01-1.4100e-02j,
         -1.1987e-02-1.1119e-05j, -3.0054e-02-4.6212e-02j,
          3.2615e-02+8.8762e-02j,  1.0786e-01+1.4100e-02j,
          0.0000e+00-2.6021e-18j, -3.9304e-02+4.3558e-02j,
         -1.6432e-02+2.4273e-02j,  2.0503e-02-2.8073e-02j,
          1.1987e-02+1.1119e-05j,  3.9304e-02-4.3558e-02j,
          1.7347e-18+1.3878e-17j,  2.6494e-02+2.6615e-05j,
          1.6579e-02-4.6121e-02j,  3.0054e-02+4.6212e-02j,
          1.6432e-02-2.4273e-02j, -2.6494e-02-2.6615e-05j,
          1.7347e-17+6.9389e-18j,  9.9819e-03+1.8046e-02j,
         -3.2615e-02-8.8762e-02j, -2.0503e-02+2.8073e-02j,
         -1.6579e-02+4.6121e-02j, -9.9819e-03-1.8046e-02j,
          1.3878e-17+4.1633e-17j],
        [-6.9389e-18+0.0000e+00j, -3.2992e-02+0.0000e+00j,
         -6.6083e-02+0.0000e+00j, -9.0341e-02+0.0000e+00j,
         -2.7061e-02+0.0000e+00j,  3.2992e-02+0.0000e+00j,
         -6.9389e-18+0.0000e+00j,  6.7713e-02+0.0000e+00j,
         -9.2829e-02+0.0000e+00j,  8.0577e-02+0.0000e+00j,
          6.6083e-02+0.0000e+00j, -6.7713e-02+0.0000e+00j,
          2.0817e-17+0.0000e+00j,  7.8642e-02+0.0000e+00j,
         -1.8514e-01+0.0000e+00j,  9.0341e-02+0.0000e+00j,
          9.2829e-02+0.0000e+00j, -7.8642e-02+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  1.8803e-01+0.0000e+00j,
          2.7061e-02+0.0000e+00j, -8.0577e-02+0.0000e+00j,
          1.8514e-01+0.0000e+00j, -1.8803e-01+0.0000e+00j,
          1.7347e-17+0.0000e+00j],
        [ 4.3368e-18-6.9389e-18j,  6.8702e-03+7.3241e-03j,
         -4.0615e-02-2.5865e-02j,  2.9369e-03+1.4148e-02j,
         -9.0543e-02-6.9655e-02j, -6.8702e-03-7.3241e-03j,
          2.0600e-18+1.7347e-18j, -1.8620e-02-3.7599e-02j,
          4.0754e-02+2.9696e-02j, -1.0373e-02-6.6466e-02j,
          4.0615e-02+2.5865e-02j,  1.8620e-02+3.7599e-02j,
         -3.4694e-18-6.9389e-18j, -6.0356e-02+5.3712e-02j,
          8.9665e-02+5.2901e-02j, -2.9369e-03-1.4148e-02j,
         -4.0754e-02-2.9696e-02j,  6.0356e-02-5.3712e-02j,
          1.3878e-17-1.3878e-17j, -1.2334e-02-9.3802e-02j,
          9.0543e-02+6.9655e-02j,  1.0373e-02+6.6466e-02j,
         -8.9665e-02-5.2901e-02j,  1.2334e-02+9.3802e-02j,
         -1.3878e-17+1.7347e-17j],
        [ 3.4694e-18+1.3878e-17j,  1.0497e-02-9.2706e-02j,
          4.5012e-02+6.2518e-02j,  7.1832e-02+4.8118e-02j,
         -9.9208e-02-1.6916e-01j, -1.0497e-02+9.2706e-02j,
          3.4694e-18+0.0000e+00j,  1.2097e-02+6.4037e-02j,
         -8.2413e-02-3.1812e-02j,  1.2173e-01+4.2776e-02j,
         -4.5012e-02-6.2518e-02j, -1.2097e-02-6.4037e-02j,
          3.4694e-18+0.0000e+00j,  1.4039e-01+2.4822e-02j,
         -1.1078e-01-1.5962e-01j, -7.1832e-02-4.8118e-02j,
          8.2413e-02+3.1812e-02j, -1.4039e-01-2.4822e-02j,
         -6.9389e-18+0.0000e+00j, -5.3048e-03+1.6784e-01j,
          9.9208e-02+1.6916e-01j, -1.2173e-01-4.2776e-02j,
          1.1078e-01+1.5962e-01j,  5.3048e-03-1.6784e-01j,
         -5.5511e-17+1.0408e-17j],
        [ 1.0408e-17+8.6736e-18j, -1.0254e-02-5.1909e-02j,
         -1.4988e-02-7.0141e-02j,  3.2192e-02+2.3254e-02j,
         -7.1570e-02+6.5956e-02j,  1.0254e-02+5.1909e-02j,
         -3.4694e-18+1.3878e-17j,  4.4784e-02-6.6121e-02j,
          2.8896e-02+8.0023e-03j,  5.4034e-02+4.1865e-02j,
          1.4988e-02+7.0141e-02j, -4.4784e-02+6.6121e-02j,
          1.3878e-17+3.4694e-18j,  1.1106e-01-2.9736e-02j,
          1.7417e-01-5.4374e-02j, -3.2192e-02-2.3254e-02j,
         -2.8896e-02-8.0023e-03j, -1.1106e-01+2.9736e-02j,
         -6.9389e-18-1.7347e-18j,  1.6651e-02+1.4813e-02j,
          7.1570e-02-6.5956e-02j, -5.4034e-02-4.1865e-02j,
         -1.7417e-01+5.4374e-02j, -1.6651e-02-1.4813e-02j,
          0.0000e+00-1.2143e-17j],
        [-5.2042e-18-6.9389e-18j,  1.1476e-01-1.5870e-02j,
         -5.2279e-02-1.9017e-02j, -2.1577e-02+1.6481e-02j,
         -5.4579e-02-6.0388e-02j, -1.1476e-01+1.5870e-02j,
         -2.7756e-17-1.2143e-17j,  5.6335e-02+1.0330e-01j,
          2.7058e-02+8.3079e-02j, -3.3456e-02+8.0641e-02j,
          5.2279e-02+1.9017e-02j, -5.6335e-02-1.0330e-01j,
          2.0817e-17+3.4694e-18j,  5.8635e-02-1.4922e-02j,
         -1.7083e-02+3.7584e-02j,  2.1577e-02-1.6481e-02j,
         -2.7058e-02-8.3079e-02j, -5.8635e-02+1.4922e-02j,
         -2.4286e-17+1.3878e-17j, -1.4714e-02+3.4101e-02j,
          5.4579e-02+6.0388e-02j,  3.3456e-02-8.0641e-02j,
          1.7083e-02-3.7584e-02j,  1.4714e-02-3.4101e-02j,
         -6.9389e-18+6.9389e-18j],
        [ 4.3368e-18+6.9389e-18j,  6.8702e-03-7.3241e-03j,
         -4.0615e-02+2.5865e-02j,  2.9369e-03-1.4148e-02j,
         -9.0543e-02+6.9655e-02j, -6.8702e-03+7.3241e-03j,
          2.0600e-18-1.7347e-18j, -1.8620e-02+3.7599e-02j,
          4.0754e-02-2.9696e-02j, -1.0373e-02+6.6466e-02j,
          4.0615e-02-2.5865e-02j,  1.8620e-02-3.7599e-02j,
         -3.4694e-18+6.9389e-18j, -6.0356e-02-5.3712e-02j,
          8.9665e-02-5.2901e-02j, -2.9369e-03+1.4148e-02j,
         -4.0754e-02+2.9696e-02j,  6.0356e-02+5.3712e-02j,
          1.3878e-17+1.3878e-17j, -1.2334e-02+9.3802e-02j,
          9.0543e-02-6.9655e-02j,  1.0373e-02-6.6466e-02j,
         -8.9665e-02+5.2901e-02j,  1.2334e-02-9.3802e-02j,
         -1.3878e-17-1.7347e-17j],
        [ 1.0408e-17+0.0000e+00j,  8.0146e-03+0.0000e+00j,
          1.2755e-01+0.0000e+00j,  8.0794e-02+0.0000e+00j,
          1.1286e-01+0.0000e+00j, -8.0146e-03+0.0000e+00j,
          3.1442e-18+0.0000e+00j,  7.8845e-02+0.0000e+00j,
          3.7743e-02+0.0000e+00j,  8.6193e-02+0.0000e+00j,
         -1.2755e-01+0.0000e+00j, -7.8845e-02+0.0000e+00j,
          2.6021e-18+0.0000e+00j, -4.3793e-02+0.0000e+00j,
         -6.3452e-02+0.0000e+00j, -8.0794e-02+0.0000e+00j,
         -3.7743e-02+0.0000e+00j,  4.3793e-02+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -7.1973e-02+0.0000e+00j,
         -1.1286e-01+0.0000e+00j, -8.6193e-02+0.0000e+00j,
          6.3452e-02+0.0000e+00j,  7.1973e-02+0.0000e+00j,
         -1.5613e-17+0.0000e+00j],
        [ 0.0000e+00-1.3878e-17j,  1.7191e-02+9.2885e-02j,
          7.9089e-02-1.7069e-01j,  1.3416e-01-3.1222e-02j,
          9.0563e-02-4.3217e-02j, -1.7191e-02-9.2885e-02j,
          2.6021e-18-3.4694e-18j, -8.3212e-02-1.2963e-02j,
          6.0296e-03-1.0190e-03j, -5.3545e-02+1.0717e-02j,
         -7.9089e-02+1.7069e-01j,  8.3212e-02+1.2963e-02j,
         -1.3878e-17+1.3878e-17j,  1.3266e-02-8.7509e-02j,
          1.3995e-01-1.5477e-02j, -1.3416e-01+3.1222e-02j,
         -6.0296e-03+1.0190e-03j, -1.3266e-02+8.7509e-02j,
         -1.7347e-17-1.3878e-17j, -5.8809e-02+1.0701e-01j,
         -9.0563e-02+4.3217e-02j,  5.3545e-02-1.0717e-02j,
         -1.3995e-01+1.5477e-02j,  5.8809e-02-1.0701e-01j,
          7.6328e-17-8.6736e-18j],
        [ 0.0000e+00-1.3878e-17j, -3.7573e-02-7.7907e-02j,
          4.6035e-02-6.6814e-02j, -2.1693e-02+4.8489e-02j,
         -9.9979e-02+2.3255e-01j,  3.7573e-02+7.7907e-02j,
          0.0000e+00+6.9389e-18j,  6.0520e-03+1.1633e-01j,
          4.8529e-02-4.3703e-02j, -1.5943e-03-7.8042e-02j,
         -4.6035e-02+6.6814e-02j, -6.0520e-03-1.1633e-01j,
          0.0000e+00+0.0000e+00j,  2.2297e-02+8.6667e-02j,
         -1.2852e-01+1.5376e-01j,  2.1693e-02-4.8489e-02j,
         -4.8529e-02+4.3703e-02j, -2.2297e-02-8.6667e-02j,
          1.3878e-17-3.4694e-18j,  1.3523e-01+4.3699e-02j,
          9.9979e-02-2.3255e-01j,  1.5943e-03+7.8042e-02j,
          1.2852e-01-1.5376e-01j, -1.3523e-01-4.3699e-02j,
          4.1633e-17+6.9389e-17j],
        [ 1.3878e-17-1.3878e-17j,  1.8553e-01+7.3818e-02j,
          7.2875e-02-1.1586e-01j, -3.4771e-02+2.5431e-02j,
          3.5099e-02-1.0438e-01j, -1.8553e-01-7.3818e-02j,
         -1.3878e-17-1.3878e-17j, -1.7220e-01-2.6094e-02j,
         -4.3429e-02+7.2823e-02j, -4.2235e-02+2.9622e-03j,
         -7.2875e-02+1.1586e-01j,  1.7220e-01+2.6094e-02j,
         -1.3878e-17+1.3878e-17j,  1.4762e-02+6.2783e-02j,
          7.8392e-03-8.1334e-02j,  3.4771e-02-2.5431e-02j,
          4.3429e-02-7.2823e-02j, -1.4762e-02-6.2783e-02j,
         -1.0408e-17-1.2143e-17j, -1.2245e-02+4.2899e-02j,
         -3.5099e-02+1.0438e-01j,  4.2235e-02-2.9622e-03j,
         -7.8392e-03+8.1334e-02j,  1.2245e-02-4.2899e-02j,
         -1.0408e-17-3.4694e-18j],
        [ 3.4694e-18-1.3878e-17j,  1.0497e-02+9.2706e-02j,
          4.5012e-02-6.2518e-02j,  7.1832e-02-4.8118e-02j,
         -9.9208e-02+1.6916e-01j, -1.0497e-02-9.2706e-02j,
          3.4694e-18+0.0000e+00j,  1.2097e-02-6.4037e-02j,
         -8.2413e-02+3.1812e-02j,  1.2173e-01-4.2776e-02j,
         -4.5012e-02+6.2518e-02j, -1.2097e-02+6.4037e-02j,
          3.4694e-18+0.0000e+00j,  1.4039e-01-2.4822e-02j,
         -1.1078e-01+1.5962e-01j, -7.1832e-02+4.8118e-02j,
          8.2413e-02-3.1812e-02j, -1.4039e-01+2.4822e-02j,
         -6.9389e-18+0.0000e+00j, -5.3048e-03-1.6784e-01j,
          9.9208e-02-1.6916e-01j, -1.2173e-01+4.2776e-02j,
          1.1078e-01-1.5962e-01j,  5.3048e-03+1.6784e-01j,
         -5.5511e-17-1.0408e-17j],
        [ 0.0000e+00+1.3878e-17j,  1.7191e-02-9.2885e-02j,
          7.9089e-02+1.7069e-01j,  1.3416e-01+3.1222e-02j,
          9.0563e-02+4.3217e-02j, -1.7191e-02+9.2885e-02j,
          2.6021e-18+3.4694e-18j, -8.3212e-02+1.2963e-02j,
          6.0296e-03+1.0190e-03j, -5.3545e-02-1.0717e-02j,
         -7.9089e-02-1.7069e-01j,  8.3212e-02-1.2963e-02j,
         -1.3878e-17-1.3878e-17j,  1.3266e-02+8.7509e-02j,
          1.3995e-01+1.5477e-02j, -1.3416e-01-3.1222e-02j,
         -6.0296e-03-1.0190e-03j, -1.3266e-02-8.7509e-02j,
         -1.7347e-17+1.3878e-17j, -5.8809e-02-1.0701e-01j,
         -9.0563e-02-4.3217e-02j,  5.3545e-02+1.0717e-02j,
         -1.3995e-01-1.5477e-02j,  5.8809e-02+1.0701e-01j,
          7.6328e-17+8.6736e-18j],
        [ 1.2360e-17+0.0000e+00j, -4.8360e-02+0.0000e+00j,
         -5.4196e-02+0.0000e+00j,  2.3771e-01+0.0000e+00j,
         -1.3484e-01+0.0000e+00j,  4.8360e-02+0.0000e+00j,
          1.1276e-17+0.0000e+00j,  7.2984e-02+0.0000e+00j,
         -1.0166e-01+0.0000e+00j,  8.4516e-02+0.0000e+00j,
          5.4196e-02+0.0000e+00j, -7.2984e-02+0.0000e+00j,
          2.1684e-17+0.0000e+00j,  2.1986e-01+0.0000e+00j,
         -1.3013e-01+0.0000e+00j, -2.3771e-01+0.0000e+00j,
          1.0166e-01+0.0000e+00j, -2.1986e-01+0.0000e+00j,
         -1.0408e-17+0.0000e+00j,  2.4268e-02+0.0000e+00j,
          1.3484e-01+0.0000e+00j, -8.4516e-02+0.0000e+00j,
          1.3013e-01+0.0000e+00j, -2.4268e-02+0.0000e+00j,
          0.0000e+00+0.0000e+00j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 0.31628528141966716.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_pinv_hermitian_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_pinv_singular_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_pinv_singular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_qr_cpu_complex128" time="0.713" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_qr_cpu_float64" time="0.178" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_slogdet_cpu_complex128" time="0.189" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_slogdet_cpu_float64" time="0.038" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_solve_cpu_complex128" time="0.308" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_solve_cpu_float64" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_solve_ex_cpu_complex128" time="0.310" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_solve_ex_cpu_float64" time="0.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_solve_triangular_cpu_float64" time="0.928" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_svd_cpu_complex128" time="2.198" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_svd_cpu_float64" time="0.636" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_svdvals_cpu_complex128" time="0.173" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_svdvals_cpu_float64" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_vander_cpu_complex128" time="0.113" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_vander_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_vecdot_cpu_float64" time="0.110" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_vector_norm_cpu_complex128" time="0.852" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linalg_vector_norm_cpu_float64" time="0.325" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linspace_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_linspace_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log10_cpu_complex128" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log10_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log1p_cpu_complex128" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log1p_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log2_cpu_complex128" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log2_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log_cpu_complex128" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log_normal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log_softmax_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log_softmax_with_dtype_cpu_complex128" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_log_softmax_with_dtype_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logaddexp2_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logaddexp_cpu_complex128" time="0.152" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logaddexp_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logcumsumexp_cpu_complex128" time="0.073" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logcumsumexp_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logdet_cpu_complex128" time="0.118" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logdet_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_and_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_and_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_not_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_not_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_or_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_or_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_xor_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logical_xor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logit_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logspace_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logspace_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_logsumexp_cpu_float64" time="0.127" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_long_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_long_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lt_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lu_cpu_float64" time="0.188" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\functional.py:1731: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2001.)
  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lu_solve_cpu_float64" time="0.316" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\opinfo\core.py:769: UserWarning: torch.lu_solve is deprecated in favor of torch.linalg.lu_solveand will be removed in a future PyTorch release.
Note that torch.linalg.lu_solve has its arguments reversed.
X = torch.lu_solve(B, LU, pivots)
should be replaced with
X = torch.linalg.lu_solve(LU, pivots, B) (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2155.)
  gradcheck_wrapper: Callable = lambda op, *args, **kwargs: op(*args, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lu_unpack_cpu_complex128" time="0.304" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_lu_unpack_cpu_float64" time="0.059" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mH_cpu_complex128" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mH_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mT_cpu_complex128" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mT_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_amax_cpu_float64" time="0.207" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_amin_cpu_float64" time="0.205" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_argmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_argmin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_cumprod_cpu_complex128" time="0.228" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_cumprod_cpu_float64" time="0.051" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_cumsum_cpu_complex128" time="0.217" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_cumsum_cpu_float64" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_fill_cpu_complex128" time="0.087" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_fill_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_log_softmax_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_logaddexp_cpu_float64" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_logsumexp_cpu_float64" time="0.208" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_mean_cpu_complex128" time="1.157" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_mean_cpu_float64" time="0.231" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_median_cpu_float64" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_norm_cpu_float64" time="0.997" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_normalize_cpu_complex128" time="0.456" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_normalize_cpu_float64" time="0.093" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_prod_cpu_complex128" time="0.950" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_prod_cpu_float64" time="0.206" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_scatter_cpu_complex128" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_scatter_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_select_cpu_complex128" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_select_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_softmax_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_softmin_cpu_float64" time="0.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_std_cpu_complex128" time="0.901" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_std_cpu_float64" time="0.183" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_sum_cpu_complex128" time="0.796" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_sum_cpu_float64" time="0.162" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_var_cpu_complex128" time="0.859" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_masked_var_cpu_float64" time="0.177" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_matmul_cpu_complex128" time="0.035" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(0.+0.j, dtype=torch.complex128)&#10;analytical:tensor(1.5615+1.1193j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[-6.8891+7.0825j],&#10;        [-6.5380+1.2241j],&#10;        [-5.3124-0.4063j],&#10;        [-4.6739-5.1440j],&#10;        [ 5.7468-3.3382j],&#10;        [ 0.4634+7.8413j],&#10;        [-2.3356+0.5779j],&#10;        [-3.4766-4.8642j],&#10;        [ 6.1016+6.0707j],&#10;        [ 4.3780-2.1708j],&#10;        [-0.0724+6.1419j],&#10;        [-2.2541-0.2617j],&#10;        [ 3.2614-5.6582j],&#10;        [ 1.1346+0.7961j],&#10;        [-3.5929+4.7102j],&#10;        [ 0.0173-0.6015j],&#10;        [-2.5660+1.5537j],&#10;        [ 3.3419+4.1913j],&#10;        [-0.1587+4.0362j],&#10;        [ 8.8151-4.4800j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 9.888138490228771.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 26, in test_fn_grad
    self._grad_test_helper(device, dtype, op, op.get_op())
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4372, in _grad_test_helper
    return self._check_helper(device, dtype, op, variant, 'gradcheck', check_forward_ad=check_forward_ad,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4341, in _check_helper
    self.assertTrue(gradcheck(fn, gradcheck_args,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3896, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.+0.j, dtype=torch.complex128)
analytical:tensor(1.5615+1.1193j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j]], dtype=torch.complex128)
Analytical:
tensor([[-6.8891+7.0825j],
        [-6.5380+1.2241j],
        [-5.3124-0.4063j],
        [-4.6739-5.1440j],
        [ 5.7468-3.3382j],
        [ 0.4634+7.8413j],
        [-2.3356+0.5779j],
        [-3.4766-4.8642j],
        [ 6.1016+6.0707j],
        [ 4.3780-2.1708j],
        [-0.0724+6.1419j],
        [-2.2541-0.2617j],
        [ 3.2614-5.6582j],
        [ 1.1346+0.7961j],
        [-3.5929+4.7102j],
        [ 0.0173-0.6015j],
        [-2.5660+1.5537j],
        [ 3.3419+4.1913j],
        [-0.1587+4.0362j],
        [ 8.8151-4.4800j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 9.888138490228771.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_matmul_cpu_float64" time="0.047" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_matrix_exp_cpu_complex128" time="0.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_matrix_exp_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_max_binary_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_max_pool2d_with_indices_backward_cpu_float64" time="3.569" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_max_reduction_no_dim_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_max_reduction_with_dim_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_maximum_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mean_cpu_complex128" time="0.189" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mean_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_median_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_meshgrid_list_of_tensors_cpu_complex128" time="0.303" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_meshgrid_list_of_tensors_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_meshgrid_variadic_tensors_cpu_complex128" time="0.302" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_meshgrid_variadic_tensors_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_min_binary_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_min_reduction_no_dim_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_min_reduction_with_dim_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_minimum_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mm_cpu_complex128" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mm_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mode_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_movedim_cpu_complex128" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_movedim_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_msort_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mul_cpu_complex128" time="0.132" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mul_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_multinomial_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mv_cpu_complex128" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mv_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mvlgamma_mvlgamma_p_1_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mvlgamma_mvlgamma_p_3_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_mvlgamma_mvlgamma_p_5_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nan_to_num_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nanmean_cpu_float64" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nanmedian_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nanquantile_cpu_float64" time="0.243" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nansum_cpu_float64" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_narrow_copy_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_narrow_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_narrow_cpu_complex128" time="0.084" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_narrow_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_native_batch_norm_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_native_dropout_backward_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_native_layer_norm_cpu_float64" time="0.085" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ne_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ne_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_neg_cpu_complex128" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_neg_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_empty_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_empty_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_empty_strided_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_empty_strided_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_full_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_full_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_ones_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_ones_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_zeros_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_new_zeros_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nextafter_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_adaptive_avg_pool1d_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_adaptive_avg_pool2d_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_adaptive_avg_pool3d_cpu_float64" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_adaptive_max_pool1d_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_adaptive_max_pool2d_cpu_float64" time="0.067" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_adaptive_max_pool3d_cpu_float64" time="0.054" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_alpha_dropout_cpu_float64" time="0.180" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_avg_pool1d_cpu_float64" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_avg_pool2d_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_avg_pool3d_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_batch_norm_cpu_float64" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_bilinear_cpu_float64" time="0.177" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_binary_cross_entropy_cpu_float64" time="0.226" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_binary_cross_entropy_with_logits_cpu_float64" time="0.094" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_celu_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv1d_cpu_complex128" time="0.589" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv1d_cpu_float64" time="0.088" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv2d_cpu_complex128" time="1.810" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\opinfo\core.py:769: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Convolution.cpp:1004.)
  gradcheck_wrapper: Callable = lambda op, *args, **kwargs: op(*args, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv2d_cpu_float64" time="0.186" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv_transpose1d_cpu_complex128" time="0.417" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv_transpose1d_cpu_float64" time="0.060" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv_transpose2d_cpu_complex128" time="0.677" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv_transpose2d_cpu_float64" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv_transpose3d_cpu_complex128" time="1.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_conv_transpose3d_cpu_float64" time="0.088" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_cosine_embedding_loss_cpu_float64" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_cosine_similarity_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_cross_entropy_cpu_float64" time="0.057" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_ctc_loss_cpu_float64" time="12.625" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_dropout2d_cpu_float64" time="0.067" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_dropout3d_cpu_float64" time="0.072" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_dropout_cpu_float64" time="0.091" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_elu_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_embedding_bag_cpu_float64" time="0.115" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_embedding_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_feature_alpha_dropout_with_train_cpu_float64" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_feature_alpha_dropout_without_train_cpu_complex128" time="0.424" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_feature_alpha_dropout_without_train_cpu_float64" time="0.075" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_fractional_max_pool2d_cpu_float64" time="0.190" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_fractional_max_pool3d_cpu_float64" time="0.356" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_gaussian_nll_loss_cpu_float64" time="1.784" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_gelu_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_glu_cpu_float64" time="0.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_grid_sample_cpu_float64" time="0.123" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_group_norm_cpu_float64" time="0.118" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_hardshrink_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_hardsigmoid_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_hardswish_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_hardtanh_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_hinge_embedding_loss_cpu_float64" time="0.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_huber_loss_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_instance_norm_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_interpolate_area_cpu_float64" time="0.068" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_interpolate_bicubic_cpu_float64" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_interpolate_bilinear_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_interpolate_linear_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_interpolate_nearest_cpu_float64" time="0.038" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_interpolate_trilinear_cpu_float64" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_kl_div_cpu_float64" time="0.053" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_l1_loss_cpu_complex128" time="0.066" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_l1_loss_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_layer_norm_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_leaky_relu_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_linear_cpu_complex128" time="0.306" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_linear_cpu_float64" time="0.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_local_response_norm_cpu_float64" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_logsigmoid_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_margin_ranking_loss_cpu_float64" time="0.086" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_pool1d_cpu_float64" time="2.116" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_pool2d_cpu_float64" time="3.427" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_pool3d_cpu_float64" time="1.563" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_unpool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_unpool1d_grad_cpu_float64" time="0.108" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_unpool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_unpool2d_grad_cpu_float64" time="0.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_unpool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_max_unpool3d_grad_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_mish_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_mse_loss_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_multi_margin_loss_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_multilabel_margin_loss_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_multilabel_soft_margin_loss_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_nll_loss_cpu_float64" time="0.178" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_normalize_cpu_complex128" time="0.119" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_normalize_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_circular_cpu_complex128" time="0.090" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_circular_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_constant_cpu_complex128" time="0.416" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_constant_cpu_float64" time="0.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_reflect_cpu_complex128" time="0.110" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_reflect_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_replicate_cpu_complex128" time="0.107" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pad_replicate_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pairwise_distance_cpu_complex128" time="0.088" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pairwise_distance_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pdist_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pixel_shuffle_cpu_complex128" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pixel_shuffle_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pixel_unshuffle_cpu_complex128" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_pixel_unshuffle_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_poisson_nll_loss_cpu_float64" time="0.273" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_prelu_cpu_float64" time="0.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_relu6_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_relu_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_rrelu_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_scaled_dot_product_attention_cpu_float64" time="0.180" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_selu_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_silu_complex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_silu_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_smooth_l1_loss_cpu_float64" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_soft_margin_loss_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_softmin_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_softmin_with_dtype_cpu_complex128" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_softmin_with_dtype_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_softplus_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_softshrink_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_softsign_cpu_complex128" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_softsign_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_tanhshrink_cpu_complex128" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_tanhshrink_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_threshold_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_triplet_margin_loss_cpu_complex128" time="0.112" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_triplet_margin_loss_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_triplet_margin_with_distance_loss_cpu_complex128" time="0.122" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_triplet_margin_with_distance_loss_cpu_float64" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_unfold_cpu_complex128" time="1.633" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_unfold_cpu_float64" time="0.313" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_upsample_bilinear_cpu_float64" time="0.011" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nn_functional_upsample_nearest_cpu_float64" time="0.026" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nonzero_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nonzero_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nonzero_static_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_nonzero_static_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_cpu_complex128" time="0.219" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_cpu_float64" time="0.083" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_fro_cpu_complex128" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_fro_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_inf_cpu_complex128" time="0.146" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_inf_cpu_float64" time="0.038" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_nuc_cpu_complex128" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_norm_nuc_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_normal_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_normal_in_place_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_normal_in_place_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_normal_number_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ones_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ones_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ones_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ones_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ormqr_cpu_complex128" time="4.134" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ormqr_cpu_float64" time="0.877" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_outer_cpu_complex128" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_outer_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_pca_lowrank_cpu_float64" time="4.107" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_permute_cpu_complex128" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_permute_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_pinverse_cpu_complex128" time="0.100" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_pinverse_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_polar_cpu_float64" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_polygamma_polygamma_n_0_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_polygamma_polygamma_n_1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_polygamma_polygamma_n_2_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_polygamma_polygamma_n_3_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_polygamma_polygamma_n_4_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_positive_cpu_complex128" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_positive_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_pow_cpu_complex128" time="0.158" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_pow_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_prod_cpu_complex128" time="0.342" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_prod_cpu_float64" time="0.077" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_put_cpu_complex128" time="0.297" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_put_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_qr_cpu_complex128" time="0.720" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\opinfo\core.py:769: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2431.)
  gradcheck_wrapper: Callable = lambda op, *args, **kwargs: op(*args, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_qr_cpu_float64" time="0.233" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_quantile_cpu_float64" time="0.251" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rad2deg_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rand_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rand_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_randint_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_randint_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_randn_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_randn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_randn_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_randn_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ravel_cpu_complex128" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_ravel_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_real_cpu_complex128" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_real_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_reciprocal_cpu_complex128" time="0.038" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_reciprocal_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_remainder_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_renorm_cpu_complex128" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_renorm_cpu_float64" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_repeat_cpu_complex128" time="0.191" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_repeat_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_repeat_interleave_cpu_complex128" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_repeat_interleave_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_reshape_as_cpu_complex128" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_reshape_as_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_reshape_cpu_complex128" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_reshape_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resize__cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resize__cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resize_as__cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resize_as__cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resolve_conj_cpu_complex128" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resolve_conj_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resolve_neg_cpu_complex128" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_resolve_neg_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_roll_cpu_complex128" time="0.142" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_roll_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rot90_cpu_complex128" time="0.290" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rot90_cpu_float64" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_round_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_round_decimals_0_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_round_decimals_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_round_decimals_neg_3_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rsqrt_cpu_complex128" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rsqrt_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rsub_cpu_complex128" time="0.146" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_rsub_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scalar_tensor_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scalar_tensor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_add_cpu_complex128" time="0.100" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_add_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_cpu_complex128" time="0.109" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_reduce_amax_cpu_float64" time="0.067" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_reduce_amin_cpu_float64" time="0.067" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_reduce_mean_cpu_float64" time="0.070" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_reduce_prod_cpu_float64" time="0.084" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_scatter_reduce_sum_cpu_float64" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_searchsorted_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_select_cpu_complex128" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_select_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_select_scatter_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sgn_cpu_complex128" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sgn_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_short_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_short_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sigmoid_cpu_complex128" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sigmoid_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sign_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_bartlett_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_blackman_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_cosine_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_exponential_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_gaussian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_general_cosine_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_general_hamming_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_hamming_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_hann_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_kaiser_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signal_windows_nuttall_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_signbit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sin_cpu_complex128" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sin_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sinc_cpu_complex128" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sinc_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sinh_cpu_complex128" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sinh_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_slice_cpu_complex128" time="0.098" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_slice_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_slice_scatter_cpu_float64" time="0.060" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_softmax_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_softmax_with_dtype_cpu_complex128" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_softmax_with_dtype_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sort_cpu_float64" time="0.117" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sparse_mm_reduce_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sparse_sampled_addmm_cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sparse_sampled_addmm_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_airy_ai_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_bessel_j0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_bessel_j1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_bessel_y0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_bessel_y1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_chebyshev_polynomial_t_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_chebyshev_polynomial_u_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_chebyshev_polynomial_v_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_chebyshev_polynomial_w_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_entr_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_erfcx_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_hermite_polynomial_h_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_hermite_polynomial_he_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_i0e_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_i1_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_i1e_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_laguerre_polynomial_l_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_legendre_polynomial_p_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_log_ndtr_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_modified_bessel_i0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_modified_bessel_i1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_modified_bessel_k0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_modified_bessel_k1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_ndtr_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_ndtri_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_polygamma_special_polygamma_n_0_cpu_float64" time="0.035" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_scaled_modified_bessel_k0_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_scaled_modified_bessel_k1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_shifted_chebyshev_polynomial_t_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_shifted_chebyshev_polynomial_u_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_shifted_chebyshev_polynomial_v_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_shifted_chebyshev_polynomial_w_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_spherical_bessel_j0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_xlog1py_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_special_zeta_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_split_cpu_complex128" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_split_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_split_list_args_cpu_complex128" time="0.068" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_split_list_args_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_split_with_sizes_cpu_complex128" time="0.085" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_split_with_sizes_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sqrt_cpu_complex128" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sqrt_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_square_cpu_complex128" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_square_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_squeeze_cpu_complex128" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_squeeze_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_squeeze_multiple_cpu_complex128" time="0.047" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_squeeze_multiple_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_stack_cpu_complex128" time="0.133" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_stack_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_cpu_complex128" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_cpu_float64" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_mean_cpu_complex128" time="0.165" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_mean_cpu_float64" time="0.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_mean_unbiased_cpu_complex128" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_mean_unbiased_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_unbiased_cpu_complex128" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_std_unbiased_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_stft_cpu_complex128" time="0.121" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\functional.py:642: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.
Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\SpectralOps.cpp:868.)
  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_stft_cpu_float64" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sub_cpu_complex128" time="0.156" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sub_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sum_cpu_complex128" time="0.160" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sum_cpu_float64" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sum_to_size_cpu_complex128" time="0.128" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_sum_to_size_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_svd_cpu_complex128" time="2.488" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_svd_cpu_float64" time="0.666" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_svd_lowrank_cpu_float64" time="5.213" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_t_cpu_complex128" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_t_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_take_along_dim_cpu_complex128" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_take_along_dim_cpu_float64" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_take_cpu_complex128" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_take_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tan_cpu_complex128" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tan_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tanh_cpu_complex128" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tanh_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tensor_split_cpu_complex128" time="0.212" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tensor_split_cpu_float64" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tensordot_cpu_complex128" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tensordot_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tile_cpu_complex128" time="0.220" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tile_cpu_float64" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_to_cpu_complex128" time="0.132" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_to_cpu_float64" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_to_sparse_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_to_sparse_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_topk_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_trace_cpu_complex128" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_trace_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_transpose_cpu_complex128" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_transpose_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_trapezoid_cpu_complex128" time="0.147" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_trapezoid_cpu_float64" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_trapz_cpu_complex128" time="0.147" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_trapz_cpu_float64" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_triangular_solve_cpu_complex128" time="0.413" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\opinfo\core.py:2714: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.
torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.
X = torch.triangular_solve(B, A).solution
should be replaced with
X = torch.linalg.solve_triangular(A, B). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\BatchLinearAlgebra.cpp:2197.)
  return op(*args[:idx], triangular_arg, *args[idx + 1 :], upper, **kwargs)
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_triangular_solve_cpu_float64" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tril_cpu_complex128" time="0.103" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_tril_cpu_float64" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_triu_cpu_complex128" time="0.097" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_triu_cpu_float64" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_true_divide_cpu_complex128" time="0.132" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_true_divide_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_trunc_cpu_float64" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unbind_cpu_complex128" time="0.202" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unbind_cpu_float64" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unflatten_cpu_complex128" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unflatten_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unfold_copy_cpu_complex128" time="0.209" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unfold_copy_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unfold_cpu_complex128" time="0.203" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unfold_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_uniform_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_uniform_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unique_consecutive_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unique_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unsafe_split_cpu_complex128" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unsafe_split_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unsqueeze_cpu_complex128" time="0.072" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_unsqueeze_cpu_float64" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_cpu_complex128" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_mean_cpu_complex128" time="0.159" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_mean_cpu_float64" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_mean_unbiased_cpu_complex128" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_mean_unbiased_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_unbiased_cpu_complex128" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_var_unbiased_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_vdot_cpu_complex128" time="0.014" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(0.+0.j, dtype=torch.complex128)&#10;analytical:tensor(8.4992-3.1575j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j],&#10;        [0.+0.j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 0.5886+6.1278j],&#10;        [ 6.3505+8.0167j],&#10;        [-8.5019-0.3712j],&#10;        [ 5.0913-8.8816j],&#10;        [ 7.9659-2.2683j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 10.237428780948914.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 26, in test_fn_grad
    self._grad_test_helper(device, dtype, op, op.get_op())
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4372, in _grad_test_helper
    return self._check_helper(device, dtype, op, variant, 'gradcheck', check_forward_ad=check_forward_ad,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4341, in _check_helper
    self.assertTrue(gradcheck(fn, gradcheck_args,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3896, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.+0.j, dtype=torch.complex128)
analytical:tensor(8.4992-3.1575j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j],
        [0.+0.j]], dtype=torch.complex128)
Analytical:
tensor([[ 0.5886+6.1278j],
        [ 6.3505+8.0167j],
        [-8.5019-0.3712j],
        [ 5.0913-8.8816j],
        [ 7.9659-2.2683j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 10.237428780948914.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_vdot_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_view_as_complex_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_view_as_cpu_complex128" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_view_as_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_view_as_real_cpu_complex128" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_view_copy_cpu_float64" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_view_cpu_complex128" time="0.056" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_view_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_vsplit_cpu_complex128" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_vsplit_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_vstack_cpu_complex128" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_vstack_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_where_cpu_complex128" time="0.087" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_where_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_xlogy_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_zero__cpu_complex128" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_zero__cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_zeros_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_zeros_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_zeros_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_grad_zeros_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Dtype is not in supported backward dtypes!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:20: Skipped! Dtype is not in supported backward dtypes!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_H_cpu_complex128" time="0.078" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_H_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_T_cpu_complex128" time="0.084" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_T_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___getitem___cpu_complex128" time="0.857" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___getitem___cpu_float64" time="0.116" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___radd___cpu_complex128" time="0.714" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___radd___cpu_float64" time="0.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rdiv___cpu_complex128" time="1.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rdiv___cpu_float64" time="0.192" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rmatmul___cpu_complex128" time="1.557" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rmatmul___cpu_float64" time="0.258" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rmod___cpu_float64" time="0.178" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rmul___cpu_complex128" time="0.760" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rmul___cpu_float64" time="0.141" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rpow___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rpow___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rsub___cpu_complex128" time="0.645" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad___rsub___cpu_float64" time="0.128" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad__native_batch_norm_legit_cpu_float64" time="0.290" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad__segment_reduce_lengths_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad__segment_reduce_offsets_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad__softmax_backward_data_cpu_float64" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad__upsample_bilinear2d_aa_cpu_float64" time="0.104" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_abs_cpu_complex128" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_abs_cpu_float64" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_acos_cpu_complex128" time="0.168" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_acos_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_acosh_cpu_complex128" time="0.134" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_acosh_cpu_float64" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_add_cpu_complex128" time="0.769" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_add_cpu_float64" time="0.174" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addbmm_cpu_complex128" time="1.942" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addbmm_cpu_float64" time="0.249" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addcdiv_cpu_complex128" time="1.878" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addcdiv_cpu_float64" time="0.317" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addcmul_cpu_complex128" time="1.769" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addcmul_cpu_float64" time="0.411" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addmm_cpu_complex128" time="0.689" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addmm_cpu_float64" time="0.113" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addmm_decomposed_cpu_complex128" time="0.912" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addmm_decomposed_cpu_float64" time="0.077" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addmv_cpu_complex128" time="1.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addmv_cpu_float64" time="0.188" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addr_cpu_complex128" time="0.596" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_addr_cpu_float64" time="0.173" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_all_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_all_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_allclose_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_allclose_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_amax_cpu_float64" time="0.137" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_amin_cpu_float64" time="0.179" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_aminmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_angle_cpu_complex128" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_angle_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_any_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_any_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_arange_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_argmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_argmin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_argsort_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_argwhere_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_argwhere_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_as_strided_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_as_strided_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_as_strided_partial_views_cpu_complex128" time="0.164" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_as_strided_partial_views_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_as_strided_scatter_cpu_complex128" time="0.545" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_as_strided_scatter_cpu_float64" time="0.154" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_asin_cpu_complex128" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_asin_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_asinh_cpu_complex128" time="0.086" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_asinh_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atan2_cpu_float64" time="0.279" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atan_cpu_complex128" time="0.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atan_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atanh_cpu_complex128" time="0.077" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atanh_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atleast_1d_cpu_complex128" time="0.560" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atleast_1d_cpu_float64" time="0.128" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atleast_2d_cpu_complex128" time="0.609" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atleast_2d_cpu_float64" time="0.120" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atleast_3d_cpu_complex128" time="0.638" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_atleast_3d_cpu_float64" time="0.111" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_baddbmm_cpu_complex128" time="2.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_baddbmm_cpu_float64" time="0.224" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bernoulli_cpu_float64" time="0.091" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bfloat16_cpu_complex128" time="0.012" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bfloat16_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_block_diag_cpu_complex128" time="0.475" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_block_diag_cpu_float64" time="0.099" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bmm_cpu_complex128" time="0.097" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bmm_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bool_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bool_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_broadcast_tensors_cpu_complex128" time="0.389" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_broadcast_tensors_cpu_float64" time="0.059" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_broadcast_to_cpu_complex128" time="0.229" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_broadcast_to_cpu_float64" time="0.062" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_bucketize_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_byte_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_byte_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cartesian_prod_cpu_complex128" time="0.426" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cartesian_prod_cpu_float64" time="0.055" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cat_cpu_complex128" time="0.365" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cat_cpu_float64" time="0.064" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cauchy_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cdist_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cdouble_cpu_complex128" time="0.188" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cdouble_cpu_float64" time="0.060" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ceil_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cfloat_cpu_complex128" time="0.017" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cfloat_cpu_float64" time="0.017" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_chalf_cpu_complex128" time="0.010" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_chalf_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_char_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_char_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cholesky_cpu_complex128" time="1.487" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cholesky_cpu_float64" time="0.306" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cholesky_inverse_cpu_complex128" time="1.194" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cholesky_inverse_cpu_float64" time="0.239" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cholesky_solve_cpu_complex128" time="1.395" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cholesky_solve_cpu_float64" time="0.239" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_chunk_cpu_complex128" time="0.255" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_chunk_cpu_float64" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_clamp_cpu_float64" time="0.170" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_clamp_max_cpu_float64" time="0.181" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_clamp_min_cpu_float64" time="0.152" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_clone_cpu_complex128" time="0.099" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_clone_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_column_stack_cpu_complex128" time="0.268" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_column_stack_cpu_float64" time="0.059" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_combinations_cpu_complex128" time="1.202" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_combinations_cpu_float64" time="0.280" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_complex_cpu_float64" time="0.238" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_conj_cpu_complex128" time="0.142" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_conj_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_conj_physical_cpu_complex128" time="0.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_conj_physical_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_constant_pad_nd_cpu_complex128" time="1.612" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_constant_pad_nd_cpu_float64" time="0.304" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_contiguous_cpu_complex128" time="0.083" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_contiguous_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_copysign_cpu_float64" time="0.104" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_corrcoef_cpu_complex128" time="0.555" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_corrcoef_cpu_float64" time="0.089" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cos_cpu_complex128" time="0.113" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cos_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cosh_cpu_complex128" time="0.144" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cosh_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_count_nonzero_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_count_nonzero_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cov_cpu_complex128" time="0.152" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cov_cpu_float64" time="0.059" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cross_cpu_complex128" time="0.334" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cross_cpu_float64" time="0.072" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cummax_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cummin_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cumprod_cpu_complex128" time="67.693" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cumprod_cpu_float64" time="10.574" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cumsum_cpu_complex128" time="0.178" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cumsum_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cumulative_trapezoid_cpu_complex128" time="0.959" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_cumulative_trapezoid_cpu_float64" time="0.247" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_deg2rad_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diag_cpu_complex128" time="0.555" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diag_cpu_float64" time="0.125" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diag_embed_cpu_complex128" time="0.749" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diag_embed_cpu_float64" time="0.159" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagflat_cpu_complex128" time="0.233" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagflat_cpu_float64" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagonal_copy_cpu_complex128" time="0.712" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagonal_copy_cpu_float64" time="0.142" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagonal_cpu_complex128" time="0.522" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagonal_cpu_float64" time="0.088" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagonal_scatter_cpu_complex128" time="1.380" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diagonal_scatter_cpu_float64" time="0.208" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diff_cpu_complex128" time="7.261" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_diff_cpu_float64" time="1.645" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_digamma_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dist_cpu_complex128" time="5.548" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dist_cpu_float64" time="1.201" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_div_floor_rounding_cpu_float64" time="0.072" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_div_no_rounding_mode_cpu_complex128" time="0.977" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_div_no_rounding_mode_cpu_float64" time="0.152" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_div_trunc_rounding_cpu_float64" time="0.090" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dot_cpu_complex128" time="0.155" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dot_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_double_cpu_complex128" time="0.133" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_double_cpu_float64" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dsplit_cpu_complex128" time="0.223" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dsplit_cpu_float64" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dstack_cpu_complex128" time="0.387" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_dstack_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_einsum_cpu_complex128" time="0.994" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_einsum_cpu_float64" time="0.179" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_empty_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_empty_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_empty_like_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_empty_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_empty_permuted_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_empty_permuted_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_eq_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_eq_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_equal_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_equal_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_erf_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_erfc_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_erfinv_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_exp2_cpu_complex128" time="0.145" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_exp2_cpu_float64" time="0.057" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_exp_cpu_complex128" time="0.167" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_exp_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_expand_as_cpu_complex128" time="0.106" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_expand_as_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_expand_cpu_complex128" time="0.393" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_expand_cpu_float64" time="0.055" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_expm1_cpu_complex128" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_expm1_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_exponential_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_eye_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_eye_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fft2_cpu_complex128" time="0.337" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fft2_cpu_float64" time="0.109" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fft_cpu_complex128" time="0.267" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fft_cpu_float64" time="0.103" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fftn_cpu_complex128" time="0.317" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fftn_cpu_float64" time="0.081" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fftshift_cpu_complex128" time="0.181" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_fftshift_cpu_float64" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_hfft2_cpu_complex128" time="0.286" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_hfft2_cpu_float64" time="0.054" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_hfft_cpu_complex128" time="0.284" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_hfft_cpu_float64" time="0.070" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_hfftn_cpu_complex128" time="0.418" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_hfftn_cpu_float64" time="0.104" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifft2_cpu_complex128" time="0.236" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifft2_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifft_cpu_complex128" time="0.298" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifft_cpu_float64" time="0.087" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifftn_cpu_complex128" time="0.332" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifftn_cpu_float64" time="0.099" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifftshift_cpu_complex128" time="0.266" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ifftshift_cpu_float64" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ihfft2_cpu_float64" time="0.070" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ihfft_cpu_float64" time="0.120" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_ihfftn_cpu_float64" time="0.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_irfft2_cpu_complex128" time="0.268" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_irfft2_cpu_float64" time="0.047" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_irfft_cpu_complex128" time="0.243" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_irfft_cpu_float64" time="0.070" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_irfftn_cpu_complex128" time="0.259" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_irfftn_cpu_float64" time="0.088" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_rfft2_cpu_float64" time="0.105" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_rfft_cpu_float64" time="0.075" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fft_rfftn_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fill_cpu_complex128" time="0.102" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fill_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_flatten_cpu_complex128" time="0.180" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_flatten_cpu_float64" time="0.072" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_flip_cpu_complex128" time="0.370" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_flip_cpu_float64" time="0.060" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fliplr_cpu_complex128" time="0.094" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fliplr_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_flipud_cpu_complex128" time="0.082" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_flipud_cpu_float64" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_float_cpu_complex128" time="0.015" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_float_cpu_float64" time="0.011" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_float_power_cpu_complex128" time="1.402" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_float_power_cpu_float64" time="0.201" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_floor_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_floor_divide_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fmax_cpu_float64" time="0.193" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fmin_cpu_float64" time="0.133" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_fmod_cpu_float64" time="0.185" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_frac_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_frexp_cpu_float64" time="0.062" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_full_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_full_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_full_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_full_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_gather_cpu_complex128" time="0.209" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_gather_cpu_float64" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ge_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_geometric_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_geqrf_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_geqrf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_gradient_cpu_complex128" time="1.763" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_gradient_cpu_float64" time="0.266" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_grid_sampler_2d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_gt_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_half_cpu_complex128" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py:735: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. 
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_half_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_heaviside_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_histc_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_histogram_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_histogramdd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_hsplit_cpu_complex128" time="0.153" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_hsplit_cpu_float64" time="0.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_hstack_cpu_complex128" time="0.260" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_hstack_cpu_float64" time="0.067" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_hypot_cpu_float64" time="0.168" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_i0_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_igamma_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_igammac_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_imag_cpu_complex128" time="0.118" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_add_cpu_complex128" time="0.685" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_add_cpu_float64" time="0.122" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_copy_cpu_complex128" time="0.277" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_copy_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_fill_cpu_complex128" time="0.320" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_fill_cpu_float64" time="0.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_put_cpu_complex128" time="0.437" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_put_cpu_float64" time="0.095" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_reduce_cpu_float64" time="0.647" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_select_cpu_complex128" time="0.108" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_index_select_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_inner_cpu_complex128" time="0.209" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_inner_cpu_float64" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_int_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_int_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isclose_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isclose_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isfinite_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isfinite_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isinf_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isinf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isnan_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isnan_cpu_float64" time="0.010" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isneginf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isposinf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isreal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_isreal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_istft_cpu_complex128" time="0.968" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_2inputs_2outputs_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_2inputs_2outputs_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_4inputs_with_extra_args_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_4inputs_with_extra_args_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_binary_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_binary_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_binary_return_by_ref_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_binary_return_by_ref_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_unary_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_jiterator_unary_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_kron_cpu_complex128" time="0.162" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_kron_cpu_float64" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_kthvalue_cpu_float64" time="0.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ldexp_cpu_complex128" time="0.921" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ldexp_cpu_float64" time="0.169" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_le_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lerp_cpu_complex128" time="2.279" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lerp_cpu_float64" time="0.269" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lgamma_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cholesky_cpu_complex128" time="1.450" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cholesky_cpu_float64" time="0.257" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cholesky_ex_cpu_complex128" time="1.382" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cholesky_ex_cpu_float64" time="0.324" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cond_cpu_complex128" time="0.223" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cond_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cross_cpu_complex128" time="0.341" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_cross_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_det_cpu_complex128" time="0.425" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_det_cpu_float64" time="0.111" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_det_singular_cpu_complex128" time="0.092" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_det_singular_cpu_float64" time="0.760" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_diagonal_cpu_complex128" time="0.646" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_diagonal_cpu_float64" time="0.115" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eig_cpu_complex128" time="1.238" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eig_cpu_float64" time="0.304" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eigh_cpu_complex128" time="0.212" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(-0.1263-0.1307j, dtype=torch.complex128)&#10;analytical:tensor(-0.2702-0.1767j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[ 0.0000e+00+0.0000e+00j, -2.7629e-02+0.0000e+00j,&#10;          1.8265e+00+0.0000e+00j,  2.4922e-01+0.0000e+00j,&#10;         -1.8255e+00+0.0000e+00j,  2.7629e-02+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  1.2710e+00+0.0000e+00j,&#10;          1.5206e+00+0.0000e+00j, -3.1934e-01+0.0000e+00j,&#10;         -1.8265e+00+0.0000e+00j, -1.2710e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  2.1956e+00+0.0000e+00j,&#10;         -2.0084e+00+0.0000e+00j, -2.4922e-01+0.0000e+00j,&#10;         -1.5206e+00+0.0000e+00j, -2.1956e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  6.8718e-01+0.0000e+00j,&#10;          1.8255e+00+0.0000e+00j,  3.1934e-01+0.0000e+00j,&#10;          2.0084e+00+0.0000e+00j, -6.8718e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.4961e+00-3.4928e-01j,&#10;         -2.5492e-01-4.7670e-01j, -4.4875e-01-7.0724e-01j,&#10;          1.9341e-01-2.5222e-01j, -1.4961e+00+3.4928e-01j,&#10;          0.0000e+00+0.0000e+00j,  3.2905e+00+1.7542e+00j,&#10;         -5.7795e-02-2.1237e-01j, -2.3773e+00-6.5816e-01j,&#10;          2.5492e-01+4.7670e-01j, -3.2905e+00-1.7542e+00j,&#10;          0.0000e+00+0.0000e+00j, -2.5173e+00-9.4584e-01j,&#10;         -8.1004e-01+2.4262e-03j,  4.4875e-01+7.0724e-01j,&#10;          5.7795e-02+2.1237e-01j,  2.5173e+00+9.4584e-01j,&#10;          0.0000e+00+0.0000e+00j, -1.4380e+00-4.9301e-01j,&#10;         -1.9341e-01+2.5222e-01j,  2.3773e+00+6.5816e-01j,&#10;          8.1004e-01-2.4262e-03j,  1.4380e+00+4.9301e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.4415e-01-6.3133e-02j,&#10;          9.0660e-01+2.3347e+00j,  2.6591e-01-1.0783e+00j,&#10;         -6.5974e-01-1.2112e+00j, -1.4415e-01+6.3133e-02j,&#10;          0.0000e+00+0.0000e+00j, -2.6798e-01+1.1805e+00j,&#10;          5.8987e-01+1.3456e+00j,  3.0531e-01-1.1188e+00j,&#10;         -9.0660e-01-2.3347e+00j,  2.6798e-01-1.1805e+00j,&#10;          0.0000e+00+0.0000e+00j,  1.5532e+00+1.1515e-02j,&#10;         -4.0404e-01-1.1510e+00j, -2.6591e-01+1.0783e+00j,&#10;         -5.8987e-01-1.3456e+00j, -1.5532e+00-1.1515e-02j,&#10;          0.0000e+00+0.0000e+00j,  5.1794e-01+6.3517e-01j,&#10;          6.5974e-01+1.2112e+00j, -3.0531e-01+1.1188e+00j,&#10;          4.0404e-01+1.1510e+00j, -5.1794e-01-6.3517e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.1748e-01-5.7510e-01j,&#10;          6.2723e-01-8.2225e-01j,  1.9392e-03-1.7370e-01j,&#10;          6.6068e-01+6.5212e-01j, -1.1748e-01+5.7510e-01j,&#10;          0.0000e+00+0.0000e+00j,  1.6768e+00-3.9248e-01j,&#10;         -5.4691e-02-2.3834e-01j, -9.1764e-01+2.6212e-01j,&#10;         -6.2723e-01+8.2225e-01j, -1.6768e+00+3.9248e-01j,&#10;          0.0000e+00+0.0000e+00j, -1.2638e+00-3.2441e-01j,&#10;         -1.1338e+00+1.4816e-02j, -1.9392e-03+1.7370e-01j,&#10;          5.4691e-02+2.3834e-01j,  1.2638e+00+3.2441e-01j,&#10;          0.0000e+00+0.0000e+00j, -5.2333e-01-5.6310e-02j,&#10;         -6.6068e-01-6.5212e-01j,  9.1764e-01-2.6212e-01j,&#10;          1.1338e+00-1.4816e-02j,  5.2333e-01+5.6310e-02j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  4.4269e-01+3.6771e-02j,&#10;          7.2476e-01+3.2081e-01j, -8.0388e-02+3.9437e-01j,&#10;         -4.2664e-01+4.4590e-01j, -4.4269e-01-3.6771e-02j,&#10;          0.0000e+00+0.0000e+00j, -1.8157e-01+1.3197e-01j,&#10;          3.1662e-01-3.9380e-01j,  1.0048e-01-3.9145e-01j,&#10;         -7.2476e-01-3.2081e-01j,  1.8157e-01-1.3197e-01j,&#10;          0.0000e+00+0.0000e+00j,  1.1081e+00-2.3731e-01j,&#10;          1.3909e-01-6.5741e-02j,  8.0388e-02-3.9437e-01j,&#10;         -3.1662e-01+3.9380e-01j, -1.1081e+00+2.3731e-01j,&#10;          0.0000e+00+0.0000e+00j,  4.6694e-02+6.1597e-01j,&#10;          4.2664e-01-4.4590e-01j, -1.0048e-01+3.9145e-01j,&#10;         -1.3909e-01+6.5741e-02j, -4.6694e-02-6.1597e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.4961e+00+3.4928e-01j,&#10;         -2.5492e-01+4.7670e-01j, -4.4875e-01+7.0724e-01j,&#10;          1.9341e-01+2.5222e-01j, -1.4961e+00-3.4928e-01j,&#10;          0.0000e+00+0.0000e+00j,  3.2905e+00-1.7542e+00j,&#10;         -5.7795e-02+2.1237e-01j, -2.3773e+00+6.5816e-01j,&#10;          2.5492e-01-4.7670e-01j, -3.2905e+00+1.7542e+00j,&#10;          0.0000e+00+0.0000e+00j, -2.5173e+00+9.4584e-01j,&#10;         -8.1004e-01-2.4262e-03j,  4.4875e-01-7.0724e-01j,&#10;          5.7795e-02-2.1237e-01j,  2.5173e+00-9.4584e-01j,&#10;          0.0000e+00+0.0000e+00j, -1.4380e+00+4.9301e-01j,&#10;         -1.9341e-01-2.5222e-01j,  2.3773e+00-6.5816e-01j,&#10;          8.1004e-01+2.4262e-03j,  1.4380e+00-4.9301e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -3.4914e-01+0.0000e+00j,&#10;         -3.0760e+00+0.0000e+00j,  3.8998e-01+0.0000e+00j,&#10;          2.7213e+00+0.0000e+00j,  3.4914e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  2.3275e+00+0.0000e+00j,&#10;         -2.1423e+00+0.0000e+00j, -7.1063e-01+0.0000e+00j,&#10;          3.0760e+00+0.0000e+00j, -2.3275e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -2.7951e+00+0.0000e+00j,&#10;          4.0797e-01+0.0000e+00j, -3.8998e-01+0.0000e+00j,&#10;          2.1423e+00+0.0000e+00j,  2.7951e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.3160e+00+0.0000e+00j,&#10;         -2.7213e+00+0.0000e+00j,  7.1063e-01+0.0000e+00j,&#10;         -4.0797e-01+0.0000e+00j,  1.3160e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -5.0913e-01+1.8365e+00j,&#10;         -1.8391e+00+8.7348e-01j, -1.3041e-01+8.8561e-02j,&#10;          2.1968e-01-1.6528e-02j,  5.0913e-01-1.8365e+00j,&#10;          0.0000e+00+0.0000e+00j,  2.4690e+00+2.9550e+00j,&#10;         -9.0080e-01-1.8398e-01j, -1.4491e+00-2.2701e+00j,&#10;          1.8391e+00-8.7348e-01j, -2.4690e+00-2.9550e+00j,&#10;          0.0000e+00+0.0000e+00j, -2.7211e+00-1.6243e+00j,&#10;         -8.4874e-01-1.1403e+00j,  1.3041e-01-8.8561e-02j,&#10;          9.0080e-01+1.8398e-01j,  2.7211e+00+1.6243e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.1194e+00-7.8553e-01j,&#10;         -2.1968e-01+1.6528e-02j,  1.4491e+00+2.2701e+00j,&#10;          8.4874e-01+1.1403e+00j,  1.1194e+00+7.8553e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.4688e+00-4.4307e-01j,&#10;         -2.0822e+00+1.0627e+00j,  6.5516e-01-2.5171e-01j,&#10;          1.3284e+00-7.8379e-01j,  1.4688e+00+4.4307e-01j,&#10;          0.0000e+00+0.0000e+00j, -2.8521e+00-1.7401e-01j,&#10;         -1.1381e+00+3.3093e-01j,  1.5043e+00+3.3606e-02j,&#10;          2.0822e+00-1.0627e+00j,  2.8521e+00+1.7401e-01j,&#10;          0.0000e+00+0.0000e+00j,  4.6373e-01+7.6571e-01j,&#10;          1.3618e+00-5.7519e-01j, -6.5516e-01+2.5171e-01j,&#10;          1.1381e+00-3.3093e-01j, -4.6373e-01-7.6571e-01j,&#10;          0.0000e+00+0.0000e+00j,  4.8770e-01+7.0755e-01j,&#10;         -1.3284e+00+7.8379e-01j, -1.5043e+00-3.3606e-02j,&#10;         -1.3618e+00+5.7519e-01j, -4.8770e-01-7.0755e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  4.5278e-01-2.0853e-01j,&#10;         -8.2821e-01-1.4705e-01j,  6.6287e-01+1.8157e-01j,&#10;          8.1542e-01-6.4004e-02j, -4.5278e-01+2.0853e-01j,&#10;          0.0000e+00+0.0000e+00j, -1.9981e-01-1.8770e+00j,&#10;         -2.0486e-01+6.6998e-02j,  4.2076e-02+1.1693e+00j,&#10;          8.2821e-01+1.4705e-01j,  1.9981e-01+1.8770e+00j,&#10;          0.0000e+00+0.0000e+00j, -2.4604e-01+1.0203e+00j,&#10;          6.3282e-01+4.6727e-01j, -6.6287e-01-1.8157e-01j,&#10;          2.0486e-01-6.6998e-02j,  2.4604e-01-1.0203e+00j,&#10;          0.0000e+00+0.0000e+00j, -3.1966e-01+1.3871e-01j,&#10;         -8.1542e-01+6.4004e-02j, -4.2076e-02-1.1693e+00j,&#10;         -6.3282e-01-4.6727e-01j,  3.1966e-01-1.3871e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.4415e-01+6.3133e-02j,&#10;          9.0660e-01-2.3347e+00j,  2.6591e-01+1.0783e+00j,&#10;         -6.5974e-01+1.2112e+00j, -1.4415e-01-6.3133e-02j,&#10;          0.0000e+00+0.0000e+00j, -2.6798e-01-1.1805e+00j,&#10;          5.8987e-01-1.3456e+00j,  3.0531e-01+1.1188e+00j,&#10;         -9.0660e-01+2.3347e+00j,  2.6798e-01+1.1805e+00j,&#10;          0.0000e+00+0.0000e+00j,  1.5532e+00-1.1515e-02j,&#10;         -4.0404e-01+1.1510e+00j, -2.6591e-01-1.0783e+00j,&#10;         -5.8987e-01+1.3456e+00j, -1.5532e+00+1.1515e-02j,&#10;          0.0000e+00+0.0000e+00j,  5.1794e-01-6.3517e-01j,&#10;          6.5974e-01-1.2112e+00j, -3.0531e-01-1.1188e+00j,&#10;          4.0404e-01-1.1510e+00j, -5.1794e-01+6.3517e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -5.0913e-01-1.8365e+00j,&#10;         -1.8391e+00-8.7348e-01j, -1.3041e-01-8.8561e-02j,&#10;          2.1968e-01+1.6528e-02j,  5.0913e-01+1.8365e+00j,&#10;          0.0000e+00+0.0000e+00j,  2.4690e+00-2.9550e+00j,&#10;         -9.0080e-01+1.8398e-01j, -1.4491e+00+2.2701e+00j,&#10;          1.8391e+00+8.7348e-01j, -2.4690e+00+2.9550e+00j,&#10;          0.0000e+00+0.0000e+00j, -2.7211e+00+1.6243e+00j,&#10;         -8.4874e-01+1.1403e+00j,  1.3041e-01+8.8561e-02j,&#10;          9.0080e-01-1.8398e-01j,  2.7211e+00-1.6243e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.1194e+00+7.8553e-01j,&#10;         -2.1968e-01-1.6528e-02j,  1.4491e+00-2.2701e+00j,&#10;          8.4874e-01-1.1403e+00j,  1.1194e+00-7.8553e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  4.0647e-01+0.0000e+00j,&#10;          2.3590e+00+0.0000e+00j, -4.4840e-01+0.0000e+00j,&#10;         -7.0010e-01+0.0000e+00j, -4.0647e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.1028e+00+0.0000e+00j,&#10;          8.3067e-01+0.0000e+00j,  5.5832e-01+0.0000e+00j,&#10;         -2.3590e+00+0.0000e+00j,  1.1028e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  3.4256e+00+0.0000e+00j,&#10;          3.0754e-01+0.0000e+00j,  4.4840e-01+0.0000e+00j,&#10;         -8.3067e-01+0.0000e+00j, -3.4256e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  1.1336e+00+0.0000e+00j,&#10;          7.0010e-01+0.0000e+00j, -5.5832e-01+0.0000e+00j,&#10;         -3.0754e-01+0.0000e+00j, -1.1336e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.2232e+00-3.8779e-02j,&#10;          3.0044e-01+1.0461e+00j,  6.7728e-01-1.1666e-01j,&#10;          5.2931e-01-6.2227e-01j,  1.2232e+00+3.8779e-02j,&#10;          0.0000e+00+0.0000e+00j, -1.4974e+00-1.5042e+00j,&#10;         -5.2483e-01+7.3272e-01j,  7.7319e-01+6.6187e-01j,&#10;         -3.0044e-01-1.0461e+00j,  1.4974e+00+1.5042e+00j,&#10;          0.0000e+00+0.0000e+00j,  8.1693e-01+1.6825e+00j,&#10;          1.7233e-01+4.1119e-01j, -6.7728e-01+1.1666e-01j,&#10;          5.2483e-01-7.3272e-01j, -8.1693e-01-1.6825e+00j,&#10;          0.0000e+00+0.0000e+00j,  5.6894e-01+1.0597e+00j,&#10;         -5.2931e-01+6.2227e-01j, -7.7319e-01-6.6187e-01j,&#10;         -1.7233e-01-4.1119e-01j, -5.6894e-01-1.0597e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -6.2133e-01-4.9666e-01j,&#10;         -1.9661e+00-1.6991e+00j, -2.4991e-01-4.1728e-01j,&#10;          1.5127e+00+2.1993e-01j,  6.2133e-01+4.9666e-01j,&#10;          0.0000e+00+0.0000e+00j,  5.4007e-01-4.4791e-01j,&#10;         -1.4764e+00-6.9333e-01j, -3.3024e-01+2.8122e-01j,&#10;          1.9661e+00+1.6991e+00j, -5.4007e-01+4.4791e-01j,&#10;          0.0000e+00+0.0000e+00j, -2.6221e+00-2.4041e-01j,&#10;          8.1628e-01+1.4775e+00j,  2.4991e-01+4.1728e-01j,&#10;          1.4764e+00+6.9333e-01j,  2.6221e+00+2.4041e-01j,&#10;          0.0000e+00+0.0000e+00j, -5.9988e-01-3.0294e-01j,&#10;         -1.5127e+00-2.1993e-01j,  3.3024e-01-2.8122e-01j,&#10;         -8.1628e-01-1.4775e+00j,  5.9988e-01+3.0294e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  1.1748e-01+5.7510e-01j,&#10;          6.2723e-01+8.2225e-01j,  1.9392e-03+1.7370e-01j,&#10;          6.6068e-01-6.5212e-01j, -1.1748e-01-5.7510e-01j,&#10;          0.0000e+00+0.0000e+00j,  1.6768e+00+3.9248e-01j,&#10;         -5.4691e-02+2.3834e-01j, -9.1764e-01-2.6212e-01j,&#10;         -6.2723e-01-8.2225e-01j, -1.6768e+00-3.9248e-01j,&#10;          0.0000e+00+0.0000e+00j, -1.2638e+00+3.2441e-01j,&#10;         -1.1338e+00-1.4816e-02j, -1.9392e-03-1.7370e-01j,&#10;          5.4691e-02-2.3834e-01j,  1.2638e+00-3.2441e-01j,&#10;          0.0000e+00+0.0000e+00j, -5.2333e-01+5.6310e-02j,&#10;         -6.6068e-01+6.5212e-01j,  9.1764e-01+2.6212e-01j,&#10;          1.1338e+00+1.4816e-02j,  5.2333e-01-5.6310e-02j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.4688e+00+4.4307e-01j,&#10;         -2.0822e+00-1.0627e+00j,  6.5516e-01+2.5171e-01j,&#10;          1.3284e+00+7.8379e-01j,  1.4688e+00-4.4307e-01j,&#10;          0.0000e+00+0.0000e+00j, -2.8521e+00+1.7401e-01j,&#10;         -1.1381e+00-3.3093e-01j,  1.5043e+00-3.3606e-02j,&#10;          2.0822e+00+1.0627e+00j,  2.8521e+00-1.7401e-01j,&#10;          0.0000e+00+0.0000e+00j,  4.6373e-01-7.6571e-01j,&#10;          1.3618e+00+5.7519e-01j, -6.5516e-01-2.5171e-01j,&#10;          1.1381e+00+3.3093e-01j, -4.6373e-01+7.6571e-01j,&#10;          0.0000e+00+0.0000e+00j,  4.8770e-01-7.0755e-01j,&#10;         -1.3284e+00-7.8379e-01j, -1.5043e+00+3.3606e-02j,&#10;         -1.3618e+00-5.7519e-01j, -4.8770e-01+7.0755e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -1.2232e+00+3.8779e-02j,&#10;          3.0044e-01-1.0461e+00j,  6.7728e-01+1.1666e-01j,&#10;          5.2931e-01+6.2227e-01j,  1.2232e+00-3.8779e-02j,&#10;          0.0000e+00+0.0000e+00j, -1.4974e+00+1.5042e+00j,&#10;         -5.2483e-01-7.3272e-01j,  7.7319e-01-6.6187e-01j,&#10;         -3.0044e-01+1.0461e+00j,  1.4974e+00-1.5042e+00j,&#10;          0.0000e+00+0.0000e+00j,  8.1693e-01-1.6825e+00j,&#10;          1.7233e-01-4.1119e-01j, -6.7728e-01-1.1666e-01j,&#10;          5.2483e-01+7.3272e-01j, -8.1693e-01+1.6825e+00j,&#10;          0.0000e+00+0.0000e+00j,  5.6894e-01-1.0597e+00j,&#10;         -5.2931e-01-6.2227e-01j, -7.7319e-01+6.6187e-01j,&#10;         -1.7233e-01+4.1119e-01j, -5.6894e-01+1.0597e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -8.3360e-01+0.0000e+00j,&#10;         -2.0211e+00+0.0000e+00j,  1.3179e-01+0.0000e+00j,&#10;          1.1326e+00+0.0000e+00j,  8.3360e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -9.7158e-01+0.0000e+00j,&#10;         -1.0122e+00+0.0000e+00j,  5.4749e-01+0.0000e+00j,&#10;          2.0211e+00+0.0000e+00j,  9.7158e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.0646e+00+0.0000e+00j,&#10;          9.7985e-01+0.0000e+00j, -1.3179e-01+0.0000e+00j,&#10;          1.0122e+00+0.0000e+00j,  1.0646e+00+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -3.5078e-01+0.0000e+00j,&#10;         -1.1326e+00+0.0000e+00j, -5.4749e-01+0.0000e+00j,&#10;         -9.7985e-01+0.0000e+00j,  3.5078e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  5.4324e-01+4.3631e-01j,&#10;         -1.2535e+00+1.8403e+00j, -3.4062e-01-5.1447e-01j,&#10;         -3.5496e-01-5.1904e-01j, -5.4324e-01-4.3631e-01j,&#10;          0.0000e+00+0.0000e+00j,  8.8587e-01-3.2437e-01j,&#10;         -7.7339e-02+1.2728e+00j, -6.6840e-01-1.6934e-01j,&#10;          1.2535e+00-1.8403e+00j, -8.8587e-01+3.2437e-01j,&#10;          0.0000e+00+0.0000e+00j, -2.5955e+00+2.3968e+00j,&#10;         -6.0851e-01-3.4232e-01j,  3.4062e-01+5.1447e-01j,&#10;          7.7339e-02-1.2728e+00j,  2.5955e+00-2.3968e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.0889e+00+1.2083e+00j,&#10;          3.5496e-01+5.1904e-01j,  6.6840e-01+1.6934e-01j,&#10;          6.0851e-01+3.4232e-01j,  1.0889e+00-1.2083e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  4.4269e-01-3.6771e-02j,&#10;          7.2476e-01-3.2081e-01j, -8.0388e-02-3.9437e-01j,&#10;         -4.2664e-01-4.4590e-01j, -4.4269e-01+3.6771e-02j,&#10;          0.0000e+00+0.0000e+00j, -1.8157e-01-1.3197e-01j,&#10;          3.1662e-01+3.9380e-01j,  1.0048e-01+3.9145e-01j,&#10;         -7.2476e-01+3.2081e-01j,  1.8157e-01+1.3197e-01j,&#10;          0.0000e+00+0.0000e+00j,  1.1081e+00+2.3731e-01j,&#10;          1.3909e-01+6.5741e-02j,  8.0388e-02+3.9437e-01j,&#10;         -3.1662e-01-3.9380e-01j, -1.1081e+00-2.3731e-01j,&#10;          0.0000e+00+0.0000e+00j,  4.6694e-02-6.1597e-01j,&#10;          4.2664e-01+4.4590e-01j, -1.0048e-01-3.9145e-01j,&#10;         -1.3909e-01-6.5741e-02j, -4.6694e-02+6.1597e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  4.5278e-01+2.0853e-01j,&#10;         -8.2821e-01+1.4705e-01j,  6.6287e-01-1.8157e-01j,&#10;          8.1542e-01+6.4004e-02j, -4.5278e-01-2.0853e-01j,&#10;          0.0000e+00+0.0000e+00j, -1.9981e-01+1.8770e+00j,&#10;         -2.0486e-01-6.6998e-02j,  4.2076e-02-1.1693e+00j,&#10;          8.2821e-01-1.4705e-01j,  1.9981e-01-1.8770e+00j,&#10;          0.0000e+00+0.0000e+00j, -2.4604e-01-1.0203e+00j,&#10;          6.3282e-01-4.6727e-01j, -6.6287e-01+1.8157e-01j,&#10;          2.0486e-01+6.6998e-02j,  2.4604e-01+1.0203e+00j,&#10;          0.0000e+00+0.0000e+00j, -3.1966e-01-1.3871e-01j,&#10;         -8.1542e-01-6.4004e-02j, -4.2076e-02+1.1693e+00j,&#10;         -6.3282e-01+4.6727e-01j,  3.1966e-01+1.3871e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j, -6.2133e-01+4.9666e-01j,&#10;         -1.9661e+00+1.6991e+00j, -2.4991e-01+4.1728e-01j,&#10;          1.5127e+00-2.1993e-01j,  6.2133e-01-4.9666e-01j,&#10;          0.0000e+00+0.0000e+00j,  5.4007e-01+4.4791e-01j,&#10;         -1.4764e+00+6.9333e-01j, -3.3024e-01-2.8122e-01j,&#10;          1.9661e+00-1.6991e+00j, -5.4007e-01-4.4791e-01j,&#10;          0.0000e+00+0.0000e+00j, -2.6221e+00+2.4041e-01j,&#10;          8.1628e-01-1.4775e+00j,  2.4991e-01-4.1728e-01j,&#10;          1.4764e+00-6.9333e-01j,  2.6221e+00-2.4041e-01j,&#10;          0.0000e+00+0.0000e+00j, -5.9988e-01+3.0294e-01j,&#10;         -1.5127e+00+2.1993e-01j,  3.3024e-01+2.8122e-01j,&#10;         -8.1628e-01+1.4775e+00j,  5.9988e-01-3.0294e-01j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  5.4324e-01-4.3631e-01j,&#10;         -1.2535e+00-1.8403e+00j, -3.4062e-01+5.1447e-01j,&#10;         -3.5496e-01+5.1904e-01j, -5.4324e-01+4.3631e-01j,&#10;          0.0000e+00+0.0000e+00j,  8.8587e-01+3.2437e-01j,&#10;         -7.7339e-02-1.2728e+00j, -6.6840e-01+1.6934e-01j,&#10;          1.2535e+00+1.8403e+00j, -8.8587e-01-3.2437e-01j,&#10;          0.0000e+00+0.0000e+00j, -2.5955e+00-2.3968e+00j,&#10;         -6.0851e-01+3.4232e-01j,  3.4062e-01-5.1447e-01j,&#10;          7.7339e-02+1.2728e+00j,  2.5955e+00+2.3968e+00j,&#10;          0.0000e+00+0.0000e+00j, -1.0889e+00-1.2083e+00j,&#10;          3.5496e-01-5.1904e-01j,  6.6840e-01-1.6934e-01j,&#10;          6.0851e-01-3.4232e-01j,  1.0889e+00+1.2083e+00j,&#10;          0.0000e+00+0.0000e+00j],&#10;        [ 0.0000e+00+0.0000e+00j,  6.7298e-01+0.0000e+00j,&#10;          1.2470e+00+0.0000e+00j, -1.0098e-01+0.0000e+00j,&#10;         -1.8411e+00+0.0000e+00j, -6.7298e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -7.5079e-01+0.0000e+00j,&#10;          9.7484e-01+0.0000e+00j, -4.6859e-02+0.0000e+00j,&#10;         -1.2470e+00+0.0000e+00j,  7.5079e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j, -6.6986e-01+0.0000e+00j,&#10;         -8.8210e-01+0.0000e+00j,  1.0098e-01+0.0000e+00j,&#10;         -9.7484e-01+0.0000e+00j,  6.6986e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j,  1.4120e-01+0.0000e+00j,&#10;          1.8411e+00+0.0000e+00j,  4.6859e-02+0.0000e+00j,&#10;          8.8210e-01+0.0000e+00j, -1.4120e-01+0.0000e+00j,&#10;          0.0000e+00+0.0000e+00j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 0.0000+0.0000j, -0.4559+0.0000j,  1.2912+0.0000j,  0.1153+0.0000j,&#10;         -1.1811+0.0000j,  0.4559+0.0000j,  0.0000+0.0000j,  0.0243+0.0000j,&#10;          1.2005+0.0000j,  0.1676+0.0000j, -1.2912+0.0000j, -0.0243+0.0000j,&#10;          0.0000+0.0000j,  2.3918+0.0000j, -0.7624+0.0000j, -0.1153+0.0000j,&#10;         -1.2005+0.0000j, -2.3918+0.0000j,  0.0000+0.0000j,  0.9385+0.0000j,&#10;          1.1811+0.0000j, -0.1676+0.0000j,  0.7624+0.0000j, -0.9385+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  1.5367-0.5418j,  0.1802+0.0306j, -0.5433-0.8284j,&#10;          0.3367-0.5477j, -1.5367+0.5418j,  0.0000+0.0000j,  4.1134+1.8237j,&#10;         -0.3180-0.1760j, -2.7153-0.7546j, -0.1802-0.0306j, -4.1134-1.8237j,&#10;          0.0000+0.0000j, -1.8290-0.3681j, -0.9640-0.3100j,  0.5433+0.8284j,&#10;          0.3180+0.1760j,  1.8290+0.3681j,  0.0000+0.0000j, -1.0764-0.0060j,&#10;         -0.3367+0.5477j,  2.7153+0.7546j,  0.9640+0.3100j,  1.0764+0.0060j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2106+0.0306j, -0.4444+3.4091j,  0.1213-1.2004j,&#10;         -0.4458-1.3984j, -0.2106-0.0306j,  0.0000+0.0000j,  0.8473+0.1676j,&#10;          0.3256+1.5739j, -0.4362-0.8291j,  0.4444-3.4091j, -0.8473-0.1676j,&#10;          0.0000+0.0000j, -1.0873+1.1727j, -0.6020-0.5465j, -0.1213+1.2004j,&#10;         -0.3256-1.5739j,  1.0873-1.1727j,  0.0000+0.0000j, -0.6905+1.3634j,&#10;          0.4458+1.3984j,  0.4362+0.8291j,  0.6020+0.5465j,  0.6905-1.3634j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0891-0.8284j, -0.5279-1.2004j,  0.0689+0.0943j,&#10;          1.2309+0.6415j,  0.0891+0.8284j,  0.0000+0.0000j,  2.5761+0.0402j,&#10;         -0.5969-0.3305j, -1.2314+0.4263j,  0.5279+1.2004j, -2.5761-0.0402j,&#10;          0.0000+0.0000j, -2.3358+0.1394j, -1.1403-0.5864j, -0.0689-0.0943j,&#10;          0.5969+0.3305j,  2.3358-0.1394j,  0.0000+0.0000j, -1.1628-0.1077j,&#10;         -1.2309-0.6415j,  1.2314-0.4263j,  1.1403+0.5864j,  1.1628+0.1077j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.5281-0.5477j,  0.1540-1.3984j, -0.1063+0.6415j,&#10;         -0.3856+1.1760j, -0.5281+0.5477j,  0.0000+0.0000j,  0.4915+0.5403j,&#10;          0.2851-0.9451j, -0.2179-0.1301j, -0.1540+1.3984j, -0.4915-0.5403j,&#10;          0.0000+0.0000j,  0.1195-0.6528j, -0.2304-0.1408j,  0.1063-0.6415j,&#10;         -0.2851+0.9451j, -0.1195+0.6528j,  0.0000+0.0000j, -0.4858+0.1067j,&#10;          0.3856-1.1760j,  0.2179+0.1301j,  0.2304+0.1408j,  0.4858-0.1067j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  1.5367+0.5418j,  0.1802-0.0306j, -0.5433+0.8284j,&#10;          0.3367+0.5477j, -1.5367-0.5418j,  0.0000+0.0000j,  4.1134-1.8237j,&#10;         -0.3180+0.1760j, -2.7153+0.7546j, -0.1802+0.0306j, -4.1134+1.8237j,&#10;          0.0000+0.0000j, -1.8290+0.3681j, -0.9640+0.3100j,  0.5433-0.8284j,&#10;          0.3180-0.1760j,  1.8290-0.3681j,  0.0000+0.0000j, -1.0764+0.0060j,&#10;         -0.3367-0.5477j,  2.7153-0.7546j,  0.9640-0.3100j,  1.0764-0.0060j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.9132+0.0000j, -4.5865+0.0000j,  0.6408+0.0000j,&#10;          3.5654+0.0000j,  0.9132+0.0000j,  0.0000+0.0000j,  2.3008+0.0000j,&#10;         -2.8383+0.0000j, -0.5041+0.0000j,  4.5865+0.0000j, -2.3008+0.0000j,&#10;          0.0000+0.0000j, -3.7487+0.0000j,  0.7610+0.0000j, -0.6408+0.0000j,&#10;          2.8383+0.0000j,  3.7487+0.0000j,  0.0000+0.0000j, -1.8556+0.0000j,&#10;         -3.5654+0.0000j,  0.5041+0.0000j, -0.7610+0.0000j,  1.8556+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.6491+1.8237j, -1.0934+0.1676j, -0.2665+0.0402j,&#10;          0.2195+0.5403j,  0.6491-1.8237j,  0.0000+0.0000j,  2.1247+4.1374j,&#10;         -0.8757-0.7111j, -1.2077-2.7678j,  1.0934-0.1676j, -2.1247-4.1374j,&#10;          0.0000+0.0000j, -1.0162-2.3968j, -0.7037-1.1995j,  0.2665-0.0402j,&#10;          0.8757+0.7111j,  1.0162+2.3968j,  0.0000+0.0000j, -0.2119-1.1998j,&#10;         -0.2195-0.5403j,  1.2077+2.7678j,  0.7037+1.1995j,  0.2119+1.1998j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -1.0983-0.1760j, -2.5084+1.5739j,  0.7175-0.3305j,&#10;          1.2145-0.9451j,  1.0983+0.1760j,  0.0000+0.0000j, -2.0243-0.7111j,&#10;         -1.0347+0.5962j,  1.1058+0.1284j,  2.5084-1.5739j,  2.0243+0.7111j,&#10;          0.0000+0.0000j, -0.7783+0.8773j,  0.9684-0.2871j, -0.7175+0.3305j,&#10;          1.0347-0.5962j,  0.7783-0.8773j,  0.0000+0.0000j, -0.2991+0.8445j,&#10;         -1.2145+0.9451j, -1.1058-0.1284j, -0.9684+0.2871j,  0.2991-0.8445j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.6274-0.7546j, -1.1261-0.8291j,  0.7356+0.4263j,&#10;          0.8638-0.1301j, -0.6274+0.7546j,  0.0000+0.0000j,  0.3297-2.7678j,&#10;         -0.2752+0.1284j, -0.1782+1.8659j,  1.1261+0.8291j, -0.3297+2.7678j,&#10;          0.0000+0.0000j, -1.0400+1.4544j,  0.4109+0.3474j, -0.7356-0.4263j,&#10;          0.2752-0.1284j,  1.0400-1.4544j,  0.0000+0.0000j, -0.7634+0.2209j,&#10;         -0.8638+0.1301j,  0.1782-1.8659j, -0.4109-0.3474j,  0.7634-0.2209j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2106-0.0306j, -0.4444-3.4091j,  0.1213+1.2004j,&#10;         -0.4458+1.3984j, -0.2106+0.0306j,  0.0000+0.0000j,  0.8473-0.1676j,&#10;          0.3256-1.5739j, -0.4362+0.8291j,  0.4444+3.4091j, -0.8473+0.1676j,&#10;          0.0000+0.0000j, -1.0873-1.1727j, -0.6020+0.5465j, -0.1213-1.2004j,&#10;         -0.3256+1.5739j,  1.0873+1.1727j,  0.0000+0.0000j, -0.6905-1.3634j,&#10;          0.4458-1.3984j,  0.4362-0.8291j,  0.6020-0.5465j,  0.6905+1.3634j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.6491-1.8237j, -1.0934-0.1676j, -0.2665-0.0402j,&#10;          0.2195-0.5403j,  0.6491+1.8237j,  0.0000+0.0000j,  2.1247-4.1374j,&#10;         -0.8757+0.7111j, -1.2077+2.7678j,  1.0934+0.1676j, -2.1247+4.1374j,&#10;          0.0000+0.0000j, -1.0162+2.3968j, -0.7037+1.1995j,  0.2665+0.0402j,&#10;          0.8757-0.7111j,  1.0162-2.3968j,  0.0000+0.0000j, -0.2119+1.1998j,&#10;         -0.2195+0.5403j,  1.2077-2.7678j,  0.7037-1.1995j,  0.2119-1.1998j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  1.0388+0.0000j,  2.1324+0.0000j, -0.5884+0.0000j,&#10;         -1.2494+0.0000j, -1.0388+0.0000j,  0.0000+0.0000j,  0.4856+0.0000j,&#10;          1.0397+0.0000j, -0.5919+0.0000j, -2.1324+0.0000j, -0.4856+0.0000j,&#10;          0.0000+0.0000j,  0.7586+0.0000j, -0.4476+0.0000j,  0.5884+0.0000j,&#10;         -1.0397+0.0000j, -0.7586+0.0000j,  0.0000+0.0000j, -0.1044+0.0000j,&#10;          1.2494+0.0000j,  0.5919+0.0000j,  0.4476+0.0000j,  0.1044+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -1.0454-0.3681j, -0.2864+1.1727j,  0.6958+0.1394j,&#10;          0.5657-0.6528j,  1.0454+0.3681j,  0.0000+0.0000j, -0.9054-2.3968j,&#10;         -0.5169+0.8773j,  0.5163+1.4544j,  0.2864-1.1727j,  0.9054+2.3968j,&#10;          0.0000+0.0000j, -0.1638+3.3088j, -0.0225+0.3807j, -0.6958-0.1394j,&#10;          0.5169-0.8773j,  0.1638-3.3088j,  0.0000+0.0000j, -0.0590+1.6176j,&#10;         -0.5657+0.6528j, -0.5163-1.4544j,  0.0225-0.3807j,  0.0590-1.6176j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1768-0.3100j, -1.0903-0.5465j, -0.3280-0.5864j,&#10;          1.0761-0.1408j,  0.1768+0.3100j,  0.0000+0.0000j,  0.5313-1.1995j,&#10;         -1.0959-0.2871j, -0.3511+0.3474j,  1.0903+0.5465j, -0.5313+1.1995j,&#10;          0.0000+0.0000j, -1.8283+0.3807j,  0.6922+1.5707j,  0.3280+0.5864j,&#10;          1.0959+0.2871j,  1.8283-0.3807j,  0.0000+0.0000j, -0.2588+0.2578j,&#10;         -1.0761+0.1408j,  0.3511-0.3474j, -0.6922-1.5707j,  0.2588-0.2578j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0891+0.8284j, -0.5279+1.2004j,  0.0689-0.0943j,&#10;          1.2309-0.6415j,  0.0891-0.8284j,  0.0000+0.0000j,  2.5761-0.0402j,&#10;         -0.5969+0.3305j, -1.2314-0.4263j,  0.5279-1.2004j, -2.5761+0.0402j,&#10;          0.0000+0.0000j, -2.3358-0.1394j, -1.1403+0.5864j, -0.0689+0.0943j,&#10;          0.5969-0.3305j,  2.3358+0.1394j,  0.0000+0.0000j, -1.1628+0.1077j,&#10;         -1.2309+0.6415j,  1.2314+0.4263j,  1.1403-0.5864j,  1.1628-0.1077j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -1.0983+0.1760j, -2.5084-1.5739j,  0.7175+0.3305j,&#10;          1.2145+0.9451j,  1.0983-0.1760j,  0.0000+0.0000j, -2.0243+0.7111j,&#10;         -1.0347-0.5962j,  1.1058-0.1284j,  2.5084+1.5739j,  2.0243-0.7111j,&#10;          0.0000+0.0000j, -0.7783-0.8773j,  0.9684+0.2871j, -0.7175-0.3305j,&#10;          1.0347+0.5962j,  0.7783+0.8773j,  0.0000+0.0000j, -0.2991-0.8445j,&#10;         -1.2145-0.9451j, -1.1058+0.1284j, -0.9684-0.2871j,  0.2991+0.8445j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -1.0454+0.3681j, -0.2864-1.1727j,  0.6958-0.1394j,&#10;          0.5657+0.6528j,  1.0454-0.3681j,  0.0000+0.0000j, -0.9054+2.3968j,&#10;         -0.5169-0.8773j,  0.5163-1.4544j,  0.2864+1.1727j,  0.9054-2.3968j,&#10;          0.0000+0.0000j, -0.1638-3.3088j, -0.0225-0.3807j, -0.6958+0.1394j,&#10;          0.5169+0.8773j,  0.1638+3.3088j,  0.0000+0.0000j, -0.0590-1.6176j,&#10;         -0.5657-0.6528j, -0.5163+1.4544j,  0.0225+0.3807j,  0.0590+1.6176j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.3428+0.0000j, -0.0842+0.0000j, -0.0667+0.0000j,&#10;          0.7062+0.0000j,  0.3428+0.0000j,  0.0000+0.0000j, -2.0598+0.0000j,&#10;         -0.3767+0.0000j,  0.9752+0.0000j,  0.0842+0.0000j,  2.0598+0.0000j,&#10;          0.0000+0.0000j,  1.2682+0.0000j,  1.3310+0.0000j,  0.0667+0.0000j,&#10;          0.3767+0.0000j, -1.2682+0.0000j,  0.0000+0.0000j,  0.8803+0.0000j,&#10;         -0.7062+0.0000j, -0.9752+0.0000j, -1.3310+0.0000j, -0.8803+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.3307-0.0060j, -0.9370+1.3634j, -0.3188-0.1077j,&#10;          0.1575+0.1067j, -0.3307+0.0060j,  0.0000+0.0000j,  0.2175-1.1998j,&#10;         -0.1475+0.8445j, -0.1225+0.2209j,  0.9370-1.3634j, -0.2175+1.1998j,&#10;          0.0000+0.0000j, -0.7826+1.6176j, -0.1887+0.2578j,  0.3188+0.1077j,&#10;          0.1475-0.8445j,  0.7826-1.6176j,  0.0000+0.0000j, -0.3421+0.8343j,&#10;         -0.1575-0.1067j,  0.1225-0.2209j,  0.1887-0.2578j,  0.3421-0.8343j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.5281+0.5477j,  0.1540+1.3984j, -0.1063-0.6415j,&#10;         -0.3856-1.1760j, -0.5281-0.5477j,  0.0000+0.0000j,  0.4915-0.5403j,&#10;          0.2851+0.9451j, -0.2179+0.1301j, -0.1540-1.3984j, -0.4915+0.5403j,&#10;          0.0000+0.0000j,  0.1195+0.6528j, -0.2304+0.1408j,  0.1063+0.6415j,&#10;         -0.2851-0.9451j, -0.1195-0.6528j,  0.0000+0.0000j, -0.4858-0.1067j,&#10;          0.3856+1.1760j,  0.2179-0.1301j,  0.2304-0.1408j,  0.4858+0.1067j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.6274+0.7546j, -1.1261+0.8291j,  0.7356-0.4263j,&#10;          0.8638+0.1301j, -0.6274-0.7546j,  0.0000+0.0000j,  0.3297+2.7678j,&#10;         -0.2752-0.1284j, -0.1782-1.8659j,  1.1261-0.8291j, -0.3297-2.7678j,&#10;          0.0000+0.0000j, -1.0400-1.4544j,  0.4109-0.3474j, -0.7356+0.4263j,&#10;          0.2752+0.1284j,  1.0400+1.4544j,  0.0000+0.0000j, -0.7634-0.2209j,&#10;         -0.8638-0.1301j,  0.1782+1.8659j, -0.4109+0.3474j,  0.7634+0.2209j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1768+0.3100j, -1.0903+0.5465j, -0.3280+0.5864j,&#10;          1.0761+0.1408j,  0.1768-0.3100j,  0.0000+0.0000j,  0.5313+1.1995j,&#10;         -1.0959+0.2871j, -0.3511-0.3474j,  1.0903-0.5465j, -0.5313-1.1995j,&#10;          0.0000+0.0000j, -1.8283-0.3807j,  0.6922-1.5707j,  0.3280-0.5864j,&#10;          1.0959-0.2871j,  1.8283+0.3807j,  0.0000+0.0000j, -0.2588-0.2578j,&#10;         -1.0761-0.1408j,  0.3511+0.3474j, -0.6922+1.5707j,  0.2588+0.2578j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.3307+0.0060j, -0.9370-1.3634j, -0.3188+0.1077j,&#10;          0.1575-0.1067j, -0.3307-0.0060j,  0.0000+0.0000j,  0.2175+1.1998j,&#10;         -0.1475-0.8445j, -0.1225-0.2209j,  0.9370+1.3634j, -0.2175-1.1998j,&#10;          0.0000+0.0000j, -0.7826-1.6176j, -0.1887-0.2578j,  0.3188-0.1077j,&#10;          0.1475+0.8445j,  0.7826+1.6176j,  0.0000+0.0000j, -0.3421-0.8343j,&#10;         -0.1575+0.1067j,  0.1225+0.2209j,  0.1887+0.2578j,  0.3421+0.8343j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.6730+0.0000j,  1.2470+0.0000j, -0.1010+0.0000j,&#10;         -1.8411+0.0000j, -0.6730+0.0000j,  0.0000+0.0000j, -0.7508+0.0000j,&#10;          0.9748+0.0000j, -0.0469+0.0000j, -1.2470+0.0000j,  0.7508+0.0000j,&#10;          0.0000+0.0000j, -0.6699+0.0000j, -0.8821+0.0000j,  0.1010+0.0000j,&#10;         -0.9748+0.0000j,  0.6699+0.0000j,  0.0000+0.0000j,  0.1412+0.0000j,&#10;          1.8411+0.0000j,  0.0469+0.0000j,  0.8821+0.0000j, -0.1412+0.0000j,&#10;          0.0000+0.0000j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 2.8845376775099463.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 60, in test_fn_gradgrad
    self._check_helper(device, dtype, op, op.get_op(), 'bwgrad_bwgrad')
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4366, in _check_helper
    self.assertTrue(gradgradcheck(fn, gradcheck_args, **kwargs))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3916, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1710, in gradgradcheck
    return gradcheck(
           ^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.1263-0.1307j, dtype=torch.complex128)
analytical:tensor(-0.2702-0.1767j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000e+00+0.0000e+00j, -2.7629e-02+0.0000e+00j,
          1.8265e+00+0.0000e+00j,  2.4922e-01+0.0000e+00j,
         -1.8255e+00+0.0000e+00j,  2.7629e-02+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  1.2710e+00+0.0000e+00j,
          1.5206e+00+0.0000e+00j, -3.1934e-01+0.0000e+00j,
         -1.8265e+00+0.0000e+00j, -1.2710e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  2.1956e+00+0.0000e+00j,
         -2.0084e+00+0.0000e+00j, -2.4922e-01+0.0000e+00j,
         -1.5206e+00+0.0000e+00j, -2.1956e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  6.8718e-01+0.0000e+00j,
          1.8255e+00+0.0000e+00j,  3.1934e-01+0.0000e+00j,
          2.0084e+00+0.0000e+00j, -6.8718e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.4961e+00-3.4928e-01j,
         -2.5492e-01-4.7670e-01j, -4.4875e-01-7.0724e-01j,
          1.9341e-01-2.5222e-01j, -1.4961e+00+3.4928e-01j,
          0.0000e+00+0.0000e+00j,  3.2905e+00+1.7542e+00j,
         -5.7795e-02-2.1237e-01j, -2.3773e+00-6.5816e-01j,
          2.5492e-01+4.7670e-01j, -3.2905e+00-1.7542e+00j,
          0.0000e+00+0.0000e+00j, -2.5173e+00-9.4584e-01j,
         -8.1004e-01+2.4262e-03j,  4.4875e-01+7.0724e-01j,
          5.7795e-02+2.1237e-01j,  2.5173e+00+9.4584e-01j,
          0.0000e+00+0.0000e+00j, -1.4380e+00-4.9301e-01j,
         -1.9341e-01+2.5222e-01j,  2.3773e+00+6.5816e-01j,
          8.1004e-01-2.4262e-03j,  1.4380e+00+4.9301e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.4415e-01-6.3133e-02j,
          9.0660e-01+2.3347e+00j,  2.6591e-01-1.0783e+00j,
         -6.5974e-01-1.2112e+00j, -1.4415e-01+6.3133e-02j,
          0.0000e+00+0.0000e+00j, -2.6798e-01+1.1805e+00j,
          5.8987e-01+1.3456e+00j,  3.0531e-01-1.1188e+00j,
         -9.0660e-01-2.3347e+00j,  2.6798e-01-1.1805e+00j,
          0.0000e+00+0.0000e+00j,  1.5532e+00+1.1515e-02j,
         -4.0404e-01-1.1510e+00j, -2.6591e-01+1.0783e+00j,
         -5.8987e-01-1.3456e+00j, -1.5532e+00-1.1515e-02j,
          0.0000e+00+0.0000e+00j,  5.1794e-01+6.3517e-01j,
          6.5974e-01+1.2112e+00j, -3.0531e-01+1.1188e+00j,
          4.0404e-01+1.1510e+00j, -5.1794e-01-6.3517e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.1748e-01-5.7510e-01j,
          6.2723e-01-8.2225e-01j,  1.9392e-03-1.7370e-01j,
          6.6068e-01+6.5212e-01j, -1.1748e-01+5.7510e-01j,
          0.0000e+00+0.0000e+00j,  1.6768e+00-3.9248e-01j,
         -5.4691e-02-2.3834e-01j, -9.1764e-01+2.6212e-01j,
         -6.2723e-01+8.2225e-01j, -1.6768e+00+3.9248e-01j,
          0.0000e+00+0.0000e+00j, -1.2638e+00-3.2441e-01j,
         -1.1338e+00+1.4816e-02j, -1.9392e-03+1.7370e-01j,
          5.4691e-02+2.3834e-01j,  1.2638e+00+3.2441e-01j,
          0.0000e+00+0.0000e+00j, -5.2333e-01-5.6310e-02j,
         -6.6068e-01-6.5212e-01j,  9.1764e-01-2.6212e-01j,
          1.1338e+00-1.4816e-02j,  5.2333e-01+5.6310e-02j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  4.4269e-01+3.6771e-02j,
          7.2476e-01+3.2081e-01j, -8.0388e-02+3.9437e-01j,
         -4.2664e-01+4.4590e-01j, -4.4269e-01-3.6771e-02j,
          0.0000e+00+0.0000e+00j, -1.8157e-01+1.3197e-01j,
          3.1662e-01-3.9380e-01j,  1.0048e-01-3.9145e-01j,
         -7.2476e-01-3.2081e-01j,  1.8157e-01-1.3197e-01j,
          0.0000e+00+0.0000e+00j,  1.1081e+00-2.3731e-01j,
          1.3909e-01-6.5741e-02j,  8.0388e-02-3.9437e-01j,
         -3.1662e-01+3.9380e-01j, -1.1081e+00+2.3731e-01j,
          0.0000e+00+0.0000e+00j,  4.6694e-02+6.1597e-01j,
          4.2664e-01-4.4590e-01j, -1.0048e-01+3.9145e-01j,
         -1.3909e-01+6.5741e-02j, -4.6694e-02-6.1597e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.4961e+00+3.4928e-01j,
         -2.5492e-01+4.7670e-01j, -4.4875e-01+7.0724e-01j,
          1.9341e-01+2.5222e-01j, -1.4961e+00-3.4928e-01j,
          0.0000e+00+0.0000e+00j,  3.2905e+00-1.7542e+00j,
         -5.7795e-02+2.1237e-01j, -2.3773e+00+6.5816e-01j,
          2.5492e-01-4.7670e-01j, -3.2905e+00+1.7542e+00j,
          0.0000e+00+0.0000e+00j, -2.5173e+00+9.4584e-01j,
         -8.1004e-01-2.4262e-03j,  4.4875e-01-7.0724e-01j,
          5.7795e-02-2.1237e-01j,  2.5173e+00-9.4584e-01j,
          0.0000e+00+0.0000e+00j, -1.4380e+00+4.9301e-01j,
         -1.9341e-01-2.5222e-01j,  2.3773e+00-6.5816e-01j,
          8.1004e-01+2.4262e-03j,  1.4380e+00-4.9301e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -3.4914e-01+0.0000e+00j,
         -3.0760e+00+0.0000e+00j,  3.8998e-01+0.0000e+00j,
          2.7213e+00+0.0000e+00j,  3.4914e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  2.3275e+00+0.0000e+00j,
         -2.1423e+00+0.0000e+00j, -7.1063e-01+0.0000e+00j,
          3.0760e+00+0.0000e+00j, -2.3275e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -2.7951e+00+0.0000e+00j,
          4.0797e-01+0.0000e+00j, -3.8998e-01+0.0000e+00j,
          2.1423e+00+0.0000e+00j,  2.7951e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -1.3160e+00+0.0000e+00j,
         -2.7213e+00+0.0000e+00j,  7.1063e-01+0.0000e+00j,
         -4.0797e-01+0.0000e+00j,  1.3160e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -5.0913e-01+1.8365e+00j,
         -1.8391e+00+8.7348e-01j, -1.3041e-01+8.8561e-02j,
          2.1968e-01-1.6528e-02j,  5.0913e-01-1.8365e+00j,
          0.0000e+00+0.0000e+00j,  2.4690e+00+2.9550e+00j,
         -9.0080e-01-1.8398e-01j, -1.4491e+00-2.2701e+00j,
          1.8391e+00-8.7348e-01j, -2.4690e+00-2.9550e+00j,
          0.0000e+00+0.0000e+00j, -2.7211e+00-1.6243e+00j,
         -8.4874e-01-1.1403e+00j,  1.3041e-01-8.8561e-02j,
          9.0080e-01+1.8398e-01j,  2.7211e+00+1.6243e+00j,
          0.0000e+00+0.0000e+00j, -1.1194e+00-7.8553e-01j,
         -2.1968e-01+1.6528e-02j,  1.4491e+00+2.2701e+00j,
          8.4874e-01+1.1403e+00j,  1.1194e+00+7.8553e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -1.4688e+00-4.4307e-01j,
         -2.0822e+00+1.0627e+00j,  6.5516e-01-2.5171e-01j,
          1.3284e+00-7.8379e-01j,  1.4688e+00+4.4307e-01j,
          0.0000e+00+0.0000e+00j, -2.8521e+00-1.7401e-01j,
         -1.1381e+00+3.3093e-01j,  1.5043e+00+3.3606e-02j,
          2.0822e+00-1.0627e+00j,  2.8521e+00+1.7401e-01j,
          0.0000e+00+0.0000e+00j,  4.6373e-01+7.6571e-01j,
          1.3618e+00-5.7519e-01j, -6.5516e-01+2.5171e-01j,
          1.1381e+00-3.3093e-01j, -4.6373e-01-7.6571e-01j,
          0.0000e+00+0.0000e+00j,  4.8770e-01+7.0755e-01j,
         -1.3284e+00+7.8379e-01j, -1.5043e+00-3.3606e-02j,
         -1.3618e+00+5.7519e-01j, -4.8770e-01-7.0755e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  4.5278e-01-2.0853e-01j,
         -8.2821e-01-1.4705e-01j,  6.6287e-01+1.8157e-01j,
          8.1542e-01-6.4004e-02j, -4.5278e-01+2.0853e-01j,
          0.0000e+00+0.0000e+00j, -1.9981e-01-1.8770e+00j,
         -2.0486e-01+6.6998e-02j,  4.2076e-02+1.1693e+00j,
          8.2821e-01+1.4705e-01j,  1.9981e-01+1.8770e+00j,
          0.0000e+00+0.0000e+00j, -2.4604e-01+1.0203e+00j,
          6.3282e-01+4.6727e-01j, -6.6287e-01-1.8157e-01j,
          2.0486e-01-6.6998e-02j,  2.4604e-01-1.0203e+00j,
          0.0000e+00+0.0000e+00j, -3.1966e-01+1.3871e-01j,
         -8.1542e-01+6.4004e-02j, -4.2076e-02-1.1693e+00j,
         -6.3282e-01-4.6727e-01j,  3.1966e-01-1.3871e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.4415e-01+6.3133e-02j,
          9.0660e-01-2.3347e+00j,  2.6591e-01+1.0783e+00j,
         -6.5974e-01+1.2112e+00j, -1.4415e-01-6.3133e-02j,
          0.0000e+00+0.0000e+00j, -2.6798e-01-1.1805e+00j,
          5.8987e-01-1.3456e+00j,  3.0531e-01+1.1188e+00j,
         -9.0660e-01+2.3347e+00j,  2.6798e-01+1.1805e+00j,
          0.0000e+00+0.0000e+00j,  1.5532e+00-1.1515e-02j,
         -4.0404e-01+1.1510e+00j, -2.6591e-01-1.0783e+00j,
         -5.8987e-01+1.3456e+00j, -1.5532e+00+1.1515e-02j,
          0.0000e+00+0.0000e+00j,  5.1794e-01-6.3517e-01j,
          6.5974e-01-1.2112e+00j, -3.0531e-01-1.1188e+00j,
          4.0404e-01-1.1510e+00j, -5.1794e-01+6.3517e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -5.0913e-01-1.8365e+00j,
         -1.8391e+00-8.7348e-01j, -1.3041e-01-8.8561e-02j,
          2.1968e-01+1.6528e-02j,  5.0913e-01+1.8365e+00j,
          0.0000e+00+0.0000e+00j,  2.4690e+00-2.9550e+00j,
         -9.0080e-01+1.8398e-01j, -1.4491e+00+2.2701e+00j,
          1.8391e+00+8.7348e-01j, -2.4690e+00+2.9550e+00j,
          0.0000e+00+0.0000e+00j, -2.7211e+00+1.6243e+00j,
         -8.4874e-01+1.1403e+00j,  1.3041e-01+8.8561e-02j,
          9.0080e-01-1.8398e-01j,  2.7211e+00-1.6243e+00j,
          0.0000e+00+0.0000e+00j, -1.1194e+00+7.8553e-01j,
         -2.1968e-01-1.6528e-02j,  1.4491e+00-2.2701e+00j,
          8.4874e-01-1.1403e+00j,  1.1194e+00-7.8553e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  4.0647e-01+0.0000e+00j,
          2.3590e+00+0.0000e+00j, -4.4840e-01+0.0000e+00j,
         -7.0010e-01+0.0000e+00j, -4.0647e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -1.1028e+00+0.0000e+00j,
          8.3067e-01+0.0000e+00j,  5.5832e-01+0.0000e+00j,
         -2.3590e+00+0.0000e+00j,  1.1028e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  3.4256e+00+0.0000e+00j,
          3.0754e-01+0.0000e+00j,  4.4840e-01+0.0000e+00j,
         -8.3067e-01+0.0000e+00j, -3.4256e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  1.1336e+00+0.0000e+00j,
          7.0010e-01+0.0000e+00j, -5.5832e-01+0.0000e+00j,
         -3.0754e-01+0.0000e+00j, -1.1336e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -1.2232e+00-3.8779e-02j,
          3.0044e-01+1.0461e+00j,  6.7728e-01-1.1666e-01j,
          5.2931e-01-6.2227e-01j,  1.2232e+00+3.8779e-02j,
          0.0000e+00+0.0000e+00j, -1.4974e+00-1.5042e+00j,
         -5.2483e-01+7.3272e-01j,  7.7319e-01+6.6187e-01j,
         -3.0044e-01-1.0461e+00j,  1.4974e+00+1.5042e+00j,
          0.0000e+00+0.0000e+00j,  8.1693e-01+1.6825e+00j,
          1.7233e-01+4.1119e-01j, -6.7728e-01+1.1666e-01j,
          5.2483e-01-7.3272e-01j, -8.1693e-01-1.6825e+00j,
          0.0000e+00+0.0000e+00j,  5.6894e-01+1.0597e+00j,
         -5.2931e-01+6.2227e-01j, -7.7319e-01-6.6187e-01j,
         -1.7233e-01-4.1119e-01j, -5.6894e-01-1.0597e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -6.2133e-01-4.9666e-01j,
         -1.9661e+00-1.6991e+00j, -2.4991e-01-4.1728e-01j,
          1.5127e+00+2.1993e-01j,  6.2133e-01+4.9666e-01j,
          0.0000e+00+0.0000e+00j,  5.4007e-01-4.4791e-01j,
         -1.4764e+00-6.9333e-01j, -3.3024e-01+2.8122e-01j,
          1.9661e+00+1.6991e+00j, -5.4007e-01+4.4791e-01j,
          0.0000e+00+0.0000e+00j, -2.6221e+00-2.4041e-01j,
          8.1628e-01+1.4775e+00j,  2.4991e-01+4.1728e-01j,
          1.4764e+00+6.9333e-01j,  2.6221e+00+2.4041e-01j,
          0.0000e+00+0.0000e+00j, -5.9988e-01-3.0294e-01j,
         -1.5127e+00-2.1993e-01j,  3.3024e-01-2.8122e-01j,
         -8.1628e-01-1.4775e+00j,  5.9988e-01+3.0294e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  1.1748e-01+5.7510e-01j,
          6.2723e-01+8.2225e-01j,  1.9392e-03+1.7370e-01j,
          6.6068e-01-6.5212e-01j, -1.1748e-01-5.7510e-01j,
          0.0000e+00+0.0000e+00j,  1.6768e+00+3.9248e-01j,
         -5.4691e-02+2.3834e-01j, -9.1764e-01-2.6212e-01j,
         -6.2723e-01-8.2225e-01j, -1.6768e+00-3.9248e-01j,
          0.0000e+00+0.0000e+00j, -1.2638e+00+3.2441e-01j,
         -1.1338e+00-1.4816e-02j, -1.9392e-03-1.7370e-01j,
          5.4691e-02-2.3834e-01j,  1.2638e+00-3.2441e-01j,
          0.0000e+00+0.0000e+00j, -5.2333e-01+5.6310e-02j,
         -6.6068e-01+6.5212e-01j,  9.1764e-01+2.6212e-01j,
          1.1338e+00+1.4816e-02j,  5.2333e-01-5.6310e-02j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -1.4688e+00+4.4307e-01j,
         -2.0822e+00-1.0627e+00j,  6.5516e-01+2.5171e-01j,
          1.3284e+00+7.8379e-01j,  1.4688e+00-4.4307e-01j,
          0.0000e+00+0.0000e+00j, -2.8521e+00+1.7401e-01j,
         -1.1381e+00-3.3093e-01j,  1.5043e+00-3.3606e-02j,
          2.0822e+00+1.0627e+00j,  2.8521e+00-1.7401e-01j,
          0.0000e+00+0.0000e+00j,  4.6373e-01-7.6571e-01j,
          1.3618e+00+5.7519e-01j, -6.5516e-01-2.5171e-01j,
          1.1381e+00+3.3093e-01j, -4.6373e-01+7.6571e-01j,
          0.0000e+00+0.0000e+00j,  4.8770e-01-7.0755e-01j,
         -1.3284e+00-7.8379e-01j, -1.5043e+00+3.3606e-02j,
         -1.3618e+00-5.7519e-01j, -4.8770e-01+7.0755e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -1.2232e+00+3.8779e-02j,
          3.0044e-01-1.0461e+00j,  6.7728e-01+1.1666e-01j,
          5.2931e-01+6.2227e-01j,  1.2232e+00-3.8779e-02j,
          0.0000e+00+0.0000e+00j, -1.4974e+00+1.5042e+00j,
         -5.2483e-01-7.3272e-01j,  7.7319e-01-6.6187e-01j,
         -3.0044e-01+1.0461e+00j,  1.4974e+00-1.5042e+00j,
          0.0000e+00+0.0000e+00j,  8.1693e-01-1.6825e+00j,
          1.7233e-01-4.1119e-01j, -6.7728e-01-1.1666e-01j,
          5.2483e-01+7.3272e-01j, -8.1693e-01+1.6825e+00j,
          0.0000e+00+0.0000e+00j,  5.6894e-01-1.0597e+00j,
         -5.2931e-01-6.2227e-01j, -7.7319e-01+6.6187e-01j,
         -1.7233e-01+4.1119e-01j, -5.6894e-01+1.0597e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -8.3360e-01+0.0000e+00j,
         -2.0211e+00+0.0000e+00j,  1.3179e-01+0.0000e+00j,
          1.1326e+00+0.0000e+00j,  8.3360e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -9.7158e-01+0.0000e+00j,
         -1.0122e+00+0.0000e+00j,  5.4749e-01+0.0000e+00j,
          2.0211e+00+0.0000e+00j,  9.7158e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -1.0646e+00+0.0000e+00j,
          9.7985e-01+0.0000e+00j, -1.3179e-01+0.0000e+00j,
          1.0122e+00+0.0000e+00j,  1.0646e+00+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -3.5078e-01+0.0000e+00j,
         -1.1326e+00+0.0000e+00j, -5.4749e-01+0.0000e+00j,
         -9.7985e-01+0.0000e+00j,  3.5078e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  5.4324e-01+4.3631e-01j,
         -1.2535e+00+1.8403e+00j, -3.4062e-01-5.1447e-01j,
         -3.5496e-01-5.1904e-01j, -5.4324e-01-4.3631e-01j,
          0.0000e+00+0.0000e+00j,  8.8587e-01-3.2437e-01j,
         -7.7339e-02+1.2728e+00j, -6.6840e-01-1.6934e-01j,
          1.2535e+00-1.8403e+00j, -8.8587e-01+3.2437e-01j,
          0.0000e+00+0.0000e+00j, -2.5955e+00+2.3968e+00j,
         -6.0851e-01-3.4232e-01j,  3.4062e-01+5.1447e-01j,
          7.7339e-02-1.2728e+00j,  2.5955e+00-2.3968e+00j,
          0.0000e+00+0.0000e+00j, -1.0889e+00+1.2083e+00j,
          3.5496e-01+5.1904e-01j,  6.6840e-01+1.6934e-01j,
          6.0851e-01+3.4232e-01j,  1.0889e+00-1.2083e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  4.4269e-01-3.6771e-02j,
          7.2476e-01-3.2081e-01j, -8.0388e-02-3.9437e-01j,
         -4.2664e-01-4.4590e-01j, -4.4269e-01+3.6771e-02j,
          0.0000e+00+0.0000e+00j, -1.8157e-01-1.3197e-01j,
          3.1662e-01+3.9380e-01j,  1.0048e-01+3.9145e-01j,
         -7.2476e-01+3.2081e-01j,  1.8157e-01+1.3197e-01j,
          0.0000e+00+0.0000e+00j,  1.1081e+00+2.3731e-01j,
          1.3909e-01+6.5741e-02j,  8.0388e-02+3.9437e-01j,
         -3.1662e-01-3.9380e-01j, -1.1081e+00-2.3731e-01j,
          0.0000e+00+0.0000e+00j,  4.6694e-02-6.1597e-01j,
          4.2664e-01+4.4590e-01j, -1.0048e-01-3.9145e-01j,
         -1.3909e-01-6.5741e-02j, -4.6694e-02+6.1597e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  4.5278e-01+2.0853e-01j,
         -8.2821e-01+1.4705e-01j,  6.6287e-01-1.8157e-01j,
          8.1542e-01+6.4004e-02j, -4.5278e-01-2.0853e-01j,
          0.0000e+00+0.0000e+00j, -1.9981e-01+1.8770e+00j,
         -2.0486e-01-6.6998e-02j,  4.2076e-02-1.1693e+00j,
          8.2821e-01-1.4705e-01j,  1.9981e-01-1.8770e+00j,
          0.0000e+00+0.0000e+00j, -2.4604e-01-1.0203e+00j,
          6.3282e-01-4.6727e-01j, -6.6287e-01+1.8157e-01j,
          2.0486e-01+6.6998e-02j,  2.4604e-01+1.0203e+00j,
          0.0000e+00+0.0000e+00j, -3.1966e-01-1.3871e-01j,
         -8.1542e-01-6.4004e-02j, -4.2076e-02+1.1693e+00j,
         -6.3282e-01+4.6727e-01j,  3.1966e-01+1.3871e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j, -6.2133e-01+4.9666e-01j,
         -1.9661e+00+1.6991e+00j, -2.4991e-01+4.1728e-01j,
          1.5127e+00-2.1993e-01j,  6.2133e-01-4.9666e-01j,
          0.0000e+00+0.0000e+00j,  5.4007e-01+4.4791e-01j,
         -1.4764e+00+6.9333e-01j, -3.3024e-01-2.8122e-01j,
          1.9661e+00-1.6991e+00j, -5.4007e-01-4.4791e-01j,
          0.0000e+00+0.0000e+00j, -2.6221e+00+2.4041e-01j,
          8.1628e-01-1.4775e+00j,  2.4991e-01-4.1728e-01j,
          1.4764e+00-6.9333e-01j,  2.6221e+00-2.4041e-01j,
          0.0000e+00+0.0000e+00j, -5.9988e-01+3.0294e-01j,
         -1.5127e+00+2.1993e-01j,  3.3024e-01+2.8122e-01j,
         -8.1628e-01+1.4775e+00j,  5.9988e-01-3.0294e-01j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  5.4324e-01-4.3631e-01j,
         -1.2535e+00-1.8403e+00j, -3.4062e-01+5.1447e-01j,
         -3.5496e-01+5.1904e-01j, -5.4324e-01+4.3631e-01j,
          0.0000e+00+0.0000e+00j,  8.8587e-01+3.2437e-01j,
         -7.7339e-02-1.2728e+00j, -6.6840e-01+1.6934e-01j,
          1.2535e+00+1.8403e+00j, -8.8587e-01-3.2437e-01j,
          0.0000e+00+0.0000e+00j, -2.5955e+00-2.3968e+00j,
         -6.0851e-01+3.4232e-01j,  3.4062e-01-5.1447e-01j,
          7.7339e-02+1.2728e+00j,  2.5955e+00+2.3968e+00j,
          0.0000e+00+0.0000e+00j, -1.0889e+00-1.2083e+00j,
          3.5496e-01-5.1904e-01j,  6.6840e-01-1.6934e-01j,
          6.0851e-01-3.4232e-01j,  1.0889e+00+1.2083e+00j,
          0.0000e+00+0.0000e+00j],
        [ 0.0000e+00+0.0000e+00j,  6.7298e-01+0.0000e+00j,
          1.2470e+00+0.0000e+00j, -1.0098e-01+0.0000e+00j,
         -1.8411e+00+0.0000e+00j, -6.7298e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -7.5079e-01+0.0000e+00j,
          9.7484e-01+0.0000e+00j, -4.6859e-02+0.0000e+00j,
         -1.2470e+00+0.0000e+00j,  7.5079e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j, -6.6986e-01+0.0000e+00j,
         -8.8210e-01+0.0000e+00j,  1.0098e-01+0.0000e+00j,
         -9.7484e-01+0.0000e+00j,  6.6986e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j,  1.4120e-01+0.0000e+00j,
          1.8411e+00+0.0000e+00j,  4.6859e-02+0.0000e+00j,
          8.8210e-01+0.0000e+00j, -1.4120e-01+0.0000e+00j,
          0.0000e+00+0.0000e+00j]], dtype=torch.complex128)
Analytical:
tensor([[ 0.0000+0.0000j, -0.4559+0.0000j,  1.2912+0.0000j,  0.1153+0.0000j,
         -1.1811+0.0000j,  0.4559+0.0000j,  0.0000+0.0000j,  0.0243+0.0000j,
          1.2005+0.0000j,  0.1676+0.0000j, -1.2912+0.0000j, -0.0243+0.0000j,
          0.0000+0.0000j,  2.3918+0.0000j, -0.7624+0.0000j, -0.1153+0.0000j,
         -1.2005+0.0000j, -2.3918+0.0000j,  0.0000+0.0000j,  0.9385+0.0000j,
          1.1811+0.0000j, -0.1676+0.0000j,  0.7624+0.0000j, -0.9385+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  1.5367-0.5418j,  0.1802+0.0306j, -0.5433-0.8284j,
          0.3367-0.5477j, -1.5367+0.5418j,  0.0000+0.0000j,  4.1134+1.8237j,
         -0.3180-0.1760j, -2.7153-0.7546j, -0.1802-0.0306j, -4.1134-1.8237j,
          0.0000+0.0000j, -1.8290-0.3681j, -0.9640-0.3100j,  0.5433+0.8284j,
          0.3180+0.1760j,  1.8290+0.3681j,  0.0000+0.0000j, -1.0764-0.0060j,
         -0.3367+0.5477j,  2.7153+0.7546j,  0.9640+0.3100j,  1.0764+0.0060j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2106+0.0306j, -0.4444+3.4091j,  0.1213-1.2004j,
         -0.4458-1.3984j, -0.2106-0.0306j,  0.0000+0.0000j,  0.8473+0.1676j,
          0.3256+1.5739j, -0.4362-0.8291j,  0.4444-3.4091j, -0.8473-0.1676j,
          0.0000+0.0000j, -1.0873+1.1727j, -0.6020-0.5465j, -0.1213+1.2004j,
         -0.3256-1.5739j,  1.0873-1.1727j,  0.0000+0.0000j, -0.6905+1.3634j,
          0.4458+1.3984j,  0.4362+0.8291j,  0.6020+0.5465j,  0.6905-1.3634j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0891-0.8284j, -0.5279-1.2004j,  0.0689+0.0943j,
          1.2309+0.6415j,  0.0891+0.8284j,  0.0000+0.0000j,  2.5761+0.0402j,
         -0.5969-0.3305j, -1.2314+0.4263j,  0.5279+1.2004j, -2.5761-0.0402j,
          0.0000+0.0000j, -2.3358+0.1394j, -1.1403-0.5864j, -0.0689-0.0943j,
          0.5969+0.3305j,  2.3358-0.1394j,  0.0000+0.0000j, -1.1628-0.1077j,
         -1.2309-0.6415j,  1.2314-0.4263j,  1.1403+0.5864j,  1.1628+0.1077j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.5281-0.5477j,  0.1540-1.3984j, -0.1063+0.6415j,
         -0.3856+1.1760j, -0.5281+0.5477j,  0.0000+0.0000j,  0.4915+0.5403j,
          0.2851-0.9451j, -0.2179-0.1301j, -0.1540+1.3984j, -0.4915-0.5403j,
          0.0000+0.0000j,  0.1195-0.6528j, -0.2304-0.1408j,  0.1063-0.6415j,
         -0.2851+0.9451j, -0.1195+0.6528j,  0.0000+0.0000j, -0.4858+0.1067j,
          0.3856-1.1760j,  0.2179+0.1301j,  0.2304+0.1408j,  0.4858-0.1067j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  1.5367+0.5418j,  0.1802-0.0306j, -0.5433+0.8284j,
          0.3367+0.5477j, -1.5367-0.5418j,  0.0000+0.0000j,  4.1134-1.8237j,
         -0.3180+0.1760j, -2.7153+0.7546j, -0.1802+0.0306j, -4.1134+1.8237j,
          0.0000+0.0000j, -1.8290+0.3681j, -0.9640+0.3100j,  0.5433-0.8284j,
          0.3180-0.1760j,  1.8290-0.3681j,  0.0000+0.0000j, -1.0764+0.0060j,
         -0.3367-0.5477j,  2.7153-0.7546j,  0.9640-0.3100j,  1.0764-0.0060j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.9132+0.0000j, -4.5865+0.0000j,  0.6408+0.0000j,
          3.5654+0.0000j,  0.9132+0.0000j,  0.0000+0.0000j,  2.3008+0.0000j,
         -2.8383+0.0000j, -0.5041+0.0000j,  4.5865+0.0000j, -2.3008+0.0000j,
          0.0000+0.0000j, -3.7487+0.0000j,  0.7610+0.0000j, -0.6408+0.0000j,
          2.8383+0.0000j,  3.7487+0.0000j,  0.0000+0.0000j, -1.8556+0.0000j,
         -3.5654+0.0000j,  0.5041+0.0000j, -0.7610+0.0000j,  1.8556+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.6491+1.8237j, -1.0934+0.1676j, -0.2665+0.0402j,
          0.2195+0.5403j,  0.6491-1.8237j,  0.0000+0.0000j,  2.1247+4.1374j,
         -0.8757-0.7111j, -1.2077-2.7678j,  1.0934-0.1676j, -2.1247-4.1374j,
          0.0000+0.0000j, -1.0162-2.3968j, -0.7037-1.1995j,  0.2665-0.0402j,
          0.8757+0.7111j,  1.0162+2.3968j,  0.0000+0.0000j, -0.2119-1.1998j,
         -0.2195-0.5403j,  1.2077+2.7678j,  0.7037+1.1995j,  0.2119+1.1998j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -1.0983-0.1760j, -2.5084+1.5739j,  0.7175-0.3305j,
          1.2145-0.9451j,  1.0983+0.1760j,  0.0000+0.0000j, -2.0243-0.7111j,
         -1.0347+0.5962j,  1.1058+0.1284j,  2.5084-1.5739j,  2.0243+0.7111j,
          0.0000+0.0000j, -0.7783+0.8773j,  0.9684-0.2871j, -0.7175+0.3305j,
          1.0347-0.5962j,  0.7783-0.8773j,  0.0000+0.0000j, -0.2991+0.8445j,
         -1.2145+0.9451j, -1.1058-0.1284j, -0.9684+0.2871j,  0.2991-0.8445j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.6274-0.7546j, -1.1261-0.8291j,  0.7356+0.4263j,
          0.8638-0.1301j, -0.6274+0.7546j,  0.0000+0.0000j,  0.3297-2.7678j,
         -0.2752+0.1284j, -0.1782+1.8659j,  1.1261+0.8291j, -0.3297+2.7678j,
          0.0000+0.0000j, -1.0400+1.4544j,  0.4109+0.3474j, -0.7356-0.4263j,
          0.2752-0.1284j,  1.0400-1.4544j,  0.0000+0.0000j, -0.7634+0.2209j,
         -0.8638+0.1301j,  0.1782-1.8659j, -0.4109-0.3474j,  0.7634-0.2209j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2106-0.0306j, -0.4444-3.4091j,  0.1213+1.2004j,
         -0.4458+1.3984j, -0.2106+0.0306j,  0.0000+0.0000j,  0.8473-0.1676j,
          0.3256-1.5739j, -0.4362+0.8291j,  0.4444+3.4091j, -0.8473+0.1676j,
          0.0000+0.0000j, -1.0873-1.1727j, -0.6020+0.5465j, -0.1213-1.2004j,
         -0.3256+1.5739j,  1.0873+1.1727j,  0.0000+0.0000j, -0.6905-1.3634j,
          0.4458-1.3984j,  0.4362-0.8291j,  0.6020-0.5465j,  0.6905+1.3634j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.6491-1.8237j, -1.0934-0.1676j, -0.2665-0.0402j,
          0.2195-0.5403j,  0.6491+1.8237j,  0.0000+0.0000j,  2.1247-4.1374j,
         -0.8757+0.7111j, -1.2077+2.7678j,  1.0934+0.1676j, -2.1247+4.1374j,
          0.0000+0.0000j, -1.0162+2.3968j, -0.7037+1.1995j,  0.2665+0.0402j,
          0.8757-0.7111j,  1.0162-2.3968j,  0.0000+0.0000j, -0.2119+1.1998j,
         -0.2195+0.5403j,  1.2077-2.7678j,  0.7037-1.1995j,  0.2119-1.1998j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  1.0388+0.0000j,  2.1324+0.0000j, -0.5884+0.0000j,
         -1.2494+0.0000j, -1.0388+0.0000j,  0.0000+0.0000j,  0.4856+0.0000j,
          1.0397+0.0000j, -0.5919+0.0000j, -2.1324+0.0000j, -0.4856+0.0000j,
          0.0000+0.0000j,  0.7586+0.0000j, -0.4476+0.0000j,  0.5884+0.0000j,
         -1.0397+0.0000j, -0.7586+0.0000j,  0.0000+0.0000j, -0.1044+0.0000j,
          1.2494+0.0000j,  0.5919+0.0000j,  0.4476+0.0000j,  0.1044+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -1.0454-0.3681j, -0.2864+1.1727j,  0.6958+0.1394j,
          0.5657-0.6528j,  1.0454+0.3681j,  0.0000+0.0000j, -0.9054-2.3968j,
         -0.5169+0.8773j,  0.5163+1.4544j,  0.2864-1.1727j,  0.9054+2.3968j,
          0.0000+0.0000j, -0.1638+3.3088j, -0.0225+0.3807j, -0.6958-0.1394j,
          0.5169-0.8773j,  0.1638-3.3088j,  0.0000+0.0000j, -0.0590+1.6176j,
         -0.5657+0.6528j, -0.5163-1.4544j,  0.0225-0.3807j,  0.0590-1.6176j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1768-0.3100j, -1.0903-0.5465j, -0.3280-0.5864j,
          1.0761-0.1408j,  0.1768+0.3100j,  0.0000+0.0000j,  0.5313-1.1995j,
         -1.0959-0.2871j, -0.3511+0.3474j,  1.0903+0.5465j, -0.5313+1.1995j,
          0.0000+0.0000j, -1.8283+0.3807j,  0.6922+1.5707j,  0.3280+0.5864j,
          1.0959+0.2871j,  1.8283-0.3807j,  0.0000+0.0000j, -0.2588+0.2578j,
         -1.0761+0.1408j,  0.3511-0.3474j, -0.6922-1.5707j,  0.2588-0.2578j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0891+0.8284j, -0.5279+1.2004j,  0.0689-0.0943j,
          1.2309-0.6415j,  0.0891-0.8284j,  0.0000+0.0000j,  2.5761-0.0402j,
         -0.5969+0.3305j, -1.2314-0.4263j,  0.5279-1.2004j, -2.5761+0.0402j,
          0.0000+0.0000j, -2.3358-0.1394j, -1.1403+0.5864j, -0.0689+0.0943j,
          0.5969-0.3305j,  2.3358+0.1394j,  0.0000+0.0000j, -1.1628+0.1077j,
         -1.2309+0.6415j,  1.2314+0.4263j,  1.1403-0.5864j,  1.1628-0.1077j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -1.0983+0.1760j, -2.5084-1.5739j,  0.7175+0.3305j,
          1.2145+0.9451j,  1.0983-0.1760j,  0.0000+0.0000j, -2.0243+0.7111j,
         -1.0347-0.5962j,  1.1058-0.1284j,  2.5084+1.5739j,  2.0243-0.7111j,
          0.0000+0.0000j, -0.7783-0.8773j,  0.9684+0.2871j, -0.7175-0.3305j,
          1.0347+0.5962j,  0.7783+0.8773j,  0.0000+0.0000j, -0.2991-0.8445j,
         -1.2145-0.9451j, -1.1058+0.1284j, -0.9684-0.2871j,  0.2991+0.8445j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -1.0454+0.3681j, -0.2864-1.1727j,  0.6958-0.1394j,
          0.5657+0.6528j,  1.0454-0.3681j,  0.0000+0.0000j, -0.9054+2.3968j,
         -0.5169-0.8773j,  0.5163-1.4544j,  0.2864+1.1727j,  0.9054-2.3968j,
          0.0000+0.0000j, -0.1638-3.3088j, -0.0225-0.3807j, -0.6958+0.1394j,
          0.5169+0.8773j,  0.1638+3.3088j,  0.0000+0.0000j, -0.0590-1.6176j,
         -0.5657-0.6528j, -0.5163+1.4544j,  0.0225+0.3807j,  0.0590+1.6176j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.3428+0.0000j, -0.0842+0.0000j, -0.0667+0.0000j,
          0.7062+0.0000j,  0.3428+0.0000j,  0.0000+0.0000j, -2.0598+0.0000j,
         -0.3767+0.0000j,  0.9752+0.0000j,  0.0842+0.0000j,  2.0598+0.0000j,
          0.0000+0.0000j,  1.2682+0.0000j,  1.3310+0.0000j,  0.0667+0.0000j,
          0.3767+0.0000j, -1.2682+0.0000j,  0.0000+0.0000j,  0.8803+0.0000j,
         -0.7062+0.0000j, -0.9752+0.0000j, -1.3310+0.0000j, -0.8803+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.3307-0.0060j, -0.9370+1.3634j, -0.3188-0.1077j,
          0.1575+0.1067j, -0.3307+0.0060j,  0.0000+0.0000j,  0.2175-1.1998j,
         -0.1475+0.8445j, -0.1225+0.2209j,  0.9370-1.3634j, -0.2175+1.1998j,
          0.0000+0.0000j, -0.7826+1.6176j, -0.1887+0.2578j,  0.3188+0.1077j,
          0.1475-0.8445j,  0.7826-1.6176j,  0.0000+0.0000j, -0.3421+0.8343j,
         -0.1575-0.1067j,  0.1225-0.2209j,  0.1887-0.2578j,  0.3421-0.8343j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.5281+0.5477j,  0.1540+1.3984j, -0.1063-0.6415j,
         -0.3856-1.1760j, -0.5281-0.5477j,  0.0000+0.0000j,  0.4915-0.5403j,
          0.2851+0.9451j, -0.2179+0.1301j, -0.1540-1.3984j, -0.4915+0.5403j,
          0.0000+0.0000j,  0.1195+0.6528j, -0.2304+0.1408j,  0.1063+0.6415j,
         -0.2851-0.9451j, -0.1195-0.6528j,  0.0000+0.0000j, -0.4858-0.1067j,
          0.3856+1.1760j,  0.2179-0.1301j,  0.2304-0.1408j,  0.4858+0.1067j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.6274+0.7546j, -1.1261+0.8291j,  0.7356-0.4263j,
          0.8638+0.1301j, -0.6274-0.7546j,  0.0000+0.0000j,  0.3297+2.7678j,
         -0.2752-0.1284j, -0.1782-1.8659j,  1.1261-0.8291j, -0.3297-2.7678j,
          0.0000+0.0000j, -1.0400-1.4544j,  0.4109-0.3474j, -0.7356+0.4263j,
          0.2752+0.1284j,  1.0400+1.4544j,  0.0000+0.0000j, -0.7634-0.2209j,
         -0.8638-0.1301j,  0.1782+1.8659j, -0.4109+0.3474j,  0.7634+0.2209j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1768+0.3100j, -1.0903+0.5465j, -0.3280+0.5864j,
          1.0761+0.1408j,  0.1768-0.3100j,  0.0000+0.0000j,  0.5313+1.1995j,
         -1.0959+0.2871j, -0.3511-0.3474j,  1.0903-0.5465j, -0.5313-1.1995j,
          0.0000+0.0000j, -1.8283-0.3807j,  0.6922-1.5707j,  0.3280-0.5864j,
          1.0959-0.2871j,  1.8283+0.3807j,  0.0000+0.0000j, -0.2588-0.2578j,
         -1.0761-0.1408j,  0.3511+0.3474j, -0.6922+1.5707j,  0.2588+0.2578j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.3307+0.0060j, -0.9370-1.3634j, -0.3188+0.1077j,
          0.1575-0.1067j, -0.3307-0.0060j,  0.0000+0.0000j,  0.2175+1.1998j,
         -0.1475-0.8445j, -0.1225-0.2209j,  0.9370+1.3634j, -0.2175-1.1998j,
          0.0000+0.0000j, -0.7826-1.6176j, -0.1887-0.2578j,  0.3188-0.1077j,
          0.1475+0.8445j,  0.7826+1.6176j,  0.0000+0.0000j, -0.3421-0.8343j,
         -0.1575+0.1067j,  0.1225+0.2209j,  0.1887+0.2578j,  0.3421+0.8343j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.6730+0.0000j,  1.2470+0.0000j, -0.1010+0.0000j,
         -1.8411+0.0000j, -0.6730+0.0000j,  0.0000+0.0000j, -0.7508+0.0000j,
          0.9748+0.0000j, -0.0469+0.0000j, -1.2470+0.0000j,  0.7508+0.0000j,
          0.0000+0.0000j, -0.6699+0.0000j, -0.8821+0.0000j,  0.1010+0.0000j,
         -0.9748+0.0000j,  0.6699+0.0000j,  0.0000+0.0000j,  0.1412+0.0000j,
          1.8411+0.0000j,  0.0469+0.0000j,  0.8821+0.0000j, -0.1412+0.0000j,
          0.0000+0.0000j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 2.8845376775099463.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eigh_cpu_float64" time="0.177" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eigvals_cpu_complex128" time="0.644" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eigvals_cpu_float64" time="0.140" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eigvalsh_cpu_complex128" time="0.114" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(-0.0115-0.1075j, dtype=torch.complex128)&#10;analytical:tensor(0.0124-0.1269j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[ 0.0000e+00+0.0000j, -7.1226e-01+0.0000j,  2.4589e-01+0.0000j,&#10;          3.6800e-01+0.0000j,  3.4854e-01+0.0000j,  7.1226e-01+0.0000j,&#10;          0.0000e+00+0.0000j,  7.0839e-01+0.0000j,  7.9111e-02+0.0000j,&#10;          4.0520e-01+0.0000j, -2.4589e-01+0.0000j, -7.0839e-01+0.0000j,&#10;          0.0000e+00+0.0000j,  7.5657e-01+0.0000j, -9.5455e-01+0.0000j,&#10;         -3.6800e-01+0.0000j, -7.9111e-02+0.0000j, -7.5657e-01+0.0000j,&#10;          0.0000e+00+0.0000j,  2.8989e-01+0.0000j, -3.4854e-01+0.0000j,&#10;         -4.0520e-01+0.0000j,  9.5455e-01+0.0000j, -2.8989e-01+0.0000j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  1.0869e-01+0.2561j, -3.8554e-02-0.0908j,&#10;         -3.5149e-01+0.0184j, -5.1345e-01-0.1842j, -1.0869e-01-0.2561j,&#10;          0.0000e+00+0.0000j,  9.0877e-01+0.1879j, -2.4202e-01-0.3719j,&#10;         -1.1362e+00-0.1333j,  3.8554e-02+0.0908j, -9.0877e-01-0.1879j,&#10;          0.0000e+00+0.0000j, -4.7893e-01-0.2942j, -2.0201e-01+0.3563j,&#10;          3.5149e-01-0.0184j,  2.4202e-01+0.3719j,  4.7893e-01+0.2942j,&#10;          0.0000e+00+0.0000j, -3.5597e-01-0.2674j,  5.1345e-01+0.1842j,&#10;          1.1362e+00+0.1333j,  2.0201e-01-0.3563j,  3.5597e-01+0.2674j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -1.7358e-01-0.1077j,  2.3354e-01+0.7498j,&#10;          4.9344e-02-0.5707j,  4.4840e-01+0.0610j,  1.7358e-01+0.1077j,&#10;          0.0000e+00+0.0000j,  2.5316e-03+0.4555j, -3.0866e-01+0.1302j,&#10;          8.2809e-02-0.3759j, -2.3354e-01-0.7498j, -2.5316e-03-0.4555j,&#10;          0.0000e+00+0.0000j,  4.4704e-01-0.1302j, -3.3332e-01-0.2510j,&#10;         -4.9344e-02+0.5707j,  3.0866e-01-0.1302j, -4.4704e-01+0.1302j,&#10;          0.0000e+00+0.0000j,  2.6715e-01+0.6974j, -4.4840e-01-0.0610j,&#10;         -8.2809e-02+0.3759j,  3.3332e-01+0.2510j, -2.6715e-01-0.6974j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  8.7642e-03+0.1118j,  4.1815e-01-0.5426j,&#10;         -2.4345e-01+0.2043j,  6.7430e-01-0.1604j, -8.7642e-03-0.1118j,&#10;          0.0000e+00+0.0000j,  4.5254e-01-0.2063j, -5.9325e-02+0.1426j,&#10;         -3.5987e-01+0.2819j, -4.1815e-01+0.5426j, -4.5254e-01+0.2063j,&#10;          0.0000e+00+0.0000j, -2.7441e-01-0.1932j, -4.6470e-01+0.0746j,&#10;          2.4345e-01-0.2043j,  5.9325e-02-0.1426j,  2.7441e-01+0.1932j,&#10;          0.0000e+00+0.0000j,  1.1504e-02-0.1257j, -6.7430e-01+0.1604j,&#10;          3.5987e-01-0.2819j,  4.6470e-01-0.0746j, -1.1504e-02+0.1257j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -7.9431e-03-0.1224j, -5.4347e-02+0.5528j,&#10;          8.6071e-03-0.2130j, -8.9172e-02+0.9089j,  7.9431e-03+0.1224j,&#10;          0.0000e+00+0.0000j, -8.6594e-02+0.4329j, -2.2028e-01+0.0403j,&#10;          1.0871e-01-0.2081j,  5.4347e-02-0.5528j,  8.6594e-02-0.4329j,&#10;          0.0000e+00+0.0000j,  2.2963e-01+0.2006j,  3.1705e-02-0.1717j,&#10;         -8.6071e-03+0.2130j,  2.2028e-01-0.0403j, -2.2963e-01-0.2006j,&#10;          0.0000e+00+0.0000j, -1.4030e-01+0.5119j,  8.9172e-02-0.9089j,&#10;         -1.0871e-01+0.2081j, -3.1705e-02+0.1717j,  1.4030e-01-0.5119j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  1.0869e-01-0.2561j, -3.8554e-02+0.0908j,&#10;         -3.5149e-01-0.0184j, -5.1345e-01+0.1842j, -1.0869e-01+0.2561j,&#10;          0.0000e+00+0.0000j,  9.0877e-01-0.1879j, -2.4202e-01+0.3719j,&#10;         -1.1362e+00+0.1333j,  3.8554e-02-0.0908j, -9.0877e-01+0.1879j,&#10;          0.0000e+00+0.0000j, -4.7893e-01+0.2942j, -2.0201e-01-0.3563j,&#10;          3.5149e-01+0.0184j,  2.4202e-01-0.3719j,  4.7893e-01-0.2942j,&#10;          0.0000e+00+0.0000j, -3.5597e-01+0.2674j,  5.1345e-01-0.1842j,&#10;          1.1362e+00-0.1333j,  2.0201e-01+0.3563j,  3.5597e-01-0.2674j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  4.3787e-01+0.0000j, -5.6031e-01+0.0000j,&#10;          4.7696e-01+0.0000j,  8.9543e-01+0.0000j, -4.3787e-01+0.0000j,&#10;          0.0000e+00+0.0000j,  3.8488e-01+0.0000j, -2.6797e-01+0.0000j,&#10;          2.6285e-04+0.0000j,  5.6031e-01+0.0000j, -3.8488e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -5.5111e-01+0.0000j,  8.3811e-02+0.0000j,&#10;         -4.7696e-01+0.0000j,  2.6797e-01+0.0000j,  5.5111e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -4.2137e-01+0.0000j, -8.9543e-01+0.0000j,&#10;         -2.6285e-04+0.0000j, -8.3811e-02+0.0000j,  4.2137e-01+0.0000j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  1.8585e-01+0.0671j, -5.0752e-01+0.4102j,&#10;          5.5556e-02-0.2735j,  5.4867e-02+0.1938j, -1.8585e-01-0.0671j,&#10;          0.0000e+00+0.0000j,  3.8148e-01+1.1253j,  6.6871e-02+0.1283j,&#10;         -5.5128e-01-0.7456j,  5.0752e-01-0.4102j, -3.8148e-01-1.1253j,&#10;          0.0000e+00+0.0000j, -7.4090e-01-0.3885j, -1.8312e-02-0.6672j,&#10;         -5.5556e-02+0.2735j, -6.6871e-02-0.1283j,  7.4090e-01+0.3885j,&#10;          0.0000e+00+0.0000j, -3.8636e-01-0.0151j, -5.4867e-02-0.1938j,&#10;          5.5128e-01+0.7456j,  1.8312e-02+0.6672j,  3.8636e-01+0.0151j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  9.0679e-02-0.1659j, -5.6424e-01-0.0944j,&#10;          1.8538e-01+0.1594j,  4.4636e-01-0.1457j, -9.0679e-02+0.1659j,&#10;          0.0000e+00+0.0000j, -9.6206e-01+0.0327j,  1.9160e-01+0.6947j,&#10;          5.8056e-01+0.4512j,  5.6424e-01+0.0944j,  9.6206e-01-0.0327j,&#10;          0.0000e+00+0.0000j, -2.4625e-03-0.0769j,  5.2800e-01-0.0966j,&#10;         -1.8538e-01-0.1594j, -1.9160e-01-0.6947j,  2.4625e-03+0.0769j,&#10;          0.0000e+00+0.0000j, -1.1122e-01-0.0906j, -4.4636e-01+0.1457j,&#10;         -5.8056e-01-0.4512j, -5.2800e-01+0.0966j,  1.1122e-01+0.0906j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -8.5819e-02+0.0636j, -3.5467e-01-0.1391j,&#10;          2.4364e-01+0.2940j, -4.6922e-01-0.1364j,  8.5819e-02-0.0636j,&#10;          0.0000e+00+0.0000j,  3.1598e-01-0.5765j,  1.8676e-01+0.3850j,&#10;         -1.8591e-02+0.8108j,  3.5467e-01+0.1391j, -3.1598e-01+0.5765j,&#10;          0.0000e+00+0.0000j, -1.2543e-01+0.3942j,  4.9580e-02+0.0459j,&#10;         -2.4364e-01-0.2940j, -1.8676e-01-0.3850j,  1.2543e-01-0.3942j,&#10;          0.0000e+00+0.0000j, -2.6446e-01+0.2122j,  4.6922e-01+0.1364j,&#10;          1.8591e-02-0.8108j, -4.9580e-02-0.0459j,  2.6446e-01-0.2122j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -1.7358e-01+0.1077j,  2.3354e-01-0.7498j,&#10;          4.9344e-02+0.5707j,  4.4840e-01-0.0610j,  1.7358e-01-0.1077j,&#10;          0.0000e+00+0.0000j,  2.5316e-03-0.4555j, -3.0866e-01-0.1302j,&#10;          8.2809e-02+0.3759j, -2.3354e-01+0.7498j, -2.5316e-03+0.4555j,&#10;          0.0000e+00+0.0000j,  4.4704e-01+0.1302j, -3.3332e-01+0.2510j,&#10;         -4.9344e-02-0.5707j,  3.0866e-01+0.1302j, -4.4704e-01-0.1302j,&#10;          0.0000e+00+0.0000j,  2.6715e-01-0.6974j, -4.4840e-01+0.0610j,&#10;         -8.2809e-02-0.3759j,  3.3332e-01-0.2510j, -2.6715e-01+0.6974j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  1.8585e-01-0.0671j, -5.0752e-01-0.4102j,&#10;          5.5556e-02+0.2735j,  5.4867e-02-0.1938j, -1.8585e-01+0.0671j,&#10;          0.0000e+00+0.0000j,  3.8148e-01-1.1253j,  6.6871e-02-0.1283j,&#10;         -5.5128e-01+0.7456j,  5.0752e-01+0.4102j, -3.8148e-01+1.1253j,&#10;          0.0000e+00+0.0000j, -7.4090e-01+0.3885j, -1.8312e-02+0.6672j,&#10;         -5.5556e-02-0.2735j, -6.6871e-02+0.1283j,  7.4090e-01-0.3885j,&#10;          0.0000e+00+0.0000j, -3.8636e-01+0.0151j, -5.4867e-02+0.1938j,&#10;          5.5128e-01-0.7456j,  1.8312e-02-0.6672j,  3.8636e-01-0.0151j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  1.2438e-01+0.0000j, -1.6087e-01+0.0000j,&#10;          2.3567e-01+0.0000j, -3.1640e-01+0.0000j, -1.2438e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -5.6624e-01+0.0000j, -4.4461e-01+0.0000j,&#10;          2.0946e-01+0.0000j,  1.6087e-01+0.0000j,  5.6624e-01+0.0000j,&#10;          0.0000e+00+0.0000j,  5.9633e-01+0.0000j, -4.5737e-04+0.0000j,&#10;         -2.3567e-01+0.0000j,  4.4461e-01+0.0000j, -5.9633e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -2.2567e-01+0.0000j,  3.1640e-01+0.0000j,&#10;         -2.0946e-01+0.0000j,  4.5737e-04+0.0000j,  2.2567e-01+0.0000j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -1.6095e-01-0.2022j,  2.3559e-01+0.2953j,&#10;          1.0270e-01-0.2563j,  8.7586e-01-0.0193j,  1.6095e-01+0.2022j,&#10;          0.0000e+00+0.0000j, -4.5378e-01-0.2702j, -7.4534e-02+0.2510j,&#10;          2.1869e-01+0.2406j, -2.3559e-01-0.2953j,  4.5378e-01+0.2702j,&#10;          0.0000e+00+0.0000j,  2.6357e-01+0.3174j,  1.4364e-01+0.0198j,&#10;         -1.0270e-01+0.2563j,  7.4534e-02-0.2510j, -2.6357e-01-0.3174j,&#10;          0.0000e+00+0.0000j,  8.8921e-02+0.3504j, -8.7586e-01+0.0193j,&#10;         -2.1869e-01-0.2406j, -1.4364e-01-0.0198j, -8.8921e-02-0.3504j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  3.2603e-01+0.2918j, -3.5033e-01-0.3286j,&#10;         -3.0910e-01+0.0639j,  1.8119e-01-0.0163j, -3.2603e-01-0.2918j,&#10;          0.0000e+00+0.0000j, -1.2339e-01-0.5714j,  9.3348e-02-0.3064j,&#10;         -3.0925e-01+0.0170j,  3.5033e-01+0.3286j,  1.2339e-01+0.5714j,&#10;          0.0000e+00+0.0000j, -9.8406e-01-0.0749j,  6.3443e-01+0.5525j,&#10;          3.0910e-01-0.0639j, -9.3348e-02+0.3064j,  9.8406e-01+0.0749j,&#10;          0.0000e+00+0.0000j, -3.3377e-01-0.2349j, -1.8119e-01+0.0163j,&#10;          3.0925e-01-0.0170j, -6.3443e-01-0.5525j,  3.3377e-01+0.2349j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  8.7642e-03-0.1118j,  4.1815e-01+0.5426j,&#10;         -2.4345e-01-0.2043j,  6.7430e-01+0.1604j, -8.7642e-03+0.1118j,&#10;          0.0000e+00+0.0000j,  4.5254e-01+0.2063j, -5.9325e-02-0.1426j,&#10;         -3.5987e-01-0.2819j, -4.1815e-01-0.5426j, -4.5254e-01-0.2063j,&#10;          0.0000e+00+0.0000j, -2.7441e-01+0.1932j, -4.6470e-01-0.0746j,&#10;          2.4345e-01+0.2043j,  5.9325e-02+0.1426j,  2.7441e-01-0.1932j,&#10;          0.0000e+00+0.0000j,  1.1504e-02+0.1257j, -6.7430e-01-0.1604j,&#10;          3.5987e-01+0.2819j,  4.6470e-01+0.0746j, -1.1504e-02-0.1257j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  9.0679e-02+0.1659j, -5.6424e-01+0.0944j,&#10;          1.8538e-01-0.1594j,  4.4636e-01+0.1457j, -9.0679e-02-0.1659j,&#10;          0.0000e+00+0.0000j, -9.6206e-01-0.0327j,  1.9160e-01-0.6947j,&#10;          5.8056e-01-0.4512j,  5.6424e-01-0.0944j,  9.6206e-01+0.0327j,&#10;          0.0000e+00+0.0000j, -2.4625e-03+0.0769j,  5.2800e-01+0.0966j,&#10;         -1.8538e-01+0.1594j, -1.9160e-01+0.6947j,  2.4625e-03-0.0769j,&#10;          0.0000e+00+0.0000j, -1.1122e-01+0.0906j, -4.4636e-01-0.1457j,&#10;         -5.8056e-01+0.4512j, -5.2800e-01-0.0966j,  1.1122e-01-0.0906j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -1.6095e-01+0.2022j,  2.3559e-01-0.2953j,&#10;          1.0270e-01+0.2563j,  8.7586e-01+0.0193j,  1.6095e-01-0.2022j,&#10;          0.0000e+00+0.0000j, -4.5378e-01+0.2702j, -7.4534e-02-0.2510j,&#10;          2.1869e-01-0.2406j, -2.3559e-01+0.2953j,  4.5378e-01-0.2702j,&#10;          0.0000e+00+0.0000j,  2.6357e-01-0.3174j,  1.4364e-01-0.0198j,&#10;         -1.0270e-01-0.2563j,  7.4534e-02+0.2510j, -2.6357e-01+0.3174j,&#10;          0.0000e+00+0.0000j,  8.8921e-02-0.3504j, -8.7586e-01-0.0193j,&#10;         -2.1869e-01+0.2406j, -1.4364e-01+0.0198j, -8.8921e-02+0.3504j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  1.8985e-01+0.0000j, -5.5124e-01+0.0000j,&#10;          7.4477e-02+0.0000j, -1.5041e-01+0.0000j, -1.8985e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -4.7381e-01+0.0000j, -4.7300e-02+0.0000j,&#10;          4.1332e-02+0.0000j,  5.5124e-01+0.0000j,  4.7381e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -2.5455e-01+0.0000j,  5.5287e-01+0.0000j,&#10;         -7.4477e-02+0.0000j,  4.7300e-02+0.0000j,  2.5455e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -2.2317e-01+0.0000j,  1.5041e-01+0.0000j,&#10;         -4.1332e-02+0.0000j, -5.5287e-01+0.0000j,  2.2317e-01+0.0000j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -1.6308e-01-0.1190j, -1.0400e-01+0.5329j,&#10;         -3.1336e-01-0.0128j, -1.8766e-02+0.1645j,  1.6308e-01+0.1190j,&#10;          0.0000e+00+0.0000j,  5.7516e-01+0.0517j,  6.2042e-01+0.0069j,&#10;         -3.4424e-01+0.3667j,  1.0400e-01-0.5329j, -5.7516e-01-0.0517j,&#10;          0.0000e+00+0.0000j, -6.5697e-01+0.5530j, -4.2617e-01-0.3952j,&#10;          3.1336e-01+0.0128j, -6.2042e-01-0.0069j,  6.5697e-01-0.5530j,&#10;          0.0000e+00+0.0000j, -2.2768e-01+0.5651j,  1.8766e-02-0.1645j,&#10;          3.4424e-01-0.3667j,  4.2617e-01+0.3952j,  2.2768e-01-0.5651j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -7.9431e-03+0.1224j, -5.4347e-02-0.5528j,&#10;          8.6071e-03+0.2130j, -8.9172e-02-0.9089j,  7.9431e-03-0.1224j,&#10;          0.0000e+00+0.0000j, -8.6594e-02-0.4329j, -2.2028e-01-0.0403j,&#10;          1.0871e-01+0.2081j,  5.4347e-02+0.5528j,  8.6594e-02+0.4329j,&#10;          0.0000e+00+0.0000j,  2.2963e-01-0.2006j,  3.1705e-02+0.1717j,&#10;         -8.6071e-03-0.2130j,  2.2028e-01+0.0403j, -2.2963e-01+0.2006j,&#10;          0.0000e+00+0.0000j, -1.4030e-01-0.5119j,  8.9172e-02+0.9089j,&#10;         -1.0871e-01-0.2081j, -3.1705e-02-0.1717j,  1.4030e-01+0.5119j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -8.5819e-02-0.0636j, -3.5467e-01+0.1391j,&#10;          2.4364e-01-0.2940j, -4.6922e-01+0.1364j,  8.5819e-02+0.0636j,&#10;          0.0000e+00+0.0000j,  3.1598e-01+0.5765j,  1.8676e-01-0.3850j,&#10;         -1.8591e-02-0.8108j,  3.5467e-01-0.1391j, -3.1598e-01-0.5765j,&#10;          0.0000e+00+0.0000j, -1.2543e-01-0.3942j,  4.9580e-02-0.0459j,&#10;         -2.4364e-01+0.2940j, -1.8676e-01+0.3850j,  1.2543e-01+0.3942j,&#10;          0.0000e+00+0.0000j, -2.6446e-01-0.2122j,  4.6922e-01-0.1364j,&#10;          1.8591e-02+0.8108j, -4.9580e-02+0.0459j,  2.6446e-01+0.2122j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j,  3.2603e-01-0.2918j, -3.5033e-01+0.3286j,&#10;         -3.0910e-01-0.0639j,  1.8119e-01+0.0163j, -3.2603e-01+0.2918j,&#10;          0.0000e+00+0.0000j, -1.2339e-01+0.5714j,  9.3348e-02+0.3064j,&#10;         -3.0925e-01-0.0170j,  3.5033e-01-0.3286j,  1.2339e-01-0.5714j,&#10;          0.0000e+00+0.0000j, -9.8406e-01+0.0749j,  6.3443e-01-0.5525j,&#10;          3.0910e-01+0.0639j, -9.3348e-02-0.3064j,  9.8406e-01-0.0749j,&#10;          0.0000e+00+0.0000j, -3.3377e-01+0.2349j, -1.8119e-01-0.0163j,&#10;          3.0925e-01+0.0170j, -6.3443e-01+0.5525j,  3.3377e-01-0.2349j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -1.6308e-01+0.1190j, -1.0400e-01-0.5329j,&#10;         -3.1336e-01+0.0128j, -1.8766e-02-0.1645j,  1.6308e-01-0.1190j,&#10;          0.0000e+00+0.0000j,  5.7516e-01-0.0517j,  6.2042e-01-0.0069j,&#10;         -3.4424e-01-0.3667j,  1.0400e-01+0.5329j, -5.7516e-01+0.0517j,&#10;          0.0000e+00+0.0000j, -6.5697e-01-0.5530j, -4.2617e-01+0.3952j,&#10;          3.1336e-01-0.0128j, -6.2042e-01+0.0069j,  6.5697e-01+0.5530j,&#10;          0.0000e+00+0.0000j, -2.2768e-01-0.5651j,  1.8766e-02+0.1645j,&#10;          3.4424e-01+0.3667j,  4.2617e-01-0.3952j,  2.2768e-01+0.5651j,&#10;          0.0000e+00+0.0000j],&#10;        [ 0.0000e+00+0.0000j, -8.3241e-02+0.0000j,  8.2337e-01+0.0000j,&#10;         -6.7595e-01+0.0000j, -2.3385e-01+0.0000j,  8.3241e-02+0.0000j,&#10;          0.0000e+00+0.0000j,  1.8722e-01+0.0000j,  4.4786e-01+0.0000j,&#10;         -3.2609e-01+0.0000j, -8.2337e-01+0.0000j, -1.8722e-01+0.0000j,&#10;          0.0000e+00+0.0000j, -2.1573e-01+0.0000j, -2.3123e-01+0.0000j,&#10;          6.7595e-01+0.0000j, -4.4786e-01+0.0000j,  2.1573e-01+0.0000j,&#10;          0.0000e+00+0.0000j,  7.9066e-01+0.0000j,  2.3385e-01+0.0000j,&#10;          3.2609e-01+0.0000j,  2.3123e-01+0.0000j, -7.9066e-01+0.0000j,&#10;          0.0000e+00+0.0000j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 0.0000+0.0000j, -0.6972+0.0000j,  0.0517+0.0000j,  0.2064+0.0000j,&#10;          0.0446+0.0000j,  0.6972+0.0000j,  0.0000+0.0000j,  0.2202+0.0000j,&#10;          0.0372+0.0000j,  0.3398+0.0000j, -0.0517+0.0000j, -0.2202+0.0000j,&#10;          0.0000+0.0000j,  0.7849+0.0000j, -0.3722+0.0000j, -0.2064+0.0000j,&#10;         -0.0372+0.0000j, -0.7849+0.0000j,  0.0000+0.0000j,  0.1094+0.0000j,&#10;         -0.0446+0.0000j, -0.3398+0.0000j,  0.3722+0.0000j, -0.1094+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1825+0.2558j, -0.1405-0.1758j, -0.2023+0.0933j,&#10;         -0.1846-0.0609j, -0.1825-0.2558j,  0.0000+0.0000j,  1.0480+0.2072j,&#10;         -0.4395-0.1987j, -1.1272+0.0112j,  0.1405+0.1758j, -1.0480-0.2072j,&#10;          0.0000+0.0000j, -0.3464-0.2914j, -0.3153+0.2398j,  0.2023-0.0933j,&#10;          0.4395+0.1987j,  0.3464+0.2914j,  0.0000+0.0000j, -0.3796-0.1880j,&#10;          0.1846+0.0609j,  1.1272-0.0112j,  0.3153-0.2398j,  0.3796+0.1880j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0851-0.1758j,  0.1410+0.9872j, -0.0518-0.8004j,&#10;          0.0171-0.0365j,  0.0851+0.1758j,  0.0000+0.0000j,  0.3070+0.2061j,&#10;          0.0558+0.1621j, -0.1567-0.4148j, -0.1410-0.9872j, -0.3070-0.2061j,&#10;          0.0000+0.0000j, -0.2308+0.0876j, -0.2313-0.0565j,  0.0518+0.8004j,&#10;         -0.0558-0.1621j,  0.2308-0.0876j,  0.0000+0.0000j, -0.0200+0.7927j,&#10;         -0.0171+0.0365j,  0.1567+0.4148j,  0.2313+0.0565j,  0.0200-0.7927j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1059+0.0933j,  0.1525-0.8004j, -0.0724+0.5898j,&#10;          0.7461+0.2136j, -0.1059-0.0933j,  0.0000+0.0000j,  0.5610-0.1432j,&#10;         -0.1501-0.0801j, -0.4113+0.5231j, -0.1525+0.8004j, -0.5610+0.1432j,&#10;          0.0000+0.0000j, -0.4900+0.0071j, -0.3849-0.1930j,  0.0724-0.5898j,&#10;          0.1501+0.0801j,  0.4900-0.0071j,  0.0000+0.0000j, -0.2840-0.1462j,&#10;         -0.7461-0.2136j,  0.4113-0.5231j,  0.3849+0.1930j,  0.2840+0.1462j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0208-0.0609j, -0.1774-0.0365j,  0.0535+0.2136j,&#10;         -0.2156+1.1209j, -0.0208+0.0609j,  0.0000+0.0000j,  0.0985+0.3547j,&#10;         -0.0599-0.3303j,  0.0820-0.0486j,  0.1774+0.0365j, -0.0985-0.3547j,&#10;          0.0000+0.0000j, -0.0343+0.2652j, -0.0822-0.1331j, -0.0535-0.2136j,&#10;          0.0599+0.3303j,  0.0343-0.2652j,  0.0000+0.0000j, -0.2798+0.2985j,&#10;          0.2156-1.1209j, -0.0820+0.0486j,  0.0822+0.1331j,  0.2798-0.2985j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1825-0.2558j, -0.1405+0.1758j, -0.2023-0.0933j,&#10;         -0.1846+0.0609j, -0.1825+0.2558j,  0.0000+0.0000j,  1.0480-0.2072j,&#10;         -0.4395+0.1987j, -1.1272-0.0112j,  0.1405-0.1758j, -1.0480+0.2072j,&#10;          0.0000+0.0000j, -0.3464+0.2914j, -0.3153-0.2398j,  0.2023+0.0933j,&#10;          0.4395-0.1987j,  0.3464-0.2914j,  0.0000+0.0000j, -0.3796+0.1880j,&#10;          0.1846-0.0609j,  1.1272+0.0112j,  0.3153+0.2398j,  0.3796-0.1880j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.5503+0.0000j, -0.8170+0.0000j,  0.6324+0.0000j,&#10;          1.0943+0.0000j, -0.5503+0.0000j,  0.0000+0.0000j,  0.2204+0.0000j,&#10;         -0.3906+0.0000j,  0.0679+0.0000j,  0.8170+0.0000j, -0.2204+0.0000j,&#10;          0.0000+0.0000j, -0.7238+0.0000j,  0.2963+0.0000j, -0.6324+0.0000j,&#10;          0.3906+0.0000j,  0.7238+0.0000j,  0.0000+0.0000j, -0.6388+0.0000j,&#10;         -1.0943+0.0000j, -0.0679+0.0000j, -0.2963+0.0000j,  0.6388+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1761+0.2072j, -0.7025+0.2061j,  0.1657-0.1432j,&#10;          0.2411+0.3547j, -0.1761-0.2072j,  0.0000+0.0000j,  0.2112+1.3270j,&#10;         -0.1105-0.0274j, -0.4068-0.8474j,  0.7025-0.2061j, -0.2112-1.3270j,&#10;          0.0000+0.0000j, -0.3862-0.5585j, -0.0380-0.6662j, -0.1657+0.1432j,&#10;          0.1105+0.0274j,  0.3862+0.5585j,  0.0000+0.0000j, -0.3012-0.2084j,&#10;         -0.2411-0.3547j,  0.4068+0.8474j,  0.0380+0.6662j,  0.3012+0.2084j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0896-0.1987j, -0.4395+0.1621j,  0.1598-0.0801j,&#10;          0.2966-0.3303j, -0.0896+0.1987j,  0.0000+0.0000j, -0.6612-0.0274j,&#10;          0.2257+0.7551j,  0.4207+0.3394j,  0.4395-0.1621j,  0.6612+0.0274j,&#10;          0.0000+0.0000j, -0.2140-0.0556j,  0.3983-0.0182j, -0.1598+0.0801j,&#10;         -0.2257-0.7551j,  0.2140+0.0556j,  0.0000+0.0000j, -0.1801+0.0342j,&#10;         -0.2966+0.3303j, -0.4207-0.3394j, -0.3983+0.0182j,  0.1801-0.0342j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0344+0.0112j, -0.2364-0.4148j,  0.2169+0.5231j,&#10;         -0.4121-0.0486j,  0.0344-0.0112j,  0.0000+0.0000j,  0.4946-0.8474j,&#10;          0.1715+0.3394j, -0.0998+1.1181j,  0.2364+0.4148j, -0.4946+0.8474j,&#10;          0.0000+0.0000j, -0.2753+0.5461j, -0.0488+0.0207j, -0.2169-0.5231j,&#10;         -0.1715-0.3394j,  0.2753-0.5461j,  0.0000+0.0000j, -0.2468+0.2884j,&#10;          0.4121+0.0486j,  0.0998-1.1181j,  0.0488-0.0207j,  0.2468-0.2884j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0851+0.1758j,  0.1410-0.9872j, -0.0518+0.8004j,&#10;          0.0171+0.0365j,  0.0851-0.1758j,  0.0000+0.0000j,  0.3070-0.2061j,&#10;          0.0558-0.1621j, -0.1567+0.4148j, -0.1410+0.9872j, -0.3070+0.2061j,&#10;          0.0000+0.0000j, -0.2308-0.0876j, -0.2313+0.0565j,  0.0518-0.8004j,&#10;         -0.0558+0.1621j,  0.2308+0.0876j,  0.0000+0.0000j, -0.0200-0.7927j,&#10;         -0.0171-0.0365j,  0.1567-0.4148j,  0.2313-0.0565j,  0.0200+0.7927j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1761-0.2072j, -0.7025-0.2061j,  0.1657+0.1432j,&#10;          0.2411-0.3547j, -0.1761+0.2072j,  0.0000+0.0000j,  0.2112-1.3270j,&#10;         -0.1105+0.0274j, -0.4068+0.8474j,  0.7025+0.2061j, -0.2112+1.3270j,&#10;          0.0000+0.0000j, -0.3862+0.5585j, -0.0380+0.6662j, -0.1657-0.1432j,&#10;          0.1105-0.0274j,  0.3862-0.5585j,  0.0000+0.0000j, -0.3012+0.2084j,&#10;         -0.2411+0.3547j,  0.4068-0.8474j,  0.0380-0.6662j,  0.3012-0.2084j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1287+0.0000j,  0.2091+0.0000j, -0.0087+0.0000j,&#10;         -0.7625+0.0000j, -0.1287+0.0000j,  0.0000+0.0000j,  0.0395+0.0000j,&#10;          0.1336+0.0000j, -0.1239+0.0000j, -0.2091+0.0000j, -0.0395+0.0000j,&#10;          0.0000+0.0000j, -0.1249+0.0000j, -0.1705+0.0000j,  0.0087+0.0000j,&#10;         -0.1336+0.0000j,  0.1249+0.0000j,  0.0000+0.0000j, -0.4104+0.0000j,&#10;          0.7625+0.0000j,  0.1239+0.0000j,  0.1705+0.0000j,  0.4104+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1576-0.2914j,  0.2030+0.0876j,  0.1189+0.0071j,&#10;          0.7009+0.2652j,  0.1576+0.2914j,  0.0000+0.0000j, -0.2758-0.5585j,&#10;         -0.0763-0.0556j,  0.1030+0.5461j, -0.2030-0.0876j,  0.2758+0.5585j,&#10;          0.0000+0.0000j,  0.1026+0.8066j,  0.1142-0.0798j, -0.1189-0.0071j,&#10;          0.0763+0.0556j, -0.1026-0.8066j,  0.0000+0.0000j, -0.0230+0.4656j,&#10;         -0.7009-0.2652j, -0.1030-0.5461j, -0.1142+0.0798j,  0.0230-0.4656j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.3287+0.2398j, -0.1228-0.0565j, -0.3790-0.1930j,&#10;          0.2294-0.1331j, -0.3287-0.2398j,  0.0000+0.0000j, -0.0409-0.6662j,&#10;         -0.0016-0.0182j, -0.3140+0.0207j,  0.1228+0.0565j,  0.0409+0.6662j,&#10;          0.0000+0.0000j, -0.7999-0.0798j,  0.4611+0.5233j,  0.3790+0.1930j,&#10;          0.0016+0.0182j,  0.7999+0.0798j,  0.0000+0.0000j, -0.1129-0.0638j,&#10;         -0.2294+0.1331j,  0.3140-0.0207j, -0.4611-0.5233j,  0.1129+0.0638j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1059-0.0933j,  0.1525+0.8004j, -0.0724-0.5898j,&#10;          0.7461-0.2136j, -0.1059+0.0933j,  0.0000+0.0000j,  0.5610+0.1432j,&#10;         -0.1501+0.0801j, -0.4113-0.5231j, -0.1525-0.8004j, -0.5610-0.1432j,&#10;          0.0000+0.0000j, -0.4900-0.0071j, -0.3849+0.1930j,  0.0724+0.5898j,&#10;          0.1501-0.0801j,  0.4900+0.0071j,  0.0000+0.0000j, -0.2840+0.1462j,&#10;         -0.7461+0.2136j,  0.4113+0.5231j,  0.3849-0.1930j,  0.2840-0.1462j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0896+0.1987j, -0.4395-0.1621j,  0.1598+0.0801j,&#10;          0.2966+0.3303j, -0.0896-0.1987j,  0.0000+0.0000j, -0.6612+0.0274j,&#10;          0.2257-0.7551j,  0.4207-0.3394j,  0.4395+0.1621j,  0.6612-0.0274j,&#10;          0.0000+0.0000j, -0.2140+0.0556j,  0.3983+0.0182j, -0.1598-0.0801j,&#10;         -0.2257+0.7551j,  0.2140-0.0556j,  0.0000+0.0000j, -0.1801-0.0342j,&#10;         -0.2966-0.3303j, -0.4207+0.3394j, -0.3983-0.0182j,  0.1801+0.0342j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1576+0.2914j,  0.2030-0.0876j,  0.1189-0.0071j,&#10;          0.7009-0.2652j,  0.1576-0.2914j,  0.0000+0.0000j, -0.2758+0.5585j,&#10;         -0.0763+0.0556j,  0.1030-0.5461j, -0.2030+0.0876j,  0.2758-0.5585j,&#10;          0.0000+0.0000j,  0.1026-0.8066j,  0.1142+0.0798j, -0.1189+0.0071j,&#10;          0.0763-0.0556j, -0.1026+0.8066j,  0.0000+0.0000j, -0.0230-0.4656j,&#10;         -0.7009+0.2652j, -0.1030+0.5461j, -0.1142-0.0798j,  0.0230+0.4656j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1015+0.0000j, -0.2672+0.0000j, -0.1541+0.0000j,&#10;         -0.1425+0.0000j, -0.1015+0.0000j,  0.0000+0.0000j, -0.6674+0.0000j,&#10;         -0.2280+0.0000j,  0.0422+0.0000j,  0.2672+0.0000j,  0.6674+0.0000j,&#10;          0.0000+0.0000j,  0.2795+0.0000j,  0.4777+0.0000j,  0.1541+0.0000j,&#10;          0.2280+0.0000j, -0.2795+0.0000j,  0.0000+0.0000j,  0.1492+0.0000j,&#10;          0.1425+0.0000j, -0.0422+0.0000j, -0.4777+0.0000j, -0.1492+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1490-0.1880j, -0.3683+0.7927j, -0.1208-0.1462j,&#10;          0.2888+0.2985j,  0.1490+0.1880j,  0.0000+0.0000j,  0.2716-0.2084j,&#10;          0.1436+0.0342j, -0.1761+0.2884j,  0.3683-0.7927j, -0.2716+0.2084j,&#10;          0.0000+0.0000j, -0.1591+0.4656j, -0.3918-0.0638j,  0.1208+0.1462j,&#10;         -0.1436-0.0342j,  0.1591-0.4656j,  0.0000+0.0000j, -0.1538+0.3930j,&#10;         -0.2888-0.2985j,  0.1761-0.2884j,  0.3918+0.0638j,  0.1538-0.3930j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0208+0.0609j, -0.1774+0.0365j,  0.0535-0.2136j,&#10;         -0.2156-1.1209j, -0.0208-0.0609j,  0.0000+0.0000j,  0.0985-0.3547j,&#10;         -0.0599+0.3303j,  0.0820+0.0486j,  0.1774-0.0365j, -0.0985+0.3547j,&#10;          0.0000+0.0000j, -0.0343-0.2652j, -0.0822+0.1331j, -0.0535+0.2136j,&#10;          0.0599-0.3303j,  0.0343+0.2652j,  0.0000+0.0000j, -0.2798-0.2985j,&#10;          0.2156+1.1209j, -0.0820-0.0486j,  0.0822-0.1331j,  0.2798+0.2985j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0344-0.0112j, -0.2364+0.4148j,  0.2169-0.5231j,&#10;         -0.4121+0.0486j,  0.0344+0.0112j,  0.0000+0.0000j,  0.4946+0.8474j,&#10;          0.1715-0.3394j, -0.0998-1.1181j,  0.2364-0.4148j, -0.4946-0.8474j,&#10;          0.0000+0.0000j, -0.2753-0.5461j, -0.0488-0.0207j, -0.2169+0.5231j,&#10;         -0.1715+0.3394j,  0.2753+0.5461j,  0.0000+0.0000j, -0.2468-0.2884j,&#10;          0.4121-0.0486j,  0.0998+1.1181j,  0.0488+0.0207j,  0.2468+0.2884j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.3287-0.2398j, -0.1228+0.0565j, -0.3790+0.1930j,&#10;          0.2294+0.1331j, -0.3287+0.2398j,  0.0000+0.0000j, -0.0409+0.6662j,&#10;         -0.0016+0.0182j, -0.3140-0.0207j,  0.1228-0.0565j,  0.0409-0.6662j,&#10;          0.0000+0.0000j, -0.7999+0.0798j,  0.4611-0.5233j,  0.3790-0.1930j,&#10;          0.0016-0.0182j,  0.7999-0.0798j,  0.0000+0.0000j, -0.1129+0.0638j,&#10;         -0.2294-0.1331j,  0.3140+0.0207j, -0.4611+0.5233j,  0.1129-0.0638j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1490+0.1880j, -0.3683-0.7927j, -0.1208+0.1462j,&#10;          0.2888-0.2985j,  0.1490-0.1880j,  0.0000+0.0000j,  0.2716+0.2084j,&#10;          0.1436-0.0342j, -0.1761-0.2884j,  0.3683+0.7927j, -0.2716-0.2084j,&#10;          0.0000+0.0000j, -0.1591-0.4656j, -0.3918+0.0638j,  0.1208-0.1462j,&#10;         -0.1436+0.0342j,  0.1591+0.4656j,  0.0000+0.0000j, -0.1538-0.3930j,&#10;         -0.2888+0.2985j,  0.1761+0.2884j,  0.3918-0.0638j,  0.1538+0.3930j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0832+0.0000j,  0.8234+0.0000j, -0.6759+0.0000j,&#10;         -0.2339+0.0000j,  0.0832+0.0000j,  0.0000+0.0000j,  0.1872+0.0000j,&#10;          0.4479+0.0000j, -0.3261+0.0000j, -0.8234+0.0000j, -0.1872+0.0000j,&#10;          0.0000+0.0000j, -0.2157+0.0000j, -0.2312+0.0000j,  0.6759+0.0000j,&#10;         -0.4479+0.0000j,  0.2157+0.0000j,  0.0000+0.0000j,  0.7907+0.0000j,&#10;          0.2339+0.0000j,  0.3261+0.0000j,  0.2312+0.0000j, -0.7907+0.0000j,&#10;          0.0000+0.0000j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 0.7211925957066757.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 60, in test_fn_gradgrad
    self._check_helper(device, dtype, op, op.get_op(), 'bwgrad_bwgrad')
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4366, in _check_helper
    self.assertTrue(gradgradcheck(fn, gradcheck_args, **kwargs))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3916, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1710, in gradgradcheck
    return gradcheck(
           ^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.0115-0.1075j, dtype=torch.complex128)
analytical:tensor(0.0124-0.1269j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000e+00+0.0000j, -7.1226e-01+0.0000j,  2.4589e-01+0.0000j,
          3.6800e-01+0.0000j,  3.4854e-01+0.0000j,  7.1226e-01+0.0000j,
          0.0000e+00+0.0000j,  7.0839e-01+0.0000j,  7.9111e-02+0.0000j,
          4.0520e-01+0.0000j, -2.4589e-01+0.0000j, -7.0839e-01+0.0000j,
          0.0000e+00+0.0000j,  7.5657e-01+0.0000j, -9.5455e-01+0.0000j,
         -3.6800e-01+0.0000j, -7.9111e-02+0.0000j, -7.5657e-01+0.0000j,
          0.0000e+00+0.0000j,  2.8989e-01+0.0000j, -3.4854e-01+0.0000j,
         -4.0520e-01+0.0000j,  9.5455e-01+0.0000j, -2.8989e-01+0.0000j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  1.0869e-01+0.2561j, -3.8554e-02-0.0908j,
         -3.5149e-01+0.0184j, -5.1345e-01-0.1842j, -1.0869e-01-0.2561j,
          0.0000e+00+0.0000j,  9.0877e-01+0.1879j, -2.4202e-01-0.3719j,
         -1.1362e+00-0.1333j,  3.8554e-02+0.0908j, -9.0877e-01-0.1879j,
          0.0000e+00+0.0000j, -4.7893e-01-0.2942j, -2.0201e-01+0.3563j,
          3.5149e-01-0.0184j,  2.4202e-01+0.3719j,  4.7893e-01+0.2942j,
          0.0000e+00+0.0000j, -3.5597e-01-0.2674j,  5.1345e-01+0.1842j,
          1.1362e+00+0.1333j,  2.0201e-01-0.3563j,  3.5597e-01+0.2674j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -1.7358e-01-0.1077j,  2.3354e-01+0.7498j,
          4.9344e-02-0.5707j,  4.4840e-01+0.0610j,  1.7358e-01+0.1077j,
          0.0000e+00+0.0000j,  2.5316e-03+0.4555j, -3.0866e-01+0.1302j,
          8.2809e-02-0.3759j, -2.3354e-01-0.7498j, -2.5316e-03-0.4555j,
          0.0000e+00+0.0000j,  4.4704e-01-0.1302j, -3.3332e-01-0.2510j,
         -4.9344e-02+0.5707j,  3.0866e-01-0.1302j, -4.4704e-01+0.1302j,
          0.0000e+00+0.0000j,  2.6715e-01+0.6974j, -4.4840e-01-0.0610j,
         -8.2809e-02+0.3759j,  3.3332e-01+0.2510j, -2.6715e-01-0.6974j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  8.7642e-03+0.1118j,  4.1815e-01-0.5426j,
         -2.4345e-01+0.2043j,  6.7430e-01-0.1604j, -8.7642e-03-0.1118j,
          0.0000e+00+0.0000j,  4.5254e-01-0.2063j, -5.9325e-02+0.1426j,
         -3.5987e-01+0.2819j, -4.1815e-01+0.5426j, -4.5254e-01+0.2063j,
          0.0000e+00+0.0000j, -2.7441e-01-0.1932j, -4.6470e-01+0.0746j,
          2.4345e-01-0.2043j,  5.9325e-02-0.1426j,  2.7441e-01+0.1932j,
          0.0000e+00+0.0000j,  1.1504e-02-0.1257j, -6.7430e-01+0.1604j,
          3.5987e-01-0.2819j,  4.6470e-01-0.0746j, -1.1504e-02+0.1257j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -7.9431e-03-0.1224j, -5.4347e-02+0.5528j,
          8.6071e-03-0.2130j, -8.9172e-02+0.9089j,  7.9431e-03+0.1224j,
          0.0000e+00+0.0000j, -8.6594e-02+0.4329j, -2.2028e-01+0.0403j,
          1.0871e-01-0.2081j,  5.4347e-02-0.5528j,  8.6594e-02-0.4329j,
          0.0000e+00+0.0000j,  2.2963e-01+0.2006j,  3.1705e-02-0.1717j,
         -8.6071e-03+0.2130j,  2.2028e-01-0.0403j, -2.2963e-01-0.2006j,
          0.0000e+00+0.0000j, -1.4030e-01+0.5119j,  8.9172e-02-0.9089j,
         -1.0871e-01+0.2081j, -3.1705e-02+0.1717j,  1.4030e-01-0.5119j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  1.0869e-01-0.2561j, -3.8554e-02+0.0908j,
         -3.5149e-01-0.0184j, -5.1345e-01+0.1842j, -1.0869e-01+0.2561j,
          0.0000e+00+0.0000j,  9.0877e-01-0.1879j, -2.4202e-01+0.3719j,
         -1.1362e+00+0.1333j,  3.8554e-02-0.0908j, -9.0877e-01+0.1879j,
          0.0000e+00+0.0000j, -4.7893e-01+0.2942j, -2.0201e-01-0.3563j,
          3.5149e-01+0.0184j,  2.4202e-01-0.3719j,  4.7893e-01-0.2942j,
          0.0000e+00+0.0000j, -3.5597e-01+0.2674j,  5.1345e-01-0.1842j,
          1.1362e+00-0.1333j,  2.0201e-01+0.3563j,  3.5597e-01-0.2674j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  4.3787e-01+0.0000j, -5.6031e-01+0.0000j,
          4.7696e-01+0.0000j,  8.9543e-01+0.0000j, -4.3787e-01+0.0000j,
          0.0000e+00+0.0000j,  3.8488e-01+0.0000j, -2.6797e-01+0.0000j,
          2.6285e-04+0.0000j,  5.6031e-01+0.0000j, -3.8488e-01+0.0000j,
          0.0000e+00+0.0000j, -5.5111e-01+0.0000j,  8.3811e-02+0.0000j,
         -4.7696e-01+0.0000j,  2.6797e-01+0.0000j,  5.5111e-01+0.0000j,
          0.0000e+00+0.0000j, -4.2137e-01+0.0000j, -8.9543e-01+0.0000j,
         -2.6285e-04+0.0000j, -8.3811e-02+0.0000j,  4.2137e-01+0.0000j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  1.8585e-01+0.0671j, -5.0752e-01+0.4102j,
          5.5556e-02-0.2735j,  5.4867e-02+0.1938j, -1.8585e-01-0.0671j,
          0.0000e+00+0.0000j,  3.8148e-01+1.1253j,  6.6871e-02+0.1283j,
         -5.5128e-01-0.7456j,  5.0752e-01-0.4102j, -3.8148e-01-1.1253j,
          0.0000e+00+0.0000j, -7.4090e-01-0.3885j, -1.8312e-02-0.6672j,
         -5.5556e-02+0.2735j, -6.6871e-02-0.1283j,  7.4090e-01+0.3885j,
          0.0000e+00+0.0000j, -3.8636e-01-0.0151j, -5.4867e-02-0.1938j,
          5.5128e-01+0.7456j,  1.8312e-02+0.6672j,  3.8636e-01+0.0151j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  9.0679e-02-0.1659j, -5.6424e-01-0.0944j,
          1.8538e-01+0.1594j,  4.4636e-01-0.1457j, -9.0679e-02+0.1659j,
          0.0000e+00+0.0000j, -9.6206e-01+0.0327j,  1.9160e-01+0.6947j,
          5.8056e-01+0.4512j,  5.6424e-01+0.0944j,  9.6206e-01-0.0327j,
          0.0000e+00+0.0000j, -2.4625e-03-0.0769j,  5.2800e-01-0.0966j,
         -1.8538e-01-0.1594j, -1.9160e-01-0.6947j,  2.4625e-03+0.0769j,
          0.0000e+00+0.0000j, -1.1122e-01-0.0906j, -4.4636e-01+0.1457j,
         -5.8056e-01-0.4512j, -5.2800e-01+0.0966j,  1.1122e-01+0.0906j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -8.5819e-02+0.0636j, -3.5467e-01-0.1391j,
          2.4364e-01+0.2940j, -4.6922e-01-0.1364j,  8.5819e-02-0.0636j,
          0.0000e+00+0.0000j,  3.1598e-01-0.5765j,  1.8676e-01+0.3850j,
         -1.8591e-02+0.8108j,  3.5467e-01+0.1391j, -3.1598e-01+0.5765j,
          0.0000e+00+0.0000j, -1.2543e-01+0.3942j,  4.9580e-02+0.0459j,
         -2.4364e-01-0.2940j, -1.8676e-01-0.3850j,  1.2543e-01-0.3942j,
          0.0000e+00+0.0000j, -2.6446e-01+0.2122j,  4.6922e-01+0.1364j,
          1.8591e-02-0.8108j, -4.9580e-02-0.0459j,  2.6446e-01-0.2122j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -1.7358e-01+0.1077j,  2.3354e-01-0.7498j,
          4.9344e-02+0.5707j,  4.4840e-01-0.0610j,  1.7358e-01-0.1077j,
          0.0000e+00+0.0000j,  2.5316e-03-0.4555j, -3.0866e-01-0.1302j,
          8.2809e-02+0.3759j, -2.3354e-01+0.7498j, -2.5316e-03+0.4555j,
          0.0000e+00+0.0000j,  4.4704e-01+0.1302j, -3.3332e-01+0.2510j,
         -4.9344e-02-0.5707j,  3.0866e-01+0.1302j, -4.4704e-01-0.1302j,
          0.0000e+00+0.0000j,  2.6715e-01-0.6974j, -4.4840e-01+0.0610j,
         -8.2809e-02-0.3759j,  3.3332e-01-0.2510j, -2.6715e-01+0.6974j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  1.8585e-01-0.0671j, -5.0752e-01-0.4102j,
          5.5556e-02+0.2735j,  5.4867e-02-0.1938j, -1.8585e-01+0.0671j,
          0.0000e+00+0.0000j,  3.8148e-01-1.1253j,  6.6871e-02-0.1283j,
         -5.5128e-01+0.7456j,  5.0752e-01+0.4102j, -3.8148e-01+1.1253j,
          0.0000e+00+0.0000j, -7.4090e-01+0.3885j, -1.8312e-02+0.6672j,
         -5.5556e-02-0.2735j, -6.6871e-02+0.1283j,  7.4090e-01-0.3885j,
          0.0000e+00+0.0000j, -3.8636e-01+0.0151j, -5.4867e-02+0.1938j,
          5.5128e-01-0.7456j,  1.8312e-02-0.6672j,  3.8636e-01-0.0151j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  1.2438e-01+0.0000j, -1.6087e-01+0.0000j,
          2.3567e-01+0.0000j, -3.1640e-01+0.0000j, -1.2438e-01+0.0000j,
          0.0000e+00+0.0000j, -5.6624e-01+0.0000j, -4.4461e-01+0.0000j,
          2.0946e-01+0.0000j,  1.6087e-01+0.0000j,  5.6624e-01+0.0000j,
          0.0000e+00+0.0000j,  5.9633e-01+0.0000j, -4.5737e-04+0.0000j,
         -2.3567e-01+0.0000j,  4.4461e-01+0.0000j, -5.9633e-01+0.0000j,
          0.0000e+00+0.0000j, -2.2567e-01+0.0000j,  3.1640e-01+0.0000j,
         -2.0946e-01+0.0000j,  4.5737e-04+0.0000j,  2.2567e-01+0.0000j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -1.6095e-01-0.2022j,  2.3559e-01+0.2953j,
          1.0270e-01-0.2563j,  8.7586e-01-0.0193j,  1.6095e-01+0.2022j,
          0.0000e+00+0.0000j, -4.5378e-01-0.2702j, -7.4534e-02+0.2510j,
          2.1869e-01+0.2406j, -2.3559e-01-0.2953j,  4.5378e-01+0.2702j,
          0.0000e+00+0.0000j,  2.6357e-01+0.3174j,  1.4364e-01+0.0198j,
         -1.0270e-01+0.2563j,  7.4534e-02-0.2510j, -2.6357e-01-0.3174j,
          0.0000e+00+0.0000j,  8.8921e-02+0.3504j, -8.7586e-01+0.0193j,
         -2.1869e-01-0.2406j, -1.4364e-01-0.0198j, -8.8921e-02-0.3504j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  3.2603e-01+0.2918j, -3.5033e-01-0.3286j,
         -3.0910e-01+0.0639j,  1.8119e-01-0.0163j, -3.2603e-01-0.2918j,
          0.0000e+00+0.0000j, -1.2339e-01-0.5714j,  9.3348e-02-0.3064j,
         -3.0925e-01+0.0170j,  3.5033e-01+0.3286j,  1.2339e-01+0.5714j,
          0.0000e+00+0.0000j, -9.8406e-01-0.0749j,  6.3443e-01+0.5525j,
          3.0910e-01-0.0639j, -9.3348e-02+0.3064j,  9.8406e-01+0.0749j,
          0.0000e+00+0.0000j, -3.3377e-01-0.2349j, -1.8119e-01+0.0163j,
          3.0925e-01-0.0170j, -6.3443e-01-0.5525j,  3.3377e-01+0.2349j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  8.7642e-03-0.1118j,  4.1815e-01+0.5426j,
         -2.4345e-01-0.2043j,  6.7430e-01+0.1604j, -8.7642e-03+0.1118j,
          0.0000e+00+0.0000j,  4.5254e-01+0.2063j, -5.9325e-02-0.1426j,
         -3.5987e-01-0.2819j, -4.1815e-01-0.5426j, -4.5254e-01-0.2063j,
          0.0000e+00+0.0000j, -2.7441e-01+0.1932j, -4.6470e-01-0.0746j,
          2.4345e-01+0.2043j,  5.9325e-02+0.1426j,  2.7441e-01-0.1932j,
          0.0000e+00+0.0000j,  1.1504e-02+0.1257j, -6.7430e-01-0.1604j,
          3.5987e-01+0.2819j,  4.6470e-01+0.0746j, -1.1504e-02-0.1257j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  9.0679e-02+0.1659j, -5.6424e-01+0.0944j,
          1.8538e-01-0.1594j,  4.4636e-01+0.1457j, -9.0679e-02-0.1659j,
          0.0000e+00+0.0000j, -9.6206e-01-0.0327j,  1.9160e-01-0.6947j,
          5.8056e-01-0.4512j,  5.6424e-01-0.0944j,  9.6206e-01+0.0327j,
          0.0000e+00+0.0000j, -2.4625e-03+0.0769j,  5.2800e-01+0.0966j,
         -1.8538e-01+0.1594j, -1.9160e-01+0.6947j,  2.4625e-03-0.0769j,
          0.0000e+00+0.0000j, -1.1122e-01+0.0906j, -4.4636e-01-0.1457j,
         -5.8056e-01+0.4512j, -5.2800e-01-0.0966j,  1.1122e-01-0.0906j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -1.6095e-01+0.2022j,  2.3559e-01-0.2953j,
          1.0270e-01+0.2563j,  8.7586e-01+0.0193j,  1.6095e-01-0.2022j,
          0.0000e+00+0.0000j, -4.5378e-01+0.2702j, -7.4534e-02-0.2510j,
          2.1869e-01-0.2406j, -2.3559e-01+0.2953j,  4.5378e-01-0.2702j,
          0.0000e+00+0.0000j,  2.6357e-01-0.3174j,  1.4364e-01-0.0198j,
         -1.0270e-01-0.2563j,  7.4534e-02+0.2510j, -2.6357e-01+0.3174j,
          0.0000e+00+0.0000j,  8.8921e-02-0.3504j, -8.7586e-01-0.0193j,
         -2.1869e-01+0.2406j, -1.4364e-01+0.0198j, -8.8921e-02+0.3504j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  1.8985e-01+0.0000j, -5.5124e-01+0.0000j,
          7.4477e-02+0.0000j, -1.5041e-01+0.0000j, -1.8985e-01+0.0000j,
          0.0000e+00+0.0000j, -4.7381e-01+0.0000j, -4.7300e-02+0.0000j,
          4.1332e-02+0.0000j,  5.5124e-01+0.0000j,  4.7381e-01+0.0000j,
          0.0000e+00+0.0000j, -2.5455e-01+0.0000j,  5.5287e-01+0.0000j,
         -7.4477e-02+0.0000j,  4.7300e-02+0.0000j,  2.5455e-01+0.0000j,
          0.0000e+00+0.0000j, -2.2317e-01+0.0000j,  1.5041e-01+0.0000j,
         -4.1332e-02+0.0000j, -5.5287e-01+0.0000j,  2.2317e-01+0.0000j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -1.6308e-01-0.1190j, -1.0400e-01+0.5329j,
         -3.1336e-01-0.0128j, -1.8766e-02+0.1645j,  1.6308e-01+0.1190j,
          0.0000e+00+0.0000j,  5.7516e-01+0.0517j,  6.2042e-01+0.0069j,
         -3.4424e-01+0.3667j,  1.0400e-01-0.5329j, -5.7516e-01-0.0517j,
          0.0000e+00+0.0000j, -6.5697e-01+0.5530j, -4.2617e-01-0.3952j,
          3.1336e-01+0.0128j, -6.2042e-01-0.0069j,  6.5697e-01-0.5530j,
          0.0000e+00+0.0000j, -2.2768e-01+0.5651j,  1.8766e-02-0.1645j,
          3.4424e-01-0.3667j,  4.2617e-01+0.3952j,  2.2768e-01-0.5651j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -7.9431e-03+0.1224j, -5.4347e-02-0.5528j,
          8.6071e-03+0.2130j, -8.9172e-02-0.9089j,  7.9431e-03-0.1224j,
          0.0000e+00+0.0000j, -8.6594e-02-0.4329j, -2.2028e-01-0.0403j,
          1.0871e-01+0.2081j,  5.4347e-02+0.5528j,  8.6594e-02+0.4329j,
          0.0000e+00+0.0000j,  2.2963e-01-0.2006j,  3.1705e-02+0.1717j,
         -8.6071e-03-0.2130j,  2.2028e-01+0.0403j, -2.2963e-01+0.2006j,
          0.0000e+00+0.0000j, -1.4030e-01-0.5119j,  8.9172e-02+0.9089j,
         -1.0871e-01-0.2081j, -3.1705e-02-0.1717j,  1.4030e-01+0.5119j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -8.5819e-02-0.0636j, -3.5467e-01+0.1391j,
          2.4364e-01-0.2940j, -4.6922e-01+0.1364j,  8.5819e-02+0.0636j,
          0.0000e+00+0.0000j,  3.1598e-01+0.5765j,  1.8676e-01-0.3850j,
         -1.8591e-02-0.8108j,  3.5467e-01-0.1391j, -3.1598e-01-0.5765j,
          0.0000e+00+0.0000j, -1.2543e-01-0.3942j,  4.9580e-02-0.0459j,
         -2.4364e-01+0.2940j, -1.8676e-01+0.3850j,  1.2543e-01+0.3942j,
          0.0000e+00+0.0000j, -2.6446e-01-0.2122j,  4.6922e-01-0.1364j,
          1.8591e-02+0.8108j, -4.9580e-02+0.0459j,  2.6446e-01+0.2122j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j,  3.2603e-01-0.2918j, -3.5033e-01+0.3286j,
         -3.0910e-01-0.0639j,  1.8119e-01+0.0163j, -3.2603e-01+0.2918j,
          0.0000e+00+0.0000j, -1.2339e-01+0.5714j,  9.3348e-02+0.3064j,
         -3.0925e-01-0.0170j,  3.5033e-01-0.3286j,  1.2339e-01-0.5714j,
          0.0000e+00+0.0000j, -9.8406e-01+0.0749j,  6.3443e-01-0.5525j,
          3.0910e-01+0.0639j, -9.3348e-02-0.3064j,  9.8406e-01-0.0749j,
          0.0000e+00+0.0000j, -3.3377e-01+0.2349j, -1.8119e-01-0.0163j,
          3.0925e-01+0.0170j, -6.3443e-01+0.5525j,  3.3377e-01-0.2349j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -1.6308e-01+0.1190j, -1.0400e-01-0.5329j,
         -3.1336e-01+0.0128j, -1.8766e-02-0.1645j,  1.6308e-01-0.1190j,
          0.0000e+00+0.0000j,  5.7516e-01-0.0517j,  6.2042e-01-0.0069j,
         -3.4424e-01-0.3667j,  1.0400e-01+0.5329j, -5.7516e-01+0.0517j,
          0.0000e+00+0.0000j, -6.5697e-01-0.5530j, -4.2617e-01+0.3952j,
          3.1336e-01-0.0128j, -6.2042e-01+0.0069j,  6.5697e-01+0.5530j,
          0.0000e+00+0.0000j, -2.2768e-01-0.5651j,  1.8766e-02+0.1645j,
          3.4424e-01+0.3667j,  4.2617e-01-0.3952j,  2.2768e-01+0.5651j,
          0.0000e+00+0.0000j],
        [ 0.0000e+00+0.0000j, -8.3241e-02+0.0000j,  8.2337e-01+0.0000j,
         -6.7595e-01+0.0000j, -2.3385e-01+0.0000j,  8.3241e-02+0.0000j,
          0.0000e+00+0.0000j,  1.8722e-01+0.0000j,  4.4786e-01+0.0000j,
         -3.2609e-01+0.0000j, -8.2337e-01+0.0000j, -1.8722e-01+0.0000j,
          0.0000e+00+0.0000j, -2.1573e-01+0.0000j, -2.3123e-01+0.0000j,
          6.7595e-01+0.0000j, -4.4786e-01+0.0000j,  2.1573e-01+0.0000j,
          0.0000e+00+0.0000j,  7.9066e-01+0.0000j,  2.3385e-01+0.0000j,
          3.2609e-01+0.0000j,  2.3123e-01+0.0000j, -7.9066e-01+0.0000j,
          0.0000e+00+0.0000j]], dtype=torch.complex128)
Analytical:
tensor([[ 0.0000+0.0000j, -0.6972+0.0000j,  0.0517+0.0000j,  0.2064+0.0000j,
          0.0446+0.0000j,  0.6972+0.0000j,  0.0000+0.0000j,  0.2202+0.0000j,
          0.0372+0.0000j,  0.3398+0.0000j, -0.0517+0.0000j, -0.2202+0.0000j,
          0.0000+0.0000j,  0.7849+0.0000j, -0.3722+0.0000j, -0.2064+0.0000j,
         -0.0372+0.0000j, -0.7849+0.0000j,  0.0000+0.0000j,  0.1094+0.0000j,
         -0.0446+0.0000j, -0.3398+0.0000j,  0.3722+0.0000j, -0.1094+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1825+0.2558j, -0.1405-0.1758j, -0.2023+0.0933j,
         -0.1846-0.0609j, -0.1825-0.2558j,  0.0000+0.0000j,  1.0480+0.2072j,
         -0.4395-0.1987j, -1.1272+0.0112j,  0.1405+0.1758j, -1.0480-0.2072j,
          0.0000+0.0000j, -0.3464-0.2914j, -0.3153+0.2398j,  0.2023-0.0933j,
          0.4395+0.1987j,  0.3464+0.2914j,  0.0000+0.0000j, -0.3796-0.1880j,
          0.1846+0.0609j,  1.1272-0.0112j,  0.3153-0.2398j,  0.3796+0.1880j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0851-0.1758j,  0.1410+0.9872j, -0.0518-0.8004j,
          0.0171-0.0365j,  0.0851+0.1758j,  0.0000+0.0000j,  0.3070+0.2061j,
          0.0558+0.1621j, -0.1567-0.4148j, -0.1410-0.9872j, -0.3070-0.2061j,
          0.0000+0.0000j, -0.2308+0.0876j, -0.2313-0.0565j,  0.0518+0.8004j,
         -0.0558-0.1621j,  0.2308-0.0876j,  0.0000+0.0000j, -0.0200+0.7927j,
         -0.0171+0.0365j,  0.1567+0.4148j,  0.2313+0.0565j,  0.0200-0.7927j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1059+0.0933j,  0.1525-0.8004j, -0.0724+0.5898j,
          0.7461+0.2136j, -0.1059-0.0933j,  0.0000+0.0000j,  0.5610-0.1432j,
         -0.1501-0.0801j, -0.4113+0.5231j, -0.1525+0.8004j, -0.5610+0.1432j,
          0.0000+0.0000j, -0.4900+0.0071j, -0.3849-0.1930j,  0.0724-0.5898j,
          0.1501+0.0801j,  0.4900-0.0071j,  0.0000+0.0000j, -0.2840-0.1462j,
         -0.7461-0.2136j,  0.4113-0.5231j,  0.3849+0.1930j,  0.2840+0.1462j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0208-0.0609j, -0.1774-0.0365j,  0.0535+0.2136j,
         -0.2156+1.1209j, -0.0208+0.0609j,  0.0000+0.0000j,  0.0985+0.3547j,
         -0.0599-0.3303j,  0.0820-0.0486j,  0.1774+0.0365j, -0.0985-0.3547j,
          0.0000+0.0000j, -0.0343+0.2652j, -0.0822-0.1331j, -0.0535-0.2136j,
          0.0599+0.3303j,  0.0343-0.2652j,  0.0000+0.0000j, -0.2798+0.2985j,
          0.2156-1.1209j, -0.0820+0.0486j,  0.0822+0.1331j,  0.2798-0.2985j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1825-0.2558j, -0.1405+0.1758j, -0.2023-0.0933j,
         -0.1846+0.0609j, -0.1825+0.2558j,  0.0000+0.0000j,  1.0480-0.2072j,
         -0.4395+0.1987j, -1.1272-0.0112j,  0.1405-0.1758j, -1.0480+0.2072j,
          0.0000+0.0000j, -0.3464+0.2914j, -0.3153-0.2398j,  0.2023+0.0933j,
          0.4395-0.1987j,  0.3464-0.2914j,  0.0000+0.0000j, -0.3796+0.1880j,
          0.1846-0.0609j,  1.1272+0.0112j,  0.3153+0.2398j,  0.3796-0.1880j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.5503+0.0000j, -0.8170+0.0000j,  0.6324+0.0000j,
          1.0943+0.0000j, -0.5503+0.0000j,  0.0000+0.0000j,  0.2204+0.0000j,
         -0.3906+0.0000j,  0.0679+0.0000j,  0.8170+0.0000j, -0.2204+0.0000j,
          0.0000+0.0000j, -0.7238+0.0000j,  0.2963+0.0000j, -0.6324+0.0000j,
          0.3906+0.0000j,  0.7238+0.0000j,  0.0000+0.0000j, -0.6388+0.0000j,
         -1.0943+0.0000j, -0.0679+0.0000j, -0.2963+0.0000j,  0.6388+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1761+0.2072j, -0.7025+0.2061j,  0.1657-0.1432j,
          0.2411+0.3547j, -0.1761-0.2072j,  0.0000+0.0000j,  0.2112+1.3270j,
         -0.1105-0.0274j, -0.4068-0.8474j,  0.7025-0.2061j, -0.2112-1.3270j,
          0.0000+0.0000j, -0.3862-0.5585j, -0.0380-0.6662j, -0.1657+0.1432j,
          0.1105+0.0274j,  0.3862+0.5585j,  0.0000+0.0000j, -0.3012-0.2084j,
         -0.2411-0.3547j,  0.4068+0.8474j,  0.0380+0.6662j,  0.3012+0.2084j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0896-0.1987j, -0.4395+0.1621j,  0.1598-0.0801j,
          0.2966-0.3303j, -0.0896+0.1987j,  0.0000+0.0000j, -0.6612-0.0274j,
          0.2257+0.7551j,  0.4207+0.3394j,  0.4395-0.1621j,  0.6612+0.0274j,
          0.0000+0.0000j, -0.2140-0.0556j,  0.3983-0.0182j, -0.1598+0.0801j,
         -0.2257-0.7551j,  0.2140+0.0556j,  0.0000+0.0000j, -0.1801+0.0342j,
         -0.2966+0.3303j, -0.4207-0.3394j, -0.3983+0.0182j,  0.1801-0.0342j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0344+0.0112j, -0.2364-0.4148j,  0.2169+0.5231j,
         -0.4121-0.0486j,  0.0344-0.0112j,  0.0000+0.0000j,  0.4946-0.8474j,
          0.1715+0.3394j, -0.0998+1.1181j,  0.2364+0.4148j, -0.4946+0.8474j,
          0.0000+0.0000j, -0.2753+0.5461j, -0.0488+0.0207j, -0.2169-0.5231j,
         -0.1715-0.3394j,  0.2753-0.5461j,  0.0000+0.0000j, -0.2468+0.2884j,
          0.4121+0.0486j,  0.0998-1.1181j,  0.0488-0.0207j,  0.2468-0.2884j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0851+0.1758j,  0.1410-0.9872j, -0.0518+0.8004j,
          0.0171+0.0365j,  0.0851-0.1758j,  0.0000+0.0000j,  0.3070-0.2061j,
          0.0558-0.1621j, -0.1567+0.4148j, -0.1410+0.9872j, -0.3070+0.2061j,
          0.0000+0.0000j, -0.2308-0.0876j, -0.2313+0.0565j,  0.0518-0.8004j,
         -0.0558+0.1621j,  0.2308+0.0876j,  0.0000+0.0000j, -0.0200-0.7927j,
         -0.0171-0.0365j,  0.1567-0.4148j,  0.2313-0.0565j,  0.0200+0.7927j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1761-0.2072j, -0.7025-0.2061j,  0.1657+0.1432j,
          0.2411-0.3547j, -0.1761+0.2072j,  0.0000+0.0000j,  0.2112-1.3270j,
         -0.1105+0.0274j, -0.4068+0.8474j,  0.7025+0.2061j, -0.2112+1.3270j,
          0.0000+0.0000j, -0.3862+0.5585j, -0.0380+0.6662j, -0.1657-0.1432j,
          0.1105-0.0274j,  0.3862-0.5585j,  0.0000+0.0000j, -0.3012+0.2084j,
         -0.2411+0.3547j,  0.4068-0.8474j,  0.0380-0.6662j,  0.3012-0.2084j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1287+0.0000j,  0.2091+0.0000j, -0.0087+0.0000j,
         -0.7625+0.0000j, -0.1287+0.0000j,  0.0000+0.0000j,  0.0395+0.0000j,
          0.1336+0.0000j, -0.1239+0.0000j, -0.2091+0.0000j, -0.0395+0.0000j,
          0.0000+0.0000j, -0.1249+0.0000j, -0.1705+0.0000j,  0.0087+0.0000j,
         -0.1336+0.0000j,  0.1249+0.0000j,  0.0000+0.0000j, -0.4104+0.0000j,
          0.7625+0.0000j,  0.1239+0.0000j,  0.1705+0.0000j,  0.4104+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1576-0.2914j,  0.2030+0.0876j,  0.1189+0.0071j,
          0.7009+0.2652j,  0.1576+0.2914j,  0.0000+0.0000j, -0.2758-0.5585j,
         -0.0763-0.0556j,  0.1030+0.5461j, -0.2030-0.0876j,  0.2758+0.5585j,
          0.0000+0.0000j,  0.1026+0.8066j,  0.1142-0.0798j, -0.1189-0.0071j,
          0.0763+0.0556j, -0.1026-0.8066j,  0.0000+0.0000j, -0.0230+0.4656j,
         -0.7009-0.2652j, -0.1030-0.5461j, -0.1142+0.0798j,  0.0230-0.4656j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.3287+0.2398j, -0.1228-0.0565j, -0.3790-0.1930j,
          0.2294-0.1331j, -0.3287-0.2398j,  0.0000+0.0000j, -0.0409-0.6662j,
         -0.0016-0.0182j, -0.3140+0.0207j,  0.1228+0.0565j,  0.0409+0.6662j,
          0.0000+0.0000j, -0.7999-0.0798j,  0.4611+0.5233j,  0.3790+0.1930j,
          0.0016+0.0182j,  0.7999+0.0798j,  0.0000+0.0000j, -0.1129-0.0638j,
         -0.2294+0.1331j,  0.3140-0.0207j, -0.4611-0.5233j,  0.1129+0.0638j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1059-0.0933j,  0.1525+0.8004j, -0.0724-0.5898j,
          0.7461-0.2136j, -0.1059+0.0933j,  0.0000+0.0000j,  0.5610+0.1432j,
         -0.1501+0.0801j, -0.4113-0.5231j, -0.1525-0.8004j, -0.5610-0.1432j,
          0.0000+0.0000j, -0.4900-0.0071j, -0.3849+0.1930j,  0.0724+0.5898j,
          0.1501-0.0801j,  0.4900+0.0071j,  0.0000+0.0000j, -0.2840+0.1462j,
         -0.7461+0.2136j,  0.4113+0.5231j,  0.3849-0.1930j,  0.2840-0.1462j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0896+0.1987j, -0.4395-0.1621j,  0.1598+0.0801j,
          0.2966+0.3303j, -0.0896-0.1987j,  0.0000+0.0000j, -0.6612+0.0274j,
          0.2257-0.7551j,  0.4207-0.3394j,  0.4395+0.1621j,  0.6612-0.0274j,
          0.0000+0.0000j, -0.2140+0.0556j,  0.3983+0.0182j, -0.1598-0.0801j,
         -0.2257+0.7551j,  0.2140-0.0556j,  0.0000+0.0000j, -0.1801-0.0342j,
         -0.2966-0.3303j, -0.4207+0.3394j, -0.3983-0.0182j,  0.1801+0.0342j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1576+0.2914j,  0.2030-0.0876j,  0.1189-0.0071j,
          0.7009-0.2652j,  0.1576-0.2914j,  0.0000+0.0000j, -0.2758+0.5585j,
         -0.0763+0.0556j,  0.1030-0.5461j, -0.2030+0.0876j,  0.2758-0.5585j,
          0.0000+0.0000j,  0.1026-0.8066j,  0.1142+0.0798j, -0.1189+0.0071j,
          0.0763-0.0556j, -0.1026+0.8066j,  0.0000+0.0000j, -0.0230-0.4656j,
         -0.7009+0.2652j, -0.1030+0.5461j, -0.1142-0.0798j,  0.0230+0.4656j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1015+0.0000j, -0.2672+0.0000j, -0.1541+0.0000j,
         -0.1425+0.0000j, -0.1015+0.0000j,  0.0000+0.0000j, -0.6674+0.0000j,
         -0.2280+0.0000j,  0.0422+0.0000j,  0.2672+0.0000j,  0.6674+0.0000j,
          0.0000+0.0000j,  0.2795+0.0000j,  0.4777+0.0000j,  0.1541+0.0000j,
          0.2280+0.0000j, -0.2795+0.0000j,  0.0000+0.0000j,  0.1492+0.0000j,
          0.1425+0.0000j, -0.0422+0.0000j, -0.4777+0.0000j, -0.1492+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1490-0.1880j, -0.3683+0.7927j, -0.1208-0.1462j,
          0.2888+0.2985j,  0.1490+0.1880j,  0.0000+0.0000j,  0.2716-0.2084j,
          0.1436+0.0342j, -0.1761+0.2884j,  0.3683-0.7927j, -0.2716+0.2084j,
          0.0000+0.0000j, -0.1591+0.4656j, -0.3918-0.0638j,  0.1208+0.1462j,
         -0.1436-0.0342j,  0.1591-0.4656j,  0.0000+0.0000j, -0.1538+0.3930j,
         -0.2888-0.2985j,  0.1761-0.2884j,  0.3918+0.0638j,  0.1538-0.3930j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0208+0.0609j, -0.1774+0.0365j,  0.0535-0.2136j,
         -0.2156-1.1209j, -0.0208-0.0609j,  0.0000+0.0000j,  0.0985-0.3547j,
         -0.0599+0.3303j,  0.0820+0.0486j,  0.1774-0.0365j, -0.0985+0.3547j,
          0.0000+0.0000j, -0.0343-0.2652j, -0.0822+0.1331j, -0.0535+0.2136j,
          0.0599-0.3303j,  0.0343+0.2652j,  0.0000+0.0000j, -0.2798-0.2985j,
          0.2156+1.1209j, -0.0820-0.0486j,  0.0822-0.1331j,  0.2798+0.2985j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0344-0.0112j, -0.2364+0.4148j,  0.2169-0.5231j,
         -0.4121+0.0486j,  0.0344+0.0112j,  0.0000+0.0000j,  0.4946+0.8474j,
          0.1715-0.3394j, -0.0998-1.1181j,  0.2364-0.4148j, -0.4946-0.8474j,
          0.0000+0.0000j, -0.2753-0.5461j, -0.0488-0.0207j, -0.2169+0.5231j,
         -0.1715+0.3394j,  0.2753+0.5461j,  0.0000+0.0000j, -0.2468-0.2884j,
          0.4121-0.0486j,  0.0998+1.1181j,  0.0488+0.0207j,  0.2468+0.2884j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.3287-0.2398j, -0.1228+0.0565j, -0.3790+0.1930j,
          0.2294+0.1331j, -0.3287+0.2398j,  0.0000+0.0000j, -0.0409+0.6662j,
         -0.0016+0.0182j, -0.3140-0.0207j,  0.1228-0.0565j,  0.0409-0.6662j,
          0.0000+0.0000j, -0.7999+0.0798j,  0.4611-0.5233j,  0.3790-0.1930j,
          0.0016-0.0182j,  0.7999-0.0798j,  0.0000+0.0000j, -0.1129+0.0638j,
         -0.2294-0.1331j,  0.3140+0.0207j, -0.4611+0.5233j,  0.1129-0.0638j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1490+0.1880j, -0.3683-0.7927j, -0.1208+0.1462j,
          0.2888-0.2985j,  0.1490-0.1880j,  0.0000+0.0000j,  0.2716+0.2084j,
          0.1436-0.0342j, -0.1761-0.2884j,  0.3683+0.7927j, -0.2716-0.2084j,
          0.0000+0.0000j, -0.1591-0.4656j, -0.3918+0.0638j,  0.1208-0.1462j,
         -0.1436+0.0342j,  0.1591+0.4656j,  0.0000+0.0000j, -0.1538-0.3930j,
         -0.2888+0.2985j,  0.1761+0.2884j,  0.3918-0.0638j,  0.1538+0.3930j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0832+0.0000j,  0.8234+0.0000j, -0.6759+0.0000j,
         -0.2339+0.0000j,  0.0832+0.0000j,  0.0000+0.0000j,  0.1872+0.0000j,
          0.4479+0.0000j, -0.3261+0.0000j, -0.8234+0.0000j, -0.1872+0.0000j,
          0.0000+0.0000j, -0.2157+0.0000j, -0.2312+0.0000j,  0.6759+0.0000j,
         -0.4479+0.0000j,  0.2157+0.0000j,  0.0000+0.0000j,  0.7907+0.0000j,
          0.2339+0.0000j,  0.3261+0.0000j,  0.2312+0.0000j, -0.7907+0.0000j,
          0.0000+0.0000j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 0.7211925957066757.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_eigvalsh_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_householder_product_cpu_complex128" time="3.813" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_householder_product_cpu_float64" time="0.635" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_inv_cpu_complex128" time="0.549" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_inv_cpu_float64" time="0.093" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_inv_ex_cpu_complex128" time="0.524" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_inv_ex_cpu_float64" time="0.091" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_ldl_factor_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_ldl_factor_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_ldl_factor_ex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_ldl_factor_ex_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_ldl_solve_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_ldl_solve_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lstsq_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lstsq_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lstsq_grad_oriented_cpu_complex128" time="8.411" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lstsq_grad_oriented_cpu_float64" time="2.108" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lu_cpu_float64" time="0.435" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lu_factor_cpu_float64" time="0.522" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lu_factor_ex_cpu_float64" time="0.428" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_lu_solve_cpu_float64" time="6.275" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_norm_cpu_complex128" time="2.691" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_norm_cpu_float64" time="0.577" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_power_cpu_complex128" time="1.397" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_power_cpu_float64" time="0.254" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_rank_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_rank_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_rank_hermitian_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_matrix_rank_hermitian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_multi_dot_cpu_complex128" time="0.963" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_multi_dot_cpu_float64" time="0.187" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_norm_cpu_complex128" time="0.604" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_norm_cpu_float64" time="0.273" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_norm_subgradients_at_zero_cpu_complex128" time="0.022" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_norm_subgradients_at_zero_cpu_float64" time="0.012" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_pinv_cpu_complex128" time="2.220" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_pinv_cpu_float64" time="0.382" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_pinv_hermitian_cpu_complex128" time="0.200" file="test_ops_gradients.py">
      <failure message="torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,&#10;numerical:tensor(-0.2966-0.2039j, dtype=torch.complex128)&#10;analytical:tensor(-0.0156+0.0625j, dtype=torch.complex128)&#10;&#10;The above quantities relating the numerical and analytical jacobians are computed &#10;in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background &#10;about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:&#10;&#10;Numerical:&#10; tensor([[ 0.0000+0.0000j,  0.0218+0.0000j, -0.5424+0.0000j, -0.0634+0.0000j,&#10;          0.1704+0.0000j, -0.0218+0.0000j,  0.0000+0.0000j,  0.1896+0.0000j,&#10;         -0.2152+0.0000j, -0.0375+0.0000j,  0.5424+0.0000j, -0.1896+0.0000j,&#10;          0.0000+0.0000j, -0.0233+0.0000j,  0.5580+0.0000j,  0.0634+0.0000j,&#10;          0.2152+0.0000j,  0.0233+0.0000j,  0.0000+0.0000j, -0.4424+0.0000j,&#10;         -0.1704+0.0000j,  0.0375+0.0000j, -0.5580+0.0000j,  0.4424+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.3792-0.5127j,  0.2345-0.3072j,  0.1949-0.2280j,&#10;         -0.4600-0.1427j,  0.3792+0.5127j,  0.0000+0.0000j,  0.6419+0.9051j,&#10;          0.0233-0.3378j,  0.9996+0.5829j, -0.2345+0.3072j, -0.6419-0.9051j,&#10;          0.0000+0.0000j,  1.2429+0.4169j, -3.0741-1.2672j, -0.1949+0.2280j,&#10;         -0.0233+0.3378j, -1.2429-0.4169j,  0.0000+0.0000j, -0.2619-0.3679j,&#10;          0.4600+0.1427j, -0.9996-0.5829j,  3.0741+1.2672j,  0.2619+0.3679j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.4076-0.3305j, -0.2731+0.4938j,  0.1746-0.0898j,&#10;          0.9136+0.1892j, -0.4076+0.3305j,  0.0000+0.0000j, -1.0547-0.1637j,&#10;         -0.0454-0.0415j, -1.6821-0.8783j,  0.2731-0.4938j,  1.0547+0.1637j,&#10;          0.0000+0.0000j, -1.6927-0.9436j,  4.9008+1.1572j, -0.1746+0.0898j,&#10;          0.0454+0.0415j,  1.6927+0.9436j,  0.0000+0.0000j,  0.6863+0.4367j,&#10;         -0.9136-0.1892j,  1.6821+0.8783j, -4.9008-1.1572j, -0.6863-0.4367j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.2900+0.2770j,  0.7682+0.1182j, -0.0639-0.0576j,&#10;          0.0233-0.3758j,  0.2900-0.2770j,  0.0000+0.0000j,  0.1546-0.0243j,&#10;         -0.0967-0.2483j, -0.1803+0.4475j, -0.7682-0.1182j, -0.1546+0.0243j,&#10;          0.0000+0.0000j,  0.1680+0.0791j, -0.8521-1.5282j,  0.0639+0.0576j,&#10;          0.0967+0.2483j, -0.1680-0.0791j,  0.0000+0.0000j,  0.1871-0.1112j,&#10;         -0.0233+0.3758j,  0.1803-0.4475j,  0.8521+1.5282j, -0.1871+0.1112j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0748-0.1043j, -0.3327-0.3628j, -0.4305-0.4218j,&#10;          0.2067+0.4163j, -0.0748+0.1043j,  0.0000+0.0000j, -0.0989-0.1422j,&#10;         -0.0520+0.0974j, -0.4434-1.2655j,  0.3327+0.3628j,  0.0989+0.1422j,&#10;          0.0000+0.0000j, -0.6953-1.1991j,  1.3390+3.3856j,  0.4305+0.4218j,&#10;          0.0520-0.0974j,  0.6953+1.1991j,  0.0000+0.0000j,  0.0334+0.6044j,&#10;         -0.2067-0.4163j,  0.4434+1.2655j, -1.3390-3.3856j, -0.0334-0.6044j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.3792+0.5127j,  0.2345+0.3072j,  0.1949+0.2280j,&#10;         -0.4600+0.1427j,  0.3792-0.5127j,  0.0000+0.0000j,  0.6419-0.9051j,&#10;          0.0233+0.3378j,  0.9996-0.5829j, -0.2345-0.3072j, -0.6419+0.9051j,&#10;          0.0000+0.0000j,  1.2429-0.4169j, -3.0741+1.2672j, -0.1949-0.2280j,&#10;         -0.0233-0.3378j, -1.2429+0.4169j,  0.0000+0.0000j, -0.2619+0.3679j,&#10;          0.4600-0.1427j, -0.9996+0.5829j,  3.0741-1.2672j,  0.2619-0.3679j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.9318+0.0000j, -0.2639+0.0000j, -0.4408+0.0000j,&#10;         -0.1636+0.0000j,  0.9318+0.0000j,  0.0000+0.0000j,  0.9742+0.0000j,&#10;          0.3994+0.0000j,  0.8002+0.0000j,  0.2639+0.0000j, -0.9742+0.0000j,&#10;          0.0000+0.0000j, -0.1164+0.0000j, -0.8842+0.0000j,  0.4408+0.0000j,&#10;         -0.3994+0.0000j,  0.1164+0.0000j,  0.0000+0.0000j, -0.1214+0.0000j,&#10;          0.1636+0.0000j, -0.8002+0.0000j,  0.8842+0.0000j,  0.1214+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2066-0.2991j, -0.1613-0.0885j, -0.0583-0.2935j,&#10;         -0.0222+0.1244j, -0.2066+0.2991j,  0.0000+0.0000j, -0.1006+0.1508j,&#10;         -0.0864+0.0122j,  0.0228-0.2160j,  0.1613+0.0885j,  0.1006-0.1508j,&#10;          0.0000+0.0000j,  0.2173-0.1370j, -0.3082-0.0439j,  0.0583+0.2935j,&#10;          0.0864-0.0122j, -0.2173+0.1370j,  0.0000+0.0000j, -0.2399-0.2007j,&#10;          0.0222-0.1244j, -0.0228+0.2160j,  0.3082+0.0439j,  0.2399+0.2007j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.4610+0.4147j,  0.0857+0.1520j, -0.0475+0.0705j,&#10;          0.2302+0.0140j, -0.4610-0.4147j,  0.0000+0.0000j, -0.5978-0.2806j,&#10;          0.0812-0.4256j, -0.6959+0.3152j, -0.0857-0.1520j,  0.5978+0.2806j,&#10;          0.0000+0.0000j, -0.6461+0.2464j,  1.7212-0.2187j,  0.0475-0.0705j,&#10;         -0.0812+0.4256j,  0.6461-0.2464j,  0.0000+0.0000j,  0.2985-0.1244j,&#10;         -0.2302-0.0140j,  0.6959-0.3152j, -1.7212+0.2187j, -0.2985+0.1244j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1365+0.6053j, -0.0372-0.1404j, -0.0650-0.0555j,&#10;         -0.3483-0.0103j, -0.1365-0.6053j,  0.0000+0.0000j,  0.6622-0.4553j,&#10;          0.4672+0.1352j,  0.5086-0.0738j,  0.0372+0.1404j, -0.6622+0.4553j,&#10;          0.0000+0.0000j,  0.1409-0.1369j, -0.6648+0.9262j,  0.0650+0.0555j,&#10;         -0.4672-0.1352j, -0.1409+0.1369j,  0.0000+0.0000j,  0.1143-0.1003j,&#10;          0.3483+0.0103j, -0.5086+0.0738j,  0.6648-0.9262j, -0.1143+0.1003j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.4076+0.3305j, -0.2731-0.4938j,  0.1746+0.0898j,&#10;          0.9136-0.1892j, -0.4076-0.3305j,  0.0000+0.0000j, -1.0547+0.1637j,&#10;         -0.0454+0.0415j, -1.6821+0.8783j,  0.2731+0.4938j,  1.0547-0.1637j,&#10;          0.0000+0.0000j, -1.6927+0.9436j,  4.9008-1.1572j, -0.1746-0.0898j,&#10;          0.0454-0.0415j,  1.6927-0.9436j,  0.0000+0.0000j,  0.6863-0.4367j,&#10;         -0.9136+0.1892j,  1.6821-0.8783j, -4.9008+1.1572j, -0.6863+0.4367j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2066+0.2991j, -0.1613+0.0885j, -0.0583+0.2935j,&#10;         -0.0222-0.1244j, -0.2066-0.2991j,  0.0000+0.0000j, -0.1006-0.1508j,&#10;         -0.0864-0.0122j,  0.0228+0.2160j,  0.1613-0.0885j,  0.1006+0.1508j,&#10;          0.0000+0.0000j,  0.2173+0.1370j, -0.3082+0.0439j,  0.0583-0.2935j,&#10;          0.0864+0.0122j, -0.2173-0.1370j,  0.0000+0.0000j, -0.2399+0.2007j,&#10;          0.0222+0.1244j, -0.0228-0.2160j,  0.3082-0.0439j,  0.2399-0.2007j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.3783+0.0000j, -0.2248+0.0000j,  0.0079+0.0000j,&#10;         -0.3962+0.0000j, -0.3783+0.0000j,  0.0000+0.0000j,  0.2228+0.0000j,&#10;         -0.2324+0.0000j,  1.0772+0.0000j,  0.2248+0.0000j, -0.2228+0.0000j,&#10;          0.0000+0.0000j,  1.2074+0.0000j, -2.7149+0.0000j, -0.0079+0.0000j,&#10;          0.2324+0.0000j, -1.2074+0.0000j,  0.0000+0.0000j, -0.5755+0.0000j,&#10;          0.3962+0.0000j, -1.0772+0.0000j,  2.7149+0.0000j,  0.5755+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1325+0.1202j,  0.3061-0.0156j,  0.2719-0.3833j,&#10;          0.4966+0.0173j, -0.1325-0.1202j,  0.0000+0.0000j, -0.5917+0.2027j,&#10;         -0.1171-0.1642j, -1.1098+0.5238j, -0.3061+0.0156j,  0.5917-0.2027j,&#10;          0.0000+0.0000j, -0.3726+0.3966j,  1.8628-1.1994j, -0.2719+0.3833j,&#10;          0.1171+0.1642j,  0.3726-0.3966j,  0.0000+0.0000j, -0.1042-0.3768j,&#10;         -0.4966-0.0173j,  1.1098-0.5238j, -1.8628+1.1994j,  0.1042+0.3768j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1279+0.2039j, -0.1442-0.6080j, -0.1129-0.6585j,&#10;          0.1220+0.1401j,  0.1279-0.2039j,  0.0000+0.0000j,  0.2019+0.0101j,&#10;          0.4833+0.1084j, -0.2998-0.2633j,  0.1442+0.6080j, -0.2019-0.0101j,&#10;          0.0000+0.0000j, -0.6449-0.7359j,  0.2436+1.1920j,  0.1129+0.6585j,&#10;         -0.4833-0.1084j,  0.6449+0.7359j,  0.0000+0.0000j,  0.0299+0.5217j,&#10;         -0.1220-0.1401j,  0.2998+0.2633j, -0.2436-1.1920j, -0.0299-0.5217j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.2900-0.2770j,  0.7682-0.1182j, -0.0639+0.0576j,&#10;          0.0233+0.3758j,  0.2900+0.2770j,  0.0000+0.0000j,  0.1546+0.0243j,&#10;         -0.0967+0.2483j, -0.1803-0.4475j, -0.7682+0.1182j, -0.1546-0.0243j,&#10;          0.0000+0.0000j,  0.1680-0.0791j, -0.8521+1.5282j,  0.0639-0.0576j,&#10;          0.0967-0.2483j, -0.1680+0.0791j,  0.0000+0.0000j,  0.1871+0.1112j,&#10;         -0.0233-0.3758j,  0.1803+0.4475j,  0.8521-1.5282j, -0.1871-0.1112j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.4610-0.4147j,  0.0857-0.1520j, -0.0475-0.0705j,&#10;          0.2302-0.0140j, -0.4610+0.4147j,  0.0000+0.0000j, -0.5978+0.2806j,&#10;          0.0812+0.4256j, -0.6959-0.3152j, -0.0857+0.1520j,  0.5978-0.2806j,&#10;          0.0000+0.0000j, -0.6461-0.2464j,  1.7212+0.2187j,  0.0475+0.0705j,&#10;         -0.0812-0.4256j,  0.6461+0.2464j,  0.0000+0.0000j,  0.2985+0.1244j,&#10;         -0.2302+0.0140j,  0.6959+0.3152j, -1.7212-0.2187j, -0.2985-0.1244j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1325-0.1202j,  0.3061+0.0156j,  0.2719+0.3833j,&#10;          0.4966-0.0173j, -0.1325+0.1202j,  0.0000+0.0000j, -0.5917-0.2027j,&#10;         -0.1171+0.1642j, -1.1098-0.5238j, -0.3061-0.0156j,  0.5917+0.2027j,&#10;          0.0000+0.0000j, -0.3726-0.3966j,  1.8628+1.1994j, -0.2719-0.3833j,&#10;          0.1171-0.1642j,  0.3726+0.3966j,  0.0000+0.0000j, -0.1042+0.3768j,&#10;         -0.4966+0.0173j,  1.1098+0.5238j, -1.8628-1.1994j,  0.1042-0.3768j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.3179+0.0000j,  0.2366+0.0000j,  0.4782+0.0000j,&#10;         -0.4087+0.0000j, -0.3179+0.0000j,  0.0000+0.0000j,  0.1923+0.0000j,&#10;         -0.0584+0.0000j,  1.0768+0.0000j, -0.2366+0.0000j, -0.1923+0.0000j,&#10;          0.0000+0.0000j,  1.8821+0.0000j, -3.0938+0.0000j, -0.4782+0.0000j,&#10;          0.0584+0.0000j, -1.8821+0.0000j,  0.0000+0.0000j, -0.3606+0.0000j,&#10;          0.4087+0.0000j, -1.0768+0.0000j,  3.0938+0.0000j,  0.3606+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0532-0.0399j,  0.3958+0.2996j,  0.4502+0.0828j,&#10;          0.0956+0.1519j, -0.0532+0.0399j,  0.0000+0.0000j, -0.2762+0.0160j,&#10;          0.0916+0.2331j, -0.0592+0.1527j, -0.3958-0.2996j,  0.2762-0.0160j,&#10;          0.0000+0.0000j,  0.2684-0.1900j,  0.0451+0.1141j, -0.4502-0.0828j,&#10;         -0.0916-0.2331j, -0.2684+0.1900j,  0.0000+0.0000j, -0.1223-0.2904j,&#10;         -0.0956-0.1519j,  0.0592-0.1527j, -0.0451-0.1141j,  0.1223+0.2904j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0748+0.1043j, -0.3327+0.3628j, -0.4305+0.4218j,&#10;          0.2067-0.4163j, -0.0748-0.1043j,  0.0000+0.0000j, -0.0989+0.1422j,&#10;         -0.0520-0.0974j, -0.4434+1.2655j,  0.3327-0.3628j,  0.0989-0.1422j,&#10;          0.0000+0.0000j, -0.6953+1.1991j,  1.3390-3.3856j,  0.4305-0.4218j,&#10;          0.0520+0.0974j,  0.6953-1.1991j,  0.0000+0.0000j,  0.0334-0.6044j,&#10;         -0.2067+0.4163j,  0.4434-1.2655j, -1.3390+3.3856j, -0.0334+0.6044j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1365-0.6053j, -0.0372+0.1404j, -0.0650+0.0555j,&#10;         -0.3483+0.0103j, -0.1365+0.6053j,  0.0000+0.0000j,  0.6622+0.4553j,&#10;          0.4672-0.1352j,  0.5086+0.0738j,  0.0372-0.1404j, -0.6622-0.4553j,&#10;          0.0000+0.0000j,  0.1409+0.1369j, -0.6648-0.9262j,  0.0650-0.0555j,&#10;         -0.4672+0.1352j, -0.1409-0.1369j,  0.0000+0.0000j,  0.1143+0.1003j,&#10;          0.3483-0.0103j, -0.5086-0.0738j,  0.6648+0.9262j, -0.1143-0.1003j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1279-0.2039j, -0.1442+0.6080j, -0.1129+0.6585j,&#10;          0.1220-0.1401j,  0.1279+0.2039j,  0.0000+0.0000j,  0.2019-0.0101j,&#10;          0.4833-0.1084j, -0.2998+0.2633j,  0.1442-0.6080j, -0.2019+0.0101j,&#10;          0.0000+0.0000j, -0.6449+0.7359j,  0.2436-1.1920j,  0.1129-0.6585j,&#10;         -0.4833+0.1084j,  0.6449-0.7359j,  0.0000+0.0000j,  0.0299-0.5217j,&#10;         -0.1220+0.1401j,  0.2998-0.2633j, -0.2436+1.1920j, -0.0299+0.5217j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0532+0.0399j,  0.3958-0.2996j,  0.4502-0.0828j,&#10;          0.0956-0.1519j, -0.0532-0.0399j,  0.0000+0.0000j, -0.2762-0.0160j,&#10;          0.0916-0.2331j, -0.0592-0.1527j, -0.3958+0.2996j,  0.2762+0.0160j,&#10;          0.0000+0.0000j,  0.2684+0.1900j,  0.0451-0.1141j, -0.4502+0.0828j,&#10;         -0.0916+0.2331j, -0.2684-0.1900j,  0.0000+0.0000j, -0.1223+0.2904j,&#10;         -0.0956+0.1519j,  0.0592+0.1527j, -0.0451+0.1141j,  0.1223-0.2904j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2624+0.0000j,  0.1797+0.0000j, -0.0495+0.0000j,&#10;          0.7238+0.0000j, -0.2624+0.0000j,  0.0000+0.0000j, -1.3409+0.0000j,&#10;          0.3647+0.0000j, -1.9858+0.0000j, -0.1797+0.0000j,  1.3409+0.0000j,&#10;          0.0000+0.0000j, -2.8159+0.0000j,  5.3445+0.0000j,  0.0495+0.0000j,&#10;         -0.3647+0.0000j,  2.8159+0.0000j,  0.0000+0.0000j,  1.3387+0.0000j,&#10;         -0.7238+0.0000j,  1.9858+0.0000j, -5.3445+0.0000j, -1.3387+0.0000j,&#10;          0.0000+0.0000j]], dtype=torch.complex128)&#10;Analytical:&#10;tensor([[ 0.0000+0.0000j,  0.0218+0.0000j, -0.5424+0.0000j, -0.0634+0.0000j,&#10;          0.1704+0.0000j, -0.0218+0.0000j,  0.0000+0.0000j,  0.1896+0.0000j,&#10;         -0.2152+0.0000j, -0.0375+0.0000j,  0.5424+0.0000j, -0.1896+0.0000j,&#10;          0.0000+0.0000j, -0.0233+0.0000j,  0.5580+0.0000j,  0.0634+0.0000j,&#10;          0.2152+0.0000j,  0.0233+0.0000j,  0.0000+0.0000j, -0.4424+0.0000j,&#10;         -0.1704+0.0000j,  0.0375+0.0000j, -0.5580+0.0000j,  0.4424+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0369-0.1488j, -0.0693-0.2892j,  0.2102+0.0833j,&#10;         -0.1702+0.0601j, -0.0369+0.1488j,  0.0000+0.0000j, -0.0954+0.1975j,&#10;          0.1912-0.1777j,  0.1852+0.0104j,  0.0693+0.2892j,  0.0954-0.1975j,&#10;          0.0000+0.0000j,  0.0544-0.0094j, -0.2359+0.3485j, -0.2102-0.0833j,&#10;         -0.1912+0.1777j, -0.0544+0.0094j,  0.0000+0.0000j,  0.0857-0.0200j,&#10;          0.1702-0.0601j, -0.1852-0.0104j,  0.2359-0.3485j, -0.0857+0.0200j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0108-0.2994j, -0.3488+0.7905j, -0.2816+0.0899j,&#10;          0.5235+0.0343j, -0.0108+0.2994j,  0.0000+0.0000j,  0.0220+0.2108j,&#10;          0.0158+0.0935j, -0.2823-0.1949j,  0.3488-0.7905j, -0.0220-0.2108j,&#10;          0.0000+0.0000j, -0.3554+0.1421j,  1.4427-0.7791j,  0.2816-0.0899j,&#10;         -0.0158-0.0935j,  0.3554-0.1421j,  0.0000+0.0000j, -0.0281+0.4863j,&#10;         -0.5235-0.0343j,  0.2823+0.1949j, -1.4427+0.7791j,  0.0281-0.4863j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0090+0.0727j,  0.5823+0.1140j, -0.2167+0.0681j,&#10;          0.0269-0.2239j,  0.0090-0.0727j,  0.0000+0.0000j,  0.0607-0.1289j,&#10;          0.0408-0.0446j,  0.0444-0.1510j, -0.5823-0.1140j, -0.0607+0.1289j,&#10;          0.0000+0.0000j,  0.0955-0.2904j, -0.5551-0.6389j,  0.2167-0.0681j,&#10;         -0.0408+0.0446j, -0.0955+0.2904j,  0.0000+0.0000j,  0.1218+0.2114j,&#10;         -0.0269+0.2239j, -0.0444+0.1510j,  0.5551+0.6389j, -0.1218-0.2114j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1570+0.0628j, -0.3817+0.0242j, -0.4255-0.2304j,&#10;          0.1927+0.1556j, -0.1570-0.0628j,  0.0000+0.0000j, -0.1469+0.1839j,&#10;         -0.0608+0.0340j, -0.3392-0.2455j,  0.3817-0.0242j,  0.1469-0.1839j,&#10;          0.0000+0.0000j, -0.5774+0.1940j,  1.1725+0.8127j,  0.4255+0.2304j,&#10;          0.0608-0.0340j,  0.5774-0.1940j,  0.0000+0.0000j, -0.0583+0.3857j,&#10;         -0.1927-0.1556j,  0.3392+0.2455j, -1.1725-0.8127j,  0.0583-0.3857j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0369+0.1488j, -0.0693+0.2892j,  0.2102-0.0833j,&#10;         -0.1702-0.0601j, -0.0369-0.1488j,  0.0000+0.0000j, -0.0954-0.1975j,&#10;          0.1912+0.1777j,  0.1852-0.0104j,  0.0693-0.2892j,  0.0954+0.1975j,&#10;          0.0000+0.0000j,  0.0544+0.0094j, -0.2359-0.3485j, -0.2102+0.0833j,&#10;         -0.1912-0.1777j, -0.0544-0.0094j,  0.0000+0.0000j,  0.0857+0.0200j,&#10;          0.1702+0.0601j, -0.1852+0.0104j,  0.2359+0.3485j, -0.0857-0.0200j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.4466+0.0000j, -0.1077+0.0000j, -0.1016+0.0000j,&#10;          0.0317+0.0000j,  0.4466+0.0000j,  0.0000+0.0000j,  0.2128+0.0000j,&#10;          0.2572+0.0000j,  0.1334+0.0000j,  0.1077+0.0000j, -0.2128+0.0000j,&#10;          0.0000+0.0000j, -0.0449+0.0000j,  0.0624+0.0000j,  0.1016+0.0000j,&#10;         -0.2572+0.0000j,  0.0449+0.0000j,  0.0000+0.0000j,  0.1523+0.0000j,&#10;         -0.0317+0.0000j, -0.1334+0.0000j, -0.0624+0.0000j, -0.1523+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1836+0.2006j, -0.1265+0.1890j,  0.1599-0.1347j,&#10;          0.0744+0.1905j,  0.1836-0.2006j,  0.0000+0.0000j,  0.1765-0.0244j,&#10;          0.1215+0.1701j, -0.0538+0.3040j,  0.1265-0.1890j, -0.1765+0.0244j,&#10;          0.0000+0.0000j,  0.4325+0.5204j, -0.7731-0.4021j, -0.1599+0.1347j,&#10;         -0.1215-0.1701j, -0.4325-0.5204j,  0.0000+0.0000j, -0.1398-0.1720j,&#10;         -0.0744-0.1905j,  0.0538-0.3040j,  0.7731+0.4021j,  0.1398+0.1720j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1552-0.1628j,  0.1286+0.0479j, -0.0798-0.0503j,&#10;          0.1298+0.0198j, -0.1552+0.1628j,  0.0000+0.0000j, -0.1011+0.1748j,&#10;          0.0526-0.0970j, -0.2625+0.0382j, -0.1286-0.0479j,  0.1011-0.1748j,&#10;          0.0000+0.0000j, -0.0773-0.1916j,  0.2044+0.2100j,  0.0798+0.0503j,&#10;         -0.0526+0.0970j,  0.0773+0.1916j,  0.0000+0.0000j,  0.0680+0.1622j,&#10;         -0.1298-0.0198j,  0.2625-0.0382j, -0.2044-0.2100j, -0.0680-0.1622j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2685+0.0097j, -0.0300-0.2073j,  0.1046-0.1632j,&#10;         -0.2543-0.2363j, -0.2685-0.0097j,  0.0000+0.0000j,  0.2619+0.3166j,&#10;          0.1203+0.0460j,  0.1277+0.2882j,  0.0300+0.2073j, -0.2619-0.3166j,&#10;          0.0000+0.0000j, -0.0974+0.6161j, -0.2637-1.2207j, -0.1046+0.1632j,&#10;         -0.1203-0.0460j,  0.0974-0.6161j,  0.0000+0.0000j,  0.0434-0.3901j,&#10;          0.2543+0.2363j, -0.1277-0.2882j,  0.2637+1.2207j, -0.0434+0.3901j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.0108+0.2994j, -0.3488-0.7905j, -0.2816-0.0899j,&#10;          0.5235-0.0343j, -0.0108-0.2994j,  0.0000+0.0000j,  0.0220-0.2108j,&#10;          0.0158-0.0935j, -0.2823+0.1949j,  0.3488+0.7905j, -0.0220+0.2108j,&#10;          0.0000+0.0000j, -0.3554-0.1421j,  1.4427+0.7791j,  0.2816+0.0899j,&#10;         -0.0158+0.0935j,  0.3554+0.1421j,  0.0000+0.0000j, -0.0281-0.4863j,&#10;         -0.5235+0.0343j,  0.2823-0.1949j, -1.4427-0.7791j,  0.0281+0.4863j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1836-0.2006j, -0.1265-0.1890j,  0.1599+0.1347j,&#10;          0.0744-0.1905j,  0.1836+0.2006j,  0.0000+0.0000j,  0.1765+0.0244j,&#10;          0.1215-0.1701j, -0.0538-0.3040j,  0.1265+0.1890j, -0.1765-0.0244j,&#10;          0.0000+0.0000j,  0.4325-0.5204j, -0.7731+0.4021j, -0.1599-0.1347j,&#10;         -0.1215+0.1701j, -0.4325+0.5204j,  0.0000+0.0000j, -0.1398+0.1720j,&#10;         -0.0744+0.1905j,  0.0538+0.3040j,  0.7731-0.4021j,  0.1398-0.1720j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2846+0.0000j, -0.9841+0.0000j, -0.0470+0.0000j,&#10;          0.3722+0.0000j, -0.2846+0.0000j,  0.0000+0.0000j, -0.8316+0.0000j,&#10;          0.3416+0.0000j, -1.1662+0.0000j,  0.9841+0.0000j,  0.8316+0.0000j,&#10;          0.0000+0.0000j, -1.8647+0.0000j,  3.6387+0.0000j,  0.0470+0.0000j,&#10;         -0.3416+0.0000j,  1.8647+0.0000j,  0.0000+0.0000j,  0.1582+0.0000j,&#10;         -0.3722+0.0000j,  1.1662+0.0000j, -3.6387+0.0000j, -0.1582+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1146-0.0334j,  0.6014+0.1697j, -0.0738-0.3082j,&#10;          0.0311+0.2282j,  0.1146+0.0334j,  0.0000+0.0000j,  0.3257+0.5473j,&#10;         -0.0622-0.1885j,  0.3221+0.6264j, -0.6014-0.1697j, -0.3257-0.5473j,&#10;          0.0000+0.0000j,  0.8720+0.7925j, -1.1467-1.6200j,  0.0738+0.3082j,&#10;          0.0622+0.1885j, -0.8720-0.7925j,  0.0000+0.0000j, -0.5628-0.2613j,&#10;         -0.0311-0.2282j, -0.3221-0.6264j,  1.1467+1.6200j,  0.5628+0.2613j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2662+0.3273j,  0.3285-0.6547j, -0.2568-0.5832j,&#10;          0.1150+0.8192j, -0.2662-0.3273j,  0.0000+0.0000j, -0.2833-0.4877j,&#10;          0.4566+0.1790j, -0.5417-1.2393j, -0.3285+0.6547j,  0.2833+0.4877j,&#10;          0.0000+0.0000j, -0.9582-1.5869j,  1.4222+3.8855j,  0.2568+0.5832j,&#10;         -0.4566-0.1790j,  0.9582+1.5869j,  0.0000+0.0000j,  0.2708+0.7713j,&#10;         -0.1150-0.8192j,  0.5417+1.2393j, -1.4222-3.8855j, -0.2708-0.7713j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0090-0.0727j,  0.5823-0.1140j, -0.2167-0.0681j,&#10;          0.0269+0.2239j,  0.0090+0.0727j,  0.0000+0.0000j,  0.0607+0.1289j,&#10;          0.0408+0.0446j,  0.0444+0.1510j, -0.5823+0.1140j, -0.0607-0.1289j,&#10;          0.0000+0.0000j,  0.0955+0.2904j, -0.5551+0.6389j,  0.2167+0.0681j,&#10;         -0.0408-0.0446j, -0.0955-0.2904j,  0.0000+0.0000j,  0.1218-0.2114j,&#10;         -0.0269-0.2239j, -0.0444-0.1510j,  0.5551-0.6389j, -0.1218+0.2114j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1552+0.1628j,  0.1286-0.0479j, -0.0798+0.0503j,&#10;          0.1298-0.0198j, -0.1552-0.1628j,  0.0000+0.0000j, -0.1011-0.1748j,&#10;          0.0526+0.0970j, -0.2625-0.0382j, -0.1286+0.0479j,  0.1011+0.1748j,&#10;          0.0000+0.0000j, -0.0773+0.1916j,  0.2044-0.2100j,  0.0798-0.0503j,&#10;         -0.0526-0.0970j,  0.0773-0.1916j,  0.0000+0.0000j,  0.0680-0.1622j,&#10;         -0.1298+0.0198j,  0.2625+0.0382j, -0.2044+0.2100j, -0.0680+0.1622j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1146+0.0334j,  0.6014-0.1697j, -0.0738+0.3082j,&#10;          0.0311-0.2282j,  0.1146-0.0334j,  0.0000+0.0000j,  0.3257-0.5473j,&#10;         -0.0622+0.1885j,  0.3221-0.6264j, -0.6014+0.1697j, -0.3257+0.5473j,&#10;          0.0000+0.0000j,  0.8720-0.7925j, -1.1467+1.6200j,  0.0738-0.3082j,&#10;          0.0622-0.1885j, -0.8720+0.7925j,  0.0000+0.0000j, -0.5628+0.2613j,&#10;         -0.0311+0.2282j, -0.3221+0.6264j,  1.1467-1.6200j,  0.5628-0.2613j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1503+0.0000j, -0.1164+0.0000j,  0.0766+0.0000j,&#10;         -0.2104+0.0000j, -0.1503+0.0000j,  0.0000+0.0000j, -0.1821+0.0000j,&#10;          0.0120+0.0000j, -0.1595+0.0000j,  0.1164+0.0000j,  0.1821+0.0000j,&#10;          0.0000+0.0000j,  0.0043+0.0000j,  0.2553+0.0000j, -0.0766+0.0000j,&#10;         -0.0120+0.0000j, -0.0043+0.0000j,  0.0000+0.0000j, -0.0623+0.0000j,&#10;          0.2104+0.0000j,  0.1595+0.0000j, -0.2553+0.0000j,  0.0623+0.0000j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1796-0.0140j,  0.2047+0.4922j,  0.0053+0.2221j,&#10;         -0.1974+0.3775j,  0.1796+0.0140j,  0.0000+0.0000j,  0.4428-0.1806j,&#10;         -0.0354+0.1543j,  0.6757-0.4050j, -0.2047-0.4922j, -0.4428+0.1806j,&#10;          0.0000+0.0000j,  1.0367-0.2541j, -2.0550+0.8155j, -0.0053-0.2221j,&#10;          0.0354-0.1543j, -1.0367+0.2541j,  0.0000+0.0000j, -0.5880+0.0310j,&#10;          0.1974-0.3775j, -0.6757+0.4050j,  2.0550-0.8155j,  0.5880-0.0310j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.1570-0.0628j, -0.3817-0.0242j, -0.4255+0.2304j,&#10;          0.1927-0.1556j, -0.1570+0.0628j,  0.0000+0.0000j, -0.1469-0.1839j,&#10;         -0.0608-0.0340j, -0.3392+0.2455j,  0.3817+0.0242j,  0.1469+0.1839j,&#10;          0.0000+0.0000j, -0.5774-0.1940j,  1.1725-0.8127j,  0.4255-0.2304j,&#10;          0.0608+0.0340j,  0.5774+0.1940j,  0.0000+0.0000j, -0.0583-0.3857j,&#10;         -0.1927+0.1556j,  0.3392-0.2455j, -1.1725+0.8127j,  0.0583+0.3857j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2685-0.0097j, -0.0300+0.2073j,  0.1046+0.1632j,&#10;         -0.2543+0.2363j, -0.2685+0.0097j,  0.0000+0.0000j,  0.2619-0.3166j,&#10;          0.1203-0.0460j,  0.1277-0.2882j,  0.0300-0.2073j, -0.2619+0.3166j,&#10;          0.0000+0.0000j, -0.0974-0.6161j, -0.2637+1.2207j, -0.1046-0.1632j,&#10;         -0.1203+0.0460j,  0.0974+0.6161j,  0.0000+0.0000j,  0.0434+0.3901j,&#10;          0.2543-0.2363j, -0.1277+0.2882j,  0.2637-1.2207j, -0.0434-0.3901j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j,  0.2662-0.3273j,  0.3285+0.6547j, -0.2568+0.5832j,&#10;          0.1150-0.8192j, -0.2662+0.3273j,  0.0000+0.0000j, -0.2833+0.4877j,&#10;          0.4566-0.1790j, -0.5417+1.2393j, -0.3285-0.6547j,  0.2833-0.4877j,&#10;          0.0000+0.0000j, -0.9582+1.5869j,  1.4222-3.8855j,  0.2568-0.5832j,&#10;         -0.4566+0.1790j,  0.9582-1.5869j,  0.0000+0.0000j,  0.2708-0.7713j,&#10;         -0.1150+0.8192j,  0.5417-1.2393j, -1.4222+3.8855j, -0.2708+0.7713j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.1796+0.0140j,  0.2047-0.4922j,  0.0053-0.2221j,&#10;         -0.1974-0.3775j,  0.1796-0.0140j,  0.0000+0.0000j,  0.4428+0.1806j,&#10;         -0.0354-0.1543j,  0.6757+0.4050j, -0.2047+0.4922j, -0.4428-0.1806j,&#10;          0.0000+0.0000j,  1.0367+0.2541j, -2.0550-0.8155j, -0.0053+0.2221j,&#10;          0.0354+0.1543j, -1.0367-0.2541j,  0.0000+0.0000j, -0.5880-0.0310j,&#10;          0.1974+0.3775j, -0.6757-0.4050j,  2.0550+0.8155j,  0.5880+0.0310j,&#10;          0.0000+0.0000j],&#10;        [ 0.0000+0.0000j, -0.0741+0.0000j, -0.1869+0.0000j, -0.7082+0.0000j,&#10;          0.6163+0.0000j,  0.0741+0.0000j,  0.0000+0.0000j, -0.1770+0.0000j,&#10;          0.5158+0.0000j, -0.9383+0.0000j,  0.1869+0.0000j,  0.1770+0.0000j,&#10;          0.0000+0.0000j, -1.7614+0.0000j,  2.8911+0.0000j,  0.7082+0.0000j,&#10;         -0.5158+0.0000j,  1.7614+0.0000j,  0.0000+0.0000j,  0.7901+0.0000j,&#10;         -0.6163+0.0000j,  0.9383+0.0000j, -2.8911+0.0000j, -0.7901+0.0000j,&#10;          0.0000+0.0000j]], dtype=torch.complex128)&#10;&#10;The max per-element difference (slow mode) is: 6.3536245618784655.">Traceback (most recent call last):
  File "C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py", line 60, in test_fn_gradgrad
    self._check_helper(device, dtype, op, op.get_op(), 'bwgrad_bwgrad')
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 4366, in _check_helper
    self.assertTrue(gradgradcheck(fn, gradcheck_args, **kwargs))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\testing\_internal\common_utils.py", line 3916, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1710, in gradgradcheck
    return gradcheck(
           ^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1552, in gradcheck
    return _gradcheck_helper(**args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1566, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1154, in _gradcheck_real_imag
    gradcheck_fn(imag_fn, imag_func_out, tupled_inputs, imag_outputs, eps,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1418, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\autograd\gradcheck.py", line 1386, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: While considering the imaginary part of complex outputs only, Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.2966-0.2039j, dtype=torch.complex128)
analytical:tensor(-0.0156+0.0625j, dtype=torch.complex128)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000+0.0000j,  0.0218+0.0000j, -0.5424+0.0000j, -0.0634+0.0000j,
          0.1704+0.0000j, -0.0218+0.0000j,  0.0000+0.0000j,  0.1896+0.0000j,
         -0.2152+0.0000j, -0.0375+0.0000j,  0.5424+0.0000j, -0.1896+0.0000j,
          0.0000+0.0000j, -0.0233+0.0000j,  0.5580+0.0000j,  0.0634+0.0000j,
          0.2152+0.0000j,  0.0233+0.0000j,  0.0000+0.0000j, -0.4424+0.0000j,
         -0.1704+0.0000j,  0.0375+0.0000j, -0.5580+0.0000j,  0.4424+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.3792-0.5127j,  0.2345-0.3072j,  0.1949-0.2280j,
         -0.4600-0.1427j,  0.3792+0.5127j,  0.0000+0.0000j,  0.6419+0.9051j,
          0.0233-0.3378j,  0.9996+0.5829j, -0.2345+0.3072j, -0.6419-0.9051j,
          0.0000+0.0000j,  1.2429+0.4169j, -3.0741-1.2672j, -0.1949+0.2280j,
         -0.0233+0.3378j, -1.2429-0.4169j,  0.0000+0.0000j, -0.2619-0.3679j,
          0.4600+0.1427j, -0.9996-0.5829j,  3.0741+1.2672j,  0.2619+0.3679j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.4076-0.3305j, -0.2731+0.4938j,  0.1746-0.0898j,
          0.9136+0.1892j, -0.4076+0.3305j,  0.0000+0.0000j, -1.0547-0.1637j,
         -0.0454-0.0415j, -1.6821-0.8783j,  0.2731-0.4938j,  1.0547+0.1637j,
          0.0000+0.0000j, -1.6927-0.9436j,  4.9008+1.1572j, -0.1746+0.0898j,
          0.0454+0.0415j,  1.6927+0.9436j,  0.0000+0.0000j,  0.6863+0.4367j,
         -0.9136-0.1892j,  1.6821+0.8783j, -4.9008-1.1572j, -0.6863-0.4367j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.2900+0.2770j,  0.7682+0.1182j, -0.0639-0.0576j,
          0.0233-0.3758j,  0.2900-0.2770j,  0.0000+0.0000j,  0.1546-0.0243j,
         -0.0967-0.2483j, -0.1803+0.4475j, -0.7682-0.1182j, -0.1546+0.0243j,
          0.0000+0.0000j,  0.1680+0.0791j, -0.8521-1.5282j,  0.0639+0.0576j,
          0.0967+0.2483j, -0.1680-0.0791j,  0.0000+0.0000j,  0.1871-0.1112j,
         -0.0233+0.3758j,  0.1803-0.4475j,  0.8521+1.5282j, -0.1871+0.1112j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0748-0.1043j, -0.3327-0.3628j, -0.4305-0.4218j,
          0.2067+0.4163j, -0.0748+0.1043j,  0.0000+0.0000j, -0.0989-0.1422j,
         -0.0520+0.0974j, -0.4434-1.2655j,  0.3327+0.3628j,  0.0989+0.1422j,
          0.0000+0.0000j, -0.6953-1.1991j,  1.3390+3.3856j,  0.4305+0.4218j,
          0.0520-0.0974j,  0.6953+1.1991j,  0.0000+0.0000j,  0.0334+0.6044j,
         -0.2067-0.4163j,  0.4434+1.2655j, -1.3390-3.3856j, -0.0334-0.6044j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.3792+0.5127j,  0.2345+0.3072j,  0.1949+0.2280j,
         -0.4600+0.1427j,  0.3792-0.5127j,  0.0000+0.0000j,  0.6419-0.9051j,
          0.0233+0.3378j,  0.9996-0.5829j, -0.2345-0.3072j, -0.6419+0.9051j,
          0.0000+0.0000j,  1.2429-0.4169j, -3.0741+1.2672j, -0.1949-0.2280j,
         -0.0233-0.3378j, -1.2429+0.4169j,  0.0000+0.0000j, -0.2619+0.3679j,
          0.4600-0.1427j, -0.9996+0.5829j,  3.0741-1.2672j,  0.2619-0.3679j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.9318+0.0000j, -0.2639+0.0000j, -0.4408+0.0000j,
         -0.1636+0.0000j,  0.9318+0.0000j,  0.0000+0.0000j,  0.9742+0.0000j,
          0.3994+0.0000j,  0.8002+0.0000j,  0.2639+0.0000j, -0.9742+0.0000j,
          0.0000+0.0000j, -0.1164+0.0000j, -0.8842+0.0000j,  0.4408+0.0000j,
         -0.3994+0.0000j,  0.1164+0.0000j,  0.0000+0.0000j, -0.1214+0.0000j,
          0.1636+0.0000j, -0.8002+0.0000j,  0.8842+0.0000j,  0.1214+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2066-0.2991j, -0.1613-0.0885j, -0.0583-0.2935j,
         -0.0222+0.1244j, -0.2066+0.2991j,  0.0000+0.0000j, -0.1006+0.1508j,
         -0.0864+0.0122j,  0.0228-0.2160j,  0.1613+0.0885j,  0.1006-0.1508j,
          0.0000+0.0000j,  0.2173-0.1370j, -0.3082-0.0439j,  0.0583+0.2935j,
          0.0864-0.0122j, -0.2173+0.1370j,  0.0000+0.0000j, -0.2399-0.2007j,
          0.0222-0.1244j, -0.0228+0.2160j,  0.3082+0.0439j,  0.2399+0.2007j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.4610+0.4147j,  0.0857+0.1520j, -0.0475+0.0705j,
          0.2302+0.0140j, -0.4610-0.4147j,  0.0000+0.0000j, -0.5978-0.2806j,
          0.0812-0.4256j, -0.6959+0.3152j, -0.0857-0.1520j,  0.5978+0.2806j,
          0.0000+0.0000j, -0.6461+0.2464j,  1.7212-0.2187j,  0.0475-0.0705j,
         -0.0812+0.4256j,  0.6461-0.2464j,  0.0000+0.0000j,  0.2985-0.1244j,
         -0.2302-0.0140j,  0.6959-0.3152j, -1.7212+0.2187j, -0.2985+0.1244j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1365+0.6053j, -0.0372-0.1404j, -0.0650-0.0555j,
         -0.3483-0.0103j, -0.1365-0.6053j,  0.0000+0.0000j,  0.6622-0.4553j,
          0.4672+0.1352j,  0.5086-0.0738j,  0.0372+0.1404j, -0.6622+0.4553j,
          0.0000+0.0000j,  0.1409-0.1369j, -0.6648+0.9262j,  0.0650+0.0555j,
         -0.4672-0.1352j, -0.1409+0.1369j,  0.0000+0.0000j,  0.1143-0.1003j,
          0.3483+0.0103j, -0.5086+0.0738j,  0.6648-0.9262j, -0.1143+0.1003j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.4076+0.3305j, -0.2731-0.4938j,  0.1746+0.0898j,
          0.9136-0.1892j, -0.4076-0.3305j,  0.0000+0.0000j, -1.0547+0.1637j,
         -0.0454+0.0415j, -1.6821+0.8783j,  0.2731+0.4938j,  1.0547-0.1637j,
          0.0000+0.0000j, -1.6927+0.9436j,  4.9008-1.1572j, -0.1746-0.0898j,
          0.0454-0.0415j,  1.6927-0.9436j,  0.0000+0.0000j,  0.6863-0.4367j,
         -0.9136+0.1892j,  1.6821-0.8783j, -4.9008+1.1572j, -0.6863+0.4367j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2066+0.2991j, -0.1613+0.0885j, -0.0583+0.2935j,
         -0.0222-0.1244j, -0.2066-0.2991j,  0.0000+0.0000j, -0.1006-0.1508j,
         -0.0864-0.0122j,  0.0228+0.2160j,  0.1613-0.0885j,  0.1006+0.1508j,
          0.0000+0.0000j,  0.2173+0.1370j, -0.3082+0.0439j,  0.0583-0.2935j,
          0.0864+0.0122j, -0.2173-0.1370j,  0.0000+0.0000j, -0.2399+0.2007j,
          0.0222+0.1244j, -0.0228-0.2160j,  0.3082-0.0439j,  0.2399-0.2007j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.3783+0.0000j, -0.2248+0.0000j,  0.0079+0.0000j,
         -0.3962+0.0000j, -0.3783+0.0000j,  0.0000+0.0000j,  0.2228+0.0000j,
         -0.2324+0.0000j,  1.0772+0.0000j,  0.2248+0.0000j, -0.2228+0.0000j,
          0.0000+0.0000j,  1.2074+0.0000j, -2.7149+0.0000j, -0.0079+0.0000j,
          0.2324+0.0000j, -1.2074+0.0000j,  0.0000+0.0000j, -0.5755+0.0000j,
          0.3962+0.0000j, -1.0772+0.0000j,  2.7149+0.0000j,  0.5755+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1325+0.1202j,  0.3061-0.0156j,  0.2719-0.3833j,
          0.4966+0.0173j, -0.1325-0.1202j,  0.0000+0.0000j, -0.5917+0.2027j,
         -0.1171-0.1642j, -1.1098+0.5238j, -0.3061+0.0156j,  0.5917-0.2027j,
          0.0000+0.0000j, -0.3726+0.3966j,  1.8628-1.1994j, -0.2719+0.3833j,
          0.1171+0.1642j,  0.3726-0.3966j,  0.0000+0.0000j, -0.1042-0.3768j,
         -0.4966-0.0173j,  1.1098-0.5238j, -1.8628+1.1994j,  0.1042+0.3768j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1279+0.2039j, -0.1442-0.6080j, -0.1129-0.6585j,
          0.1220+0.1401j,  0.1279-0.2039j,  0.0000+0.0000j,  0.2019+0.0101j,
          0.4833+0.1084j, -0.2998-0.2633j,  0.1442+0.6080j, -0.2019-0.0101j,
          0.0000+0.0000j, -0.6449-0.7359j,  0.2436+1.1920j,  0.1129+0.6585j,
         -0.4833-0.1084j,  0.6449+0.7359j,  0.0000+0.0000j,  0.0299+0.5217j,
         -0.1220-0.1401j,  0.2998+0.2633j, -0.2436-1.1920j, -0.0299-0.5217j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.2900-0.2770j,  0.7682-0.1182j, -0.0639+0.0576j,
          0.0233+0.3758j,  0.2900+0.2770j,  0.0000+0.0000j,  0.1546+0.0243j,
         -0.0967+0.2483j, -0.1803-0.4475j, -0.7682+0.1182j, -0.1546-0.0243j,
          0.0000+0.0000j,  0.1680-0.0791j, -0.8521+1.5282j,  0.0639-0.0576j,
          0.0967-0.2483j, -0.1680+0.0791j,  0.0000+0.0000j,  0.1871+0.1112j,
         -0.0233-0.3758j,  0.1803+0.4475j,  0.8521-1.5282j, -0.1871-0.1112j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.4610-0.4147j,  0.0857-0.1520j, -0.0475-0.0705j,
          0.2302-0.0140j, -0.4610+0.4147j,  0.0000+0.0000j, -0.5978+0.2806j,
          0.0812+0.4256j, -0.6959-0.3152j, -0.0857+0.1520j,  0.5978-0.2806j,
          0.0000+0.0000j, -0.6461-0.2464j,  1.7212+0.2187j,  0.0475+0.0705j,
         -0.0812-0.4256j,  0.6461+0.2464j,  0.0000+0.0000j,  0.2985+0.1244j,
         -0.2302+0.0140j,  0.6959+0.3152j, -1.7212-0.2187j, -0.2985-0.1244j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1325-0.1202j,  0.3061+0.0156j,  0.2719+0.3833j,
          0.4966-0.0173j, -0.1325+0.1202j,  0.0000+0.0000j, -0.5917-0.2027j,
         -0.1171+0.1642j, -1.1098-0.5238j, -0.3061-0.0156j,  0.5917+0.2027j,
          0.0000+0.0000j, -0.3726-0.3966j,  1.8628+1.1994j, -0.2719-0.3833j,
          0.1171-0.1642j,  0.3726+0.3966j,  0.0000+0.0000j, -0.1042+0.3768j,
         -0.4966+0.0173j,  1.1098+0.5238j, -1.8628-1.1994j,  0.1042-0.3768j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.3179+0.0000j,  0.2366+0.0000j,  0.4782+0.0000j,
         -0.4087+0.0000j, -0.3179+0.0000j,  0.0000+0.0000j,  0.1923+0.0000j,
         -0.0584+0.0000j,  1.0768+0.0000j, -0.2366+0.0000j, -0.1923+0.0000j,
          0.0000+0.0000j,  1.8821+0.0000j, -3.0938+0.0000j, -0.4782+0.0000j,
          0.0584+0.0000j, -1.8821+0.0000j,  0.0000+0.0000j, -0.3606+0.0000j,
          0.4087+0.0000j, -1.0768+0.0000j,  3.0938+0.0000j,  0.3606+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0532-0.0399j,  0.3958+0.2996j,  0.4502+0.0828j,
          0.0956+0.1519j, -0.0532+0.0399j,  0.0000+0.0000j, -0.2762+0.0160j,
          0.0916+0.2331j, -0.0592+0.1527j, -0.3958-0.2996j,  0.2762-0.0160j,
          0.0000+0.0000j,  0.2684-0.1900j,  0.0451+0.1141j, -0.4502-0.0828j,
         -0.0916-0.2331j, -0.2684+0.1900j,  0.0000+0.0000j, -0.1223-0.2904j,
         -0.0956-0.1519j,  0.0592-0.1527j, -0.0451-0.1141j,  0.1223+0.2904j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0748+0.1043j, -0.3327+0.3628j, -0.4305+0.4218j,
          0.2067-0.4163j, -0.0748-0.1043j,  0.0000+0.0000j, -0.0989+0.1422j,
         -0.0520-0.0974j, -0.4434+1.2655j,  0.3327-0.3628j,  0.0989-0.1422j,
          0.0000+0.0000j, -0.6953+1.1991j,  1.3390-3.3856j,  0.4305-0.4218j,
          0.0520+0.0974j,  0.6953-1.1991j,  0.0000+0.0000j,  0.0334-0.6044j,
         -0.2067+0.4163j,  0.4434-1.2655j, -1.3390+3.3856j, -0.0334+0.6044j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1365-0.6053j, -0.0372+0.1404j, -0.0650+0.0555j,
         -0.3483+0.0103j, -0.1365+0.6053j,  0.0000+0.0000j,  0.6622+0.4553j,
          0.4672-0.1352j,  0.5086+0.0738j,  0.0372-0.1404j, -0.6622-0.4553j,
          0.0000+0.0000j,  0.1409+0.1369j, -0.6648-0.9262j,  0.0650-0.0555j,
         -0.4672+0.1352j, -0.1409-0.1369j,  0.0000+0.0000j,  0.1143+0.1003j,
          0.3483-0.0103j, -0.5086-0.0738j,  0.6648+0.9262j, -0.1143-0.1003j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1279-0.2039j, -0.1442+0.6080j, -0.1129+0.6585j,
          0.1220-0.1401j,  0.1279+0.2039j,  0.0000+0.0000j,  0.2019-0.0101j,
          0.4833-0.1084j, -0.2998+0.2633j,  0.1442-0.6080j, -0.2019+0.0101j,
          0.0000+0.0000j, -0.6449+0.7359j,  0.2436-1.1920j,  0.1129-0.6585j,
         -0.4833+0.1084j,  0.6449-0.7359j,  0.0000+0.0000j,  0.0299-0.5217j,
         -0.1220+0.1401j,  0.2998-0.2633j, -0.2436+1.1920j, -0.0299+0.5217j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0532+0.0399j,  0.3958-0.2996j,  0.4502-0.0828j,
          0.0956-0.1519j, -0.0532-0.0399j,  0.0000+0.0000j, -0.2762-0.0160j,
          0.0916-0.2331j, -0.0592-0.1527j, -0.3958+0.2996j,  0.2762+0.0160j,
          0.0000+0.0000j,  0.2684+0.1900j,  0.0451-0.1141j, -0.4502+0.0828j,
         -0.0916+0.2331j, -0.2684-0.1900j,  0.0000+0.0000j, -0.1223+0.2904j,
         -0.0956+0.1519j,  0.0592+0.1527j, -0.0451+0.1141j,  0.1223-0.2904j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2624+0.0000j,  0.1797+0.0000j, -0.0495+0.0000j,
          0.7238+0.0000j, -0.2624+0.0000j,  0.0000+0.0000j, -1.3409+0.0000j,
          0.3647+0.0000j, -1.9858+0.0000j, -0.1797+0.0000j,  1.3409+0.0000j,
          0.0000+0.0000j, -2.8159+0.0000j,  5.3445+0.0000j,  0.0495+0.0000j,
         -0.3647+0.0000j,  2.8159+0.0000j,  0.0000+0.0000j,  1.3387+0.0000j,
         -0.7238+0.0000j,  1.9858+0.0000j, -5.3445+0.0000j, -1.3387+0.0000j,
          0.0000+0.0000j]], dtype=torch.complex128)
Analytical:
tensor([[ 0.0000+0.0000j,  0.0218+0.0000j, -0.5424+0.0000j, -0.0634+0.0000j,
          0.1704+0.0000j, -0.0218+0.0000j,  0.0000+0.0000j,  0.1896+0.0000j,
         -0.2152+0.0000j, -0.0375+0.0000j,  0.5424+0.0000j, -0.1896+0.0000j,
          0.0000+0.0000j, -0.0233+0.0000j,  0.5580+0.0000j,  0.0634+0.0000j,
          0.2152+0.0000j,  0.0233+0.0000j,  0.0000+0.0000j, -0.4424+0.0000j,
         -0.1704+0.0000j,  0.0375+0.0000j, -0.5580+0.0000j,  0.4424+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0369-0.1488j, -0.0693-0.2892j,  0.2102+0.0833j,
         -0.1702+0.0601j, -0.0369+0.1488j,  0.0000+0.0000j, -0.0954+0.1975j,
          0.1912-0.1777j,  0.1852+0.0104j,  0.0693+0.2892j,  0.0954-0.1975j,
          0.0000+0.0000j,  0.0544-0.0094j, -0.2359+0.3485j, -0.2102-0.0833j,
         -0.1912+0.1777j, -0.0544+0.0094j,  0.0000+0.0000j,  0.0857-0.0200j,
          0.1702-0.0601j, -0.1852-0.0104j,  0.2359-0.3485j, -0.0857+0.0200j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0108-0.2994j, -0.3488+0.7905j, -0.2816+0.0899j,
          0.5235+0.0343j, -0.0108+0.2994j,  0.0000+0.0000j,  0.0220+0.2108j,
          0.0158+0.0935j, -0.2823-0.1949j,  0.3488-0.7905j, -0.0220-0.2108j,
          0.0000+0.0000j, -0.3554+0.1421j,  1.4427-0.7791j,  0.2816-0.0899j,
         -0.0158-0.0935j,  0.3554-0.1421j,  0.0000+0.0000j, -0.0281+0.4863j,
         -0.5235-0.0343j,  0.2823+0.1949j, -1.4427+0.7791j,  0.0281-0.4863j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0090+0.0727j,  0.5823+0.1140j, -0.2167+0.0681j,
          0.0269-0.2239j,  0.0090-0.0727j,  0.0000+0.0000j,  0.0607-0.1289j,
          0.0408-0.0446j,  0.0444-0.1510j, -0.5823-0.1140j, -0.0607+0.1289j,
          0.0000+0.0000j,  0.0955-0.2904j, -0.5551-0.6389j,  0.2167-0.0681j,
         -0.0408+0.0446j, -0.0955+0.2904j,  0.0000+0.0000j,  0.1218+0.2114j,
         -0.0269+0.2239j, -0.0444+0.1510j,  0.5551+0.6389j, -0.1218-0.2114j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1570+0.0628j, -0.3817+0.0242j, -0.4255-0.2304j,
          0.1927+0.1556j, -0.1570-0.0628j,  0.0000+0.0000j, -0.1469+0.1839j,
         -0.0608+0.0340j, -0.3392-0.2455j,  0.3817-0.0242j,  0.1469-0.1839j,
          0.0000+0.0000j, -0.5774+0.1940j,  1.1725+0.8127j,  0.4255+0.2304j,
          0.0608-0.0340j,  0.5774-0.1940j,  0.0000+0.0000j, -0.0583+0.3857j,
         -0.1927-0.1556j,  0.3392+0.2455j, -1.1725-0.8127j,  0.0583-0.3857j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0369+0.1488j, -0.0693+0.2892j,  0.2102-0.0833j,
         -0.1702-0.0601j, -0.0369-0.1488j,  0.0000+0.0000j, -0.0954-0.1975j,
          0.1912+0.1777j,  0.1852-0.0104j,  0.0693-0.2892j,  0.0954+0.1975j,
          0.0000+0.0000j,  0.0544+0.0094j, -0.2359-0.3485j, -0.2102+0.0833j,
         -0.1912-0.1777j, -0.0544-0.0094j,  0.0000+0.0000j,  0.0857+0.0200j,
          0.1702+0.0601j, -0.1852+0.0104j,  0.2359+0.3485j, -0.0857-0.0200j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.4466+0.0000j, -0.1077+0.0000j, -0.1016+0.0000j,
          0.0317+0.0000j,  0.4466+0.0000j,  0.0000+0.0000j,  0.2128+0.0000j,
          0.2572+0.0000j,  0.1334+0.0000j,  0.1077+0.0000j, -0.2128+0.0000j,
          0.0000+0.0000j, -0.0449+0.0000j,  0.0624+0.0000j,  0.1016+0.0000j,
         -0.2572+0.0000j,  0.0449+0.0000j,  0.0000+0.0000j,  0.1523+0.0000j,
         -0.0317+0.0000j, -0.1334+0.0000j, -0.0624+0.0000j, -0.1523+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1836+0.2006j, -0.1265+0.1890j,  0.1599-0.1347j,
          0.0744+0.1905j,  0.1836-0.2006j,  0.0000+0.0000j,  0.1765-0.0244j,
          0.1215+0.1701j, -0.0538+0.3040j,  0.1265-0.1890j, -0.1765+0.0244j,
          0.0000+0.0000j,  0.4325+0.5204j, -0.7731-0.4021j, -0.1599+0.1347j,
         -0.1215-0.1701j, -0.4325-0.5204j,  0.0000+0.0000j, -0.1398-0.1720j,
         -0.0744-0.1905j,  0.0538-0.3040j,  0.7731+0.4021j,  0.1398+0.1720j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1552-0.1628j,  0.1286+0.0479j, -0.0798-0.0503j,
          0.1298+0.0198j, -0.1552+0.1628j,  0.0000+0.0000j, -0.1011+0.1748j,
          0.0526-0.0970j, -0.2625+0.0382j, -0.1286-0.0479j,  0.1011-0.1748j,
          0.0000+0.0000j, -0.0773-0.1916j,  0.2044+0.2100j,  0.0798+0.0503j,
         -0.0526+0.0970j,  0.0773+0.1916j,  0.0000+0.0000j,  0.0680+0.1622j,
         -0.1298-0.0198j,  0.2625-0.0382j, -0.2044-0.2100j, -0.0680-0.1622j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2685+0.0097j, -0.0300-0.2073j,  0.1046-0.1632j,
         -0.2543-0.2363j, -0.2685-0.0097j,  0.0000+0.0000j,  0.2619+0.3166j,
          0.1203+0.0460j,  0.1277+0.2882j,  0.0300+0.2073j, -0.2619-0.3166j,
          0.0000+0.0000j, -0.0974+0.6161j, -0.2637-1.2207j, -0.1046+0.1632j,
         -0.1203-0.0460j,  0.0974-0.6161j,  0.0000+0.0000j,  0.0434-0.3901j,
          0.2543+0.2363j, -0.1277-0.2882j,  0.2637+1.2207j, -0.0434+0.3901j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.0108+0.2994j, -0.3488-0.7905j, -0.2816-0.0899j,
          0.5235-0.0343j, -0.0108-0.2994j,  0.0000+0.0000j,  0.0220-0.2108j,
          0.0158-0.0935j, -0.2823+0.1949j,  0.3488+0.7905j, -0.0220+0.2108j,
          0.0000+0.0000j, -0.3554-0.1421j,  1.4427+0.7791j,  0.2816+0.0899j,
         -0.0158+0.0935j,  0.3554+0.1421j,  0.0000+0.0000j, -0.0281-0.4863j,
         -0.5235+0.0343j,  0.2823-0.1949j, -1.4427-0.7791j,  0.0281+0.4863j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1836-0.2006j, -0.1265-0.1890j,  0.1599+0.1347j,
          0.0744-0.1905j,  0.1836+0.2006j,  0.0000+0.0000j,  0.1765+0.0244j,
          0.1215-0.1701j, -0.0538-0.3040j,  0.1265+0.1890j, -0.1765-0.0244j,
          0.0000+0.0000j,  0.4325-0.5204j, -0.7731+0.4021j, -0.1599-0.1347j,
         -0.1215+0.1701j, -0.4325+0.5204j,  0.0000+0.0000j, -0.1398+0.1720j,
         -0.0744+0.1905j,  0.0538+0.3040j,  0.7731-0.4021j,  0.1398-0.1720j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2846+0.0000j, -0.9841+0.0000j, -0.0470+0.0000j,
          0.3722+0.0000j, -0.2846+0.0000j,  0.0000+0.0000j, -0.8316+0.0000j,
          0.3416+0.0000j, -1.1662+0.0000j,  0.9841+0.0000j,  0.8316+0.0000j,
          0.0000+0.0000j, -1.8647+0.0000j,  3.6387+0.0000j,  0.0470+0.0000j,
         -0.3416+0.0000j,  1.8647+0.0000j,  0.0000+0.0000j,  0.1582+0.0000j,
         -0.3722+0.0000j,  1.1662+0.0000j, -3.6387+0.0000j, -0.1582+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1146-0.0334j,  0.6014+0.1697j, -0.0738-0.3082j,
          0.0311+0.2282j,  0.1146+0.0334j,  0.0000+0.0000j,  0.3257+0.5473j,
         -0.0622-0.1885j,  0.3221+0.6264j, -0.6014-0.1697j, -0.3257-0.5473j,
          0.0000+0.0000j,  0.8720+0.7925j, -1.1467-1.6200j,  0.0738+0.3082j,
          0.0622+0.1885j, -0.8720-0.7925j,  0.0000+0.0000j, -0.5628-0.2613j,
         -0.0311-0.2282j, -0.3221-0.6264j,  1.1467+1.6200j,  0.5628+0.2613j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2662+0.3273j,  0.3285-0.6547j, -0.2568-0.5832j,
          0.1150+0.8192j, -0.2662-0.3273j,  0.0000+0.0000j, -0.2833-0.4877j,
          0.4566+0.1790j, -0.5417-1.2393j, -0.3285+0.6547j,  0.2833+0.4877j,
          0.0000+0.0000j, -0.9582-1.5869j,  1.4222+3.8855j,  0.2568+0.5832j,
         -0.4566-0.1790j,  0.9582+1.5869j,  0.0000+0.0000j,  0.2708+0.7713j,
         -0.1150-0.8192j,  0.5417+1.2393j, -1.4222-3.8855j, -0.2708-0.7713j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0090-0.0727j,  0.5823-0.1140j, -0.2167-0.0681j,
          0.0269+0.2239j,  0.0090+0.0727j,  0.0000+0.0000j,  0.0607+0.1289j,
          0.0408+0.0446j,  0.0444+0.1510j, -0.5823+0.1140j, -0.0607-0.1289j,
          0.0000+0.0000j,  0.0955+0.2904j, -0.5551+0.6389j,  0.2167+0.0681j,
         -0.0408-0.0446j, -0.0955-0.2904j,  0.0000+0.0000j,  0.1218-0.2114j,
         -0.0269-0.2239j, -0.0444-0.1510j,  0.5551-0.6389j, -0.1218+0.2114j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1552+0.1628j,  0.1286-0.0479j, -0.0798+0.0503j,
          0.1298-0.0198j, -0.1552-0.1628j,  0.0000+0.0000j, -0.1011-0.1748j,
          0.0526+0.0970j, -0.2625-0.0382j, -0.1286+0.0479j,  0.1011+0.1748j,
          0.0000+0.0000j, -0.0773+0.1916j,  0.2044-0.2100j,  0.0798-0.0503j,
         -0.0526-0.0970j,  0.0773-0.1916j,  0.0000+0.0000j,  0.0680-0.1622j,
         -0.1298+0.0198j,  0.2625+0.0382j, -0.2044+0.2100j, -0.0680+0.1622j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1146+0.0334j,  0.6014-0.1697j, -0.0738+0.3082j,
          0.0311-0.2282j,  0.1146-0.0334j,  0.0000+0.0000j,  0.3257-0.5473j,
         -0.0622+0.1885j,  0.3221-0.6264j, -0.6014+0.1697j, -0.3257+0.5473j,
          0.0000+0.0000j,  0.8720-0.7925j, -1.1467+1.6200j,  0.0738-0.3082j,
          0.0622-0.1885j, -0.8720+0.7925j,  0.0000+0.0000j, -0.5628+0.2613j,
         -0.0311+0.2282j, -0.3221+0.6264j,  1.1467-1.6200j,  0.5628-0.2613j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1503+0.0000j, -0.1164+0.0000j,  0.0766+0.0000j,
         -0.2104+0.0000j, -0.1503+0.0000j,  0.0000+0.0000j, -0.1821+0.0000j,
          0.0120+0.0000j, -0.1595+0.0000j,  0.1164+0.0000j,  0.1821+0.0000j,
          0.0000+0.0000j,  0.0043+0.0000j,  0.2553+0.0000j, -0.0766+0.0000j,
         -0.0120+0.0000j, -0.0043+0.0000j,  0.0000+0.0000j, -0.0623+0.0000j,
          0.2104+0.0000j,  0.1595+0.0000j, -0.2553+0.0000j,  0.0623+0.0000j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1796-0.0140j,  0.2047+0.4922j,  0.0053+0.2221j,
         -0.1974+0.3775j,  0.1796+0.0140j,  0.0000+0.0000j,  0.4428-0.1806j,
         -0.0354+0.1543j,  0.6757-0.4050j, -0.2047-0.4922j, -0.4428+0.1806j,
          0.0000+0.0000j,  1.0367-0.2541j, -2.0550+0.8155j, -0.0053-0.2221j,
          0.0354-0.1543j, -1.0367+0.2541j,  0.0000+0.0000j, -0.5880+0.0310j,
          0.1974-0.3775j, -0.6757+0.4050j,  2.0550-0.8155j,  0.5880-0.0310j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.1570-0.0628j, -0.3817-0.0242j, -0.4255+0.2304j,
          0.1927-0.1556j, -0.1570+0.0628j,  0.0000+0.0000j, -0.1469-0.1839j,
         -0.0608-0.0340j, -0.3392+0.2455j,  0.3817+0.0242j,  0.1469+0.1839j,
          0.0000+0.0000j, -0.5774-0.1940j,  1.1725-0.8127j,  0.4255-0.2304j,
          0.0608+0.0340j,  0.5774+0.1940j,  0.0000+0.0000j, -0.0583-0.3857j,
         -0.1927+0.1556j,  0.3392-0.2455j, -1.1725+0.8127j,  0.0583+0.3857j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2685-0.0097j, -0.0300+0.2073j,  0.1046+0.1632j,
         -0.2543+0.2363j, -0.2685+0.0097j,  0.0000+0.0000j,  0.2619-0.3166j,
          0.1203-0.0460j,  0.1277-0.2882j,  0.0300-0.2073j, -0.2619+0.3166j,
          0.0000+0.0000j, -0.0974-0.6161j, -0.2637+1.2207j, -0.1046-0.1632j,
         -0.1203+0.0460j,  0.0974+0.6161j,  0.0000+0.0000j,  0.0434+0.3901j,
          0.2543-0.2363j, -0.1277+0.2882j,  0.2637-1.2207j, -0.0434-0.3901j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j,  0.2662-0.3273j,  0.3285+0.6547j, -0.2568+0.5832j,
          0.1150-0.8192j, -0.2662+0.3273j,  0.0000+0.0000j, -0.2833+0.4877j,
          0.4566-0.1790j, -0.5417+1.2393j, -0.3285-0.6547j,  0.2833-0.4877j,
          0.0000+0.0000j, -0.9582+1.5869j,  1.4222-3.8855j,  0.2568-0.5832j,
         -0.4566+0.1790j,  0.9582-1.5869j,  0.0000+0.0000j,  0.2708-0.7713j,
         -0.1150+0.8192j,  0.5417-1.2393j, -1.4222+3.8855j, -0.2708+0.7713j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.1796+0.0140j,  0.2047-0.4922j,  0.0053-0.2221j,
         -0.1974-0.3775j,  0.1796-0.0140j,  0.0000+0.0000j,  0.4428+0.1806j,
         -0.0354-0.1543j,  0.6757+0.4050j, -0.2047+0.4922j, -0.4428-0.1806j,
          0.0000+0.0000j,  1.0367+0.2541j, -2.0550-0.8155j, -0.0053+0.2221j,
          0.0354+0.1543j, -1.0367-0.2541j,  0.0000+0.0000j, -0.5880-0.0310j,
          0.1974+0.3775j, -0.6757-0.4050j,  2.0550+0.8155j,  0.5880+0.0310j,
          0.0000+0.0000j],
        [ 0.0000+0.0000j, -0.0741+0.0000j, -0.1869+0.0000j, -0.7082+0.0000j,
          0.6163+0.0000j,  0.0741+0.0000j,  0.0000+0.0000j, -0.1770+0.0000j,
          0.5158+0.0000j, -0.9383+0.0000j,  0.1869+0.0000j,  0.1770+0.0000j,
          0.0000+0.0000j, -1.7614+0.0000j,  2.8911+0.0000j,  0.7082+0.0000j,
         -0.5158+0.0000j,  1.7614+0.0000j,  0.0000+0.0000j,  0.7901+0.0000j,
         -0.6163+0.0000j,  0.9383+0.0000j, -2.8911+0.0000j, -0.7901+0.0000j,
          0.0000+0.0000j]], dtype=torch.complex128)

The max per-element difference (slow mode) is: 6.3536245618784655.</failure>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_pinv_hermitian_cpu_float64" time="0.117" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_pinv_singular_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_pinv_singular_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_qr_cpu_complex128" time="3.707" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_qr_cpu_float64" time="0.517" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_slogdet_cpu_complex128" time="0.747" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_slogdet_cpu_float64" time="0.132" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_solve_cpu_complex128" time="2.001" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_solve_cpu_float64" time="0.430" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_solve_ex_cpu_complex128" time="1.963" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_solve_ex_cpu_float64" time="0.417" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_solve_triangular_cpu_float64" time="5.438" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_svd_cpu_complex128" time="20.056" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_svd_cpu_float64" time="3.533" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_svdvals_cpu_complex128" time="1.396" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_svdvals_cpu_float64" time="0.264" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_vander_cpu_complex128" time="0.582" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_vander_cpu_float64" time="0.116" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_vecdot_cpu_float64" time="0.625" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_vector_norm_cpu_complex128" time="7.209" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linalg_vector_norm_cpu_float64" time="1.703" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linspace_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_linspace_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log10_cpu_complex128" time="0.154" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log10_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log1p_cpu_complex128" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log1p_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log2_cpu_complex128" time="0.119" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log2_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log_cpu_complex128" time="0.149" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log_normal_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log_softmax_cpu_float64" time="0.073" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log_softmax_with_dtype_cpu_complex128" time="0.327" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_log_softmax_with_dtype_cpu_float64" time="0.051" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logaddexp2_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logaddexp_cpu_complex128" time="1.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logaddexp_cpu_float64" time="0.161" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logcumsumexp_cpu_complex128" time="0.425" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logcumsumexp_cpu_float64" time="0.106" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logdet_cpu_complex128" time="0.717" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logdet_cpu_float64" time="0.128" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_and_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_and_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_not_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_not_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_or_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_or_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_xor_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logical_xor_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logit_cpu_float64" time="0.047" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logspace_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logspace_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_logsumexp_cpu_float64" time="0.924" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_long_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_long_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lt_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lu_cpu_float64" time="0.943" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lu_solve_cpu_float64" time="1.629" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lu_unpack_cpu_complex128" time="0.960" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_lu_unpack_cpu_float64" time="0.180" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mH_cpu_complex128" time="0.221" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mH_cpu_float64" time="0.034" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mT_cpu_complex128" time="0.170" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mT_cpu_float64" time="0.051" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_amax_cpu_float64" time="0.771" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_amin_cpu_float64" time="0.727" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_argmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_argmin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_cumprod_cpu_complex128" time="1.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_cumprod_cpu_float64" time="0.211" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_cumsum_cpu_complex128" time="0.895" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_cumsum_cpu_float64" time="0.253" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_fill_cpu_complex128" time="0.491" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_fill_cpu_float64" time="0.076" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_log_softmax_cpu_float64" time="0.338" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_logaddexp_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_logsumexp_cpu_float64" time="0.879" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_mean_cpu_complex128" time="4.991" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_mean_cpu_float64" time="0.876" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_median_cpu_float64" time="0.191" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_norm_cpu_float64" time="4.301" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_normalize_cpu_complex128" time="2.826" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_normalize_cpu_float64" time="0.604" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_prod_cpu_complex128" time="5.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_prod_cpu_float64" time="0.980" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_scatter_cpu_complex128" time="0.392" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_scatter_cpu_float64" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_select_cpu_complex128" time="0.385" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_select_cpu_float64" time="0.054" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_softmax_cpu_float64" time="0.336" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_softmin_cpu_float64" time="0.352" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_std_cpu_complex128" time="4.567" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_std_cpu_float64" time="0.760" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_sum_cpu_complex128" time="3.276" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_sum_cpu_float64" time="0.571" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_var_cpu_complex128" time="4.168" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_masked_var_cpu_float64" time="0.673" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_matmul_cpu_complex128" time="1.545" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_matmul_cpu_float64" time="0.300" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_matrix_exp_cpu_complex128" time="0.422" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_matrix_exp_cpu_float64" time="0.072" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_max_binary_cpu_float64" time="0.160" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_max_pool2d_with_indices_backward_cpu_float64" time="10.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_max_reduction_no_dim_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_max_reduction_with_dim_cpu_float64" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_maximum_cpu_float64" time="0.224" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mean_cpu_complex128" time="0.754" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mean_cpu_float64" time="0.130" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_median_cpu_float64" time="0.096" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_meshgrid_list_of_tensors_cpu_complex128" time="1.344" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_meshgrid_list_of_tensors_cpu_float64" time="0.283" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_meshgrid_variadic_tensors_cpu_complex128" time="1.393" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_meshgrid_variadic_tensors_cpu_float64" time="0.299" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_min_binary_cpu_float64" time="0.155" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_min_reduction_no_dim_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_min_reduction_with_dim_cpu_float64" time="0.038" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_minimum_cpu_float64" time="0.163" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mm_cpu_complex128" time="0.218" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mm_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mode_cpu_float64" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_movedim_cpu_complex128" time="0.098" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_movedim_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_msort_cpu_float64" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mul_cpu_complex128" time="0.889" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mul_cpu_float64" time="0.185" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_multinomial_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mv_cpu_complex128" time="0.093" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mv_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mvlgamma_mvlgamma_p_1_cpu_float64" time="0.110" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mvlgamma_mvlgamma_p_3_cpu_float64" time="0.168" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_mvlgamma_mvlgamma_p_5_cpu_float64" time="0.080" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nan_to_num_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nanmean_cpu_float64" time="0.269" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nanmedian_cpu_float64" time="0.132" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nanquantile_cpu_float64" time="1.186" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nansum_cpu_float64" time="0.228" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_narrow_copy_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_narrow_copy_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_narrow_cpu_complex128" time="0.347" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_narrow_cpu_float64" time="0.066" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_native_batch_norm_cpu_float64" time="0.291" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_native_dropout_backward_cpu_float64" time="0.089" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_native_layer_norm_cpu_float64" time="0.083" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ne_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ne_cpu_float64" time="0.015" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_neg_cpu_complex128" time="0.057" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_neg_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_empty_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_empty_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_empty_strided_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_empty_strided_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_full_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_full_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_ones_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_ones_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_zeros_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_new_zeros_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nextafter_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_adaptive_avg_pool1d_cpu_float64" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_adaptive_avg_pool2d_cpu_float64" time="0.075" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_adaptive_avg_pool3d_cpu_float64" time="0.130" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_adaptive_max_pool1d_cpu_float64" time="0.100" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_adaptive_max_pool2d_cpu_float64" time="0.224" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_adaptive_max_pool3d_cpu_float64" time="0.170" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_alpha_dropout_cpu_float64" time="0.537" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_avg_pool1d_cpu_float64" time="0.086" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_avg_pool2d_cpu_float64" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_avg_pool3d_cpu_float64" time="0.088" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_batch_norm_cpu_float64" time="0.441" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_bilinear_cpu_float64" time="1.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_binary_cross_entropy_cpu_float64" time="1.928" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_binary_cross_entropy_with_logits_cpu_float64" time="0.446" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_celu_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv1d_cpu_complex128" time="3.470" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv1d_cpu_float64" time="0.382" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv2d_cpu_complex128" time="11.901" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv2d_cpu_float64" time="1.244" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv_transpose1d_cpu_complex128" time="3.251" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv_transpose1d_cpu_float64" time="0.384" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv_transpose2d_cpu_complex128" time="4.284" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv_transpose2d_cpu_float64" time="0.453" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv_transpose3d_cpu_complex128" time="6.829" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_conv_transpose3d_cpu_float64" time="0.665" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_cosine_embedding_loss_cpu_float64" time="0.302" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_cosine_similarity_cpu_float64" time="0.401" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_cross_entropy_cpu_float64" time="0.302" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_ctc_loss_cpu_float64" time="0.015" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_dropout2d_cpu_float64" time="0.324" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_dropout3d_cpu_float64" time="0.255" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_dropout_cpu_float64" time="0.465" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_elu_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_embedding_bag_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_embedding_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_feature_alpha_dropout_with_train_cpu_float64" time="0.141" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_feature_alpha_dropout_without_train_cpu_complex128" time="1.581" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_feature_alpha_dropout_without_train_cpu_float64" time="0.366" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_fractional_max_pool2d_cpu_float64" time="0.675" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_fractional_max_pool3d_cpu_float64" time="1.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_gaussian_nll_loss_cpu_float64" time="13.408" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_gelu_cpu_float64" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_glu_cpu_float64" time="0.521" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_grid_sample_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_group_norm_cpu_float64" time="1.195" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_hardshrink_cpu_float64" time="0.056" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_hardsigmoid_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_hardswish_cpu_float64" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_hardtanh_cpu_float64" time="0.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_hinge_embedding_loss_cpu_float64" time="0.183" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_huber_loss_cpu_float64" time="0.155" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_instance_norm_cpu_float64" time="0.432" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_interpolate_area_cpu_float64" time="0.160" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_interpolate_bicubic_cpu_float64" time="0.139" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_interpolate_bilinear_cpu_float64" time="0.174" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_interpolate_linear_cpu_float64" time="0.199" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_interpolate_nearest_cpu_float64" time="0.127" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_interpolate_trilinear_cpu_float64" time="0.179" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_kl_div_cpu_float64" time="0.295" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:2951: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_l1_loss_cpu_complex128" time="0.660" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_l1_loss_cpu_float64" time="0.110" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_layer_norm_cpu_float64" time="0.243" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_leaky_relu_cpu_float64" time="0.067" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_linear_cpu_complex128" time="1.955" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_linear_cpu_float64" time="0.414" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_local_response_norm_cpu_float64" time="0.176" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_logsigmoid_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_margin_ranking_loss_cpu_float64" time="0.258" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_pool1d_cpu_float64" time="7.371" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_pool2d_cpu_float64" time="9.252" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_pool3d_cpu_float64" time="4.769" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_unpool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_unpool1d_grad_cpu_float64" time="0.189" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_unpool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_unpool2d_grad_cpu_float64" time="0.252" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_unpool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_max_unpool3d_grad_cpu_float64" time="0.151" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_mish_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_mse_loss_cpu_float64" time="0.115" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_multi_margin_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_multilabel_margin_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_multilabel_soft_margin_loss_cpu_float64" time="0.068" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_nll_loss_cpu_float64" time="0.532" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_normalize_cpu_complex128" time="0.881" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_normalize_cpu_float64" time="0.173" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_circular_cpu_complex128" time="0.571" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_circular_cpu_float64" time="0.138" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_constant_cpu_complex128" time="1.760" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_constant_cpu_float64" time="0.312" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_reflect_cpu_complex128" time="0.515" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_reflect_cpu_float64" time="0.124" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_replicate_cpu_complex128" time="0.596" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pad_replicate_cpu_float64" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pairwise_distance_cpu_complex128" time="0.666" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pairwise_distance_cpu_float64" time="0.146" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pdist_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op claims it doesn't support gradgrad. This is not verified.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Op claims it doesn't support gradgrad. This is not verified.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pixel_shuffle_cpu_complex128" time="0.226" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pixel_shuffle_cpu_float64" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pixel_unshuffle_cpu_complex128" time="0.165" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_pixel_unshuffle_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_poisson_nll_loss_cpu_float64" time="1.538" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_prelu_cpu_float64" time="0.400" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_relu6_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_relu_cpu_float64" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_rrelu_cpu_float64" time="0.121" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_scaled_dot_product_attention_cpu_float64" time="1.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_selu_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_silu_complex_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_silu_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_smooth_l1_loss_cpu_float64" time="0.187" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_soft_margin_loss_cpu_float64" time="0.052" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_softmin_cpu_float64" time="0.062" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_softmin_with_dtype_cpu_complex128" time="0.256" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_softmin_with_dtype_cpu_float64" time="0.096" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_softplus_cpu_float64" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_softshrink_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_softsign_cpu_complex128" time="0.213" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_softsign_cpu_float64" time="0.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_tanhshrink_cpu_complex128" time="0.179" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_tanhshrink_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_threshold_cpu_float64" time="0.044" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_triplet_margin_loss_cpu_complex128" time="1.550" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_triplet_margin_loss_cpu_float64" time="0.328" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_triplet_margin_with_distance_loss_cpu_complex128" time="1.587" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_triplet_margin_with_distance_loss_cpu_float64" time="0.344" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_unfold_cpu_complex128" time="6.522" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_unfold_cpu_float64" time="1.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_upsample_bilinear_cpu_float64" time="0.031" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4115: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nn_functional_upsample_nearest_cpu_float64" time="0.084" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:4059: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nonzero_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nonzero_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nonzero_static_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_nonzero_static_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_cpu_complex128" time="1.847" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_cpu_float64" time="0.536" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_fro_cpu_complex128" time="0.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_fro_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_inf_cpu_complex128" time="2.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_inf_cpu_float64" time="0.251" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_nuc_cpu_complex128" time="0.117" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_norm_nuc_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_normal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_normal_in_place_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_normal_in_place_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_normal_number_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ones_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ones_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ones_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ones_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ormqr_cpu_complex128" time="43.885" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ormqr_cpu_float64" time="10.607" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_outer_cpu_complex128" time="0.097" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_outer_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_pca_lowrank_cpu_float64" time="23.575" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_permute_cpu_complex128" time="0.186" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_permute_cpu_float64" time="0.035" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_pinverse_cpu_complex128" time="0.712" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_pinverse_cpu_float64" time="0.121" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_polar_cpu_float64" time="0.272" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_polygamma_polygamma_n_0_cpu_float64" time="0.118" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_polygamma_polygamma_n_1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_polygamma_polygamma_n_2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_polygamma_polygamma_n_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_polygamma_polygamma_n_4_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_positive_cpu_complex128" time="0.048" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_positive_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_pow_cpu_complex128" time="1.267" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_pow_cpu_float64" time="0.204" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_prod_cpu_complex128" time="2.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_prod_cpu_float64" time="0.427" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_put_cpu_complex128" time="1.494" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_put_cpu_float64" time="0.261" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_qr_cpu_complex128" time="3.812" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_qr_cpu_float64" time="0.494" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_quantile_cpu_float64" time="1.250" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rad2deg_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rand_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rand_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_randint_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_randint_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_randn_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_randn_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_randn_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_randn_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ravel_cpu_complex128" time="0.121" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_ravel_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_real_cpu_complex128" time="0.138" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_real_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_reciprocal_cpu_complex128" time="0.119" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_reciprocal_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_remainder_cpu_float64" time="0.179" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_renorm_cpu_complex128" time="0.350" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_renorm_cpu_float64" time="0.060" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_repeat_cpu_complex128" time="0.867" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_repeat_cpu_float64" time="0.194" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_repeat_interleave_cpu_complex128" time="0.206" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_repeat_interleave_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_reshape_as_cpu_complex128" time="0.135" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_reshape_as_cpu_float64" time="0.036" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_reshape_cpu_complex128" time="0.275" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_reshape_cpu_float64" time="0.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resize__cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resize__cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resize_as__cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resize_as__cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resolve_conj_cpu_complex128" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resolve_conj_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resolve_neg_cpu_complex128" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_resolve_neg_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_roll_cpu_complex128" time="0.578" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_roll_cpu_float64" time="0.147" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rot90_cpu_complex128" time="1.574" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rot90_cpu_float64" time="0.217" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_round_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_round_decimals_0_cpu_float64" time="0.035" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_round_decimals_3_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_round_decimals_neg_3_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rsqrt_cpu_complex128" time="0.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rsqrt_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rsub_cpu_complex128" time="0.833" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_rsub_cpu_float64" time="0.209" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scalar_tensor_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scalar_tensor_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_add_cpu_complex128" time="0.505" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_add_cpu_float64" time="0.155" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_cpu_complex128" time="0.644" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_cpu_float64" time="0.107" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_reduce_amax_cpu_float64" time="0.407" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_reduce_amin_cpu_float64" time="0.368" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_reduce_mean_cpu_float64" time="0.384" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_reduce_prod_cpu_float64" time="0.860" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_scatter_reduce_sum_cpu_float64" time="0.331" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_searchsorted_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_select_cpu_complex128" time="0.202" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_select_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_select_scatter_cpu_float64" time="0.120" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sgn_cpu_complex128" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sgn_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_short_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_short_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sigmoid_cpu_complex128" time="0.104" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sigmoid_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sign_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_bartlett_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_blackman_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_cosine_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_exponential_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_gaussian_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_general_cosine_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_general_hamming_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_hamming_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_hann_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_kaiser_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signal_windows_nuttall_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_signbit_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sin_cpu_complex128" time="0.084" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sin_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sinc_cpu_complex128" time="0.204" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sinc_cpu_float64" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sinh_cpu_complex128" time="0.068" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sinh_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_slice_cpu_complex128" time="0.462" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_slice_cpu_float64" time="0.073" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_slice_scatter_cpu_float64" time="0.253" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_softmax_cpu_float64" time="0.112" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_softmax_with_dtype_cpu_complex128" time="0.246" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_softmax_with_dtype_cpu_float64" time="0.075" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sort_cpu_float64" time="0.456" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sparse_mm_reduce_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sparse_sampled_addmm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sparse_sampled_addmm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_airy_ai_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_bessel_j0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_bessel_j1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_bessel_y0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_bessel_y1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_chebyshev_polynomial_t_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_chebyshev_polynomial_u_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_chebyshev_polynomial_v_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_chebyshev_polynomial_w_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_entr_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_erfcx_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_hermite_polynomial_h_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_hermite_polynomial_he_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_i0e_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_i1_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_i1e_cpu_float64" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_laguerre_polynomial_l_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_legendre_polynomial_p_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_log_ndtr_cpu_float64" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_modified_bessel_i0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_modified_bessel_i1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_modified_bessel_k0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_modified_bessel_k1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_ndtr_cpu_float64" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_ndtri_cpu_float64" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_polygamma_special_polygamma_n_0_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_scaled_modified_bessel_k0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_scaled_modified_bessel_k1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_shifted_chebyshev_polynomial_t_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_shifted_chebyshev_polynomial_u_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_shifted_chebyshev_polynomial_v_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_shifted_chebyshev_polynomial_w_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_spherical_bessel_j0_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_xlog1py_cpu_float64" time="0.173" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_special_zeta_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_split_cpu_complex128" time="0.153" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_split_cpu_float64" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_split_list_args_cpu_complex128" time="0.259" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_split_list_args_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_split_with_sizes_cpu_complex128" time="0.324" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_split_with_sizes_cpu_float64" time="0.082" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sqrt_cpu_complex128" time="0.051" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sqrt_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_square_cpu_complex128" time="0.124" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_square_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_squeeze_cpu_complex128" time="0.244" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_squeeze_cpu_float64" time="0.083" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_squeeze_multiple_cpu_complex128" time="0.233" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_squeeze_multiple_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_stack_cpu_complex128" time="0.968" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_stack_cpu_float64" time="0.159" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_cpu_complex128" time="0.465" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_cpu_float64" time="0.147" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_mean_cpu_complex128" time="0.752" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_mean_cpu_float64" time="0.198" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_mean_unbiased_cpu_complex128" time="0.142" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_mean_unbiased_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_unbiased_cpu_complex128" time="0.093" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_std_unbiased_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_stft_cpu_complex128" time="0.810" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_stft_cpu_float64" time="0.182" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sub_cpu_complex128" time="1.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sub_cpu_float64" time="0.204" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sum_cpu_complex128" time="0.663" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sum_cpu_float64" time="0.121" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sum_to_size_cpu_complex128" time="0.545" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_sum_to_size_cpu_float64" time="0.128" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_svd_cpu_complex128" time="23.322" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_svd_cpu_float64" time="4.365" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_svd_lowrank_cpu_float64" time="33.693" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_t_cpu_complex128" time="0.124" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_t_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_take_along_dim_cpu_complex128" time="0.283" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_take_along_dim_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_take_cpu_complex128" time="0.411" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_take_cpu_float64" time="0.098" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tan_cpu_complex128" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tan_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tanh_cpu_complex128" time="0.053" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tanh_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tensor_split_cpu_complex128" time="1.183" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tensor_split_cpu_float64" time="0.149" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tensordot_cpu_complex128" time="0.262" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tensordot_cpu_float64" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tile_cpu_complex128" time="0.979" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tile_cpu_float64" time="0.253" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_to_cpu_complex128" time="0.953" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_to_cpu_float64" time="0.230" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_to_sparse_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_to_sparse_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_topk_cpu_float64" time="0.105" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_trace_cpu_complex128" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_trace_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_transpose_cpu_complex128" time="0.341" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_transpose_cpu_float64" time="0.055" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_trapezoid_cpu_complex128" time="1.210" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_trapezoid_cpu_float64" time="0.194" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_trapz_cpu_complex128" time="1.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_trapz_cpu_float64" time="0.184" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_triangular_solve_cpu_complex128" time="1.620" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_triangular_solve_cpu_float64" time="0.293" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tril_cpu_complex128" time="0.332" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_tril_cpu_float64" time="0.091" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_triu_cpu_complex128" time="0.465" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_triu_cpu_float64" time="0.093" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_true_divide_cpu_complex128" time="1.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_true_divide_cpu_float64" time="0.174" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_trunc_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unbind_cpu_complex128" time="0.668" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unbind_cpu_float64" time="0.192" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unflatten_cpu_complex128" time="0.344" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unflatten_cpu_float64" time="0.105" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unfold_copy_cpu_complex128" time="1.119" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unfold_copy_cpu_float64" time="0.196" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unfold_cpu_complex128" time="0.985" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unfold_cpu_float64" time="0.151" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_uniform_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_uniform_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unique_consecutive_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unique_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unsafe_split_cpu_complex128" time="0.123" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unsafe_split_cpu_float64" time="0.028" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unsqueeze_cpu_complex128" time="0.356" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_unsqueeze_cpu_float64" time="0.094" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_cpu_complex128" time="0.448" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_cpu_float64" time="0.132" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_mean_cpu_complex128" time="0.777" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_mean_cpu_float64" time="0.134" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_mean_unbiased_cpu_complex128" time="0.134" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_mean_unbiased_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_unbiased_cpu_complex128" time="0.087" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_var_unbiased_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_vdot_cpu_complex128" time="0.171" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_vdot_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_view_as_complex_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_view_as_cpu_complex128" time="0.164" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_view_as_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_view_as_real_cpu_complex128" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_view_copy_cpu_float64" time="0.055" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_view_cpu_complex128" time="0.270" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_view_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_vsplit_cpu_complex128" time="0.181" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_vsplit_cpu_float64" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_vstack_cpu_complex128" time="0.376" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_vstack_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_where_cpu_complex128" time="0.585" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_where_cpu_float64" time="0.156" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_xlogy_cpu_float64" time="0.224" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_zero__cpu_complex128" time="0.119" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_zero__cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_zeros_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_zeros_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_zeros_like_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_fn_gradgrad_zeros_like_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:54: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_H_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_H_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_T_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_T_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___getitem___cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___getitem___cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___radd___cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___radd___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rdiv___cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rdiv___cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rmatmul___cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rmatmul___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rmod___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rmul___cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rmul___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rpow___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rpow___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rsub___cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad___rsub___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad__native_batch_norm_legit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad__segment_reduce_lengths_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad__segment_reduce_offsets_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad__softmax_backward_data_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad__upsample_bilinear2d_aa_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_abs_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="In-place abs not supported for complex tensors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: In-place abs not supported for complex tensors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_abs_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_acos_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_acos_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_acosh_cpu_complex128" time="0.001" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_acosh_cpu_float64" time="0.001" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_add_cpu_complex128" time="0.115" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_add_cpu_float64" time="0.024" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addbmm_cpu_complex128" time="0.121" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addbmm_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addcdiv_cpu_complex128" time="0.150" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addcdiv_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addcmul_cpu_complex128" time="0.145" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addcmul_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addmm_cpu_complex128" time="0.076" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addmm_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addmm_decomposed_cpu_complex128" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addmm_decomposed_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addmv_cpu_complex128" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addmv_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addr_cpu_complex128" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_addr_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_all_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_all_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_allclose_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_allclose_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_amax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_amin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_aminmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_angle_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_angle_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_any_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_any_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_arange_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_argmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_argmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_argsort_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_argwhere_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_argwhere_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_as_strided_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_as_strided_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_as_strided_partial_views_cpu_complex128" time="0.014" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_as_strided_partial_views_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_as_strided_scatter_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_as_strided_scatter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_asin_cpu_complex128" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_asin_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_asinh_cpu_complex128" time="0.002" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_asinh_cpu_float64" time="0.001" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atan2_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atan_cpu_complex128" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atan_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atanh_cpu_complex128" time="0.001" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atanh_cpu_float64" time="0.001" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atleast_1d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atleast_1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atleast_2d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atleast_2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atleast_3d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_atleast_3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_baddbmm_cpu_complex128" time="0.131" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_baddbmm_cpu_float64" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bernoulli_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bfloat16_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bfloat16_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_block_diag_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_block_diag_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bmm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bmm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bool_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bool_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_broadcast_tensors_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_broadcast_tensors_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_broadcast_to_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_broadcast_to_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_bucketize_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_byte_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_byte_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cartesian_prod_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cartesian_prod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cat_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cat_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cauchy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cdist_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cdouble_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cdouble_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ceil_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cfloat_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cfloat_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_chalf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_chalf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_char_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_char_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cholesky_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cholesky_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cholesky_inverse_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cholesky_inverse_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cholesky_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cholesky_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_chunk_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_chunk_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_clamp_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_clamp_max_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_clamp_min_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_clone_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_clone_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_column_stack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_column_stack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_combinations_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_combinations_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_complex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_conj_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_conj_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_conj_physical_cpu_complex128" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_conj_physical_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_constant_pad_nd_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_constant_pad_nd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_contiguous_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_contiguous_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_copysign_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_corrcoef_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_corrcoef_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cos_cpu_complex128" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cos_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cosh_cpu_complex128" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cosh_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_count_nonzero_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_count_nonzero_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cov_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cov_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cross_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cross_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cummax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cummin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cumprod_cpu_complex128" time="6.589" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cumprod_cpu_float64" time="1.040" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cumsum_cpu_complex128" time="0.056" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cumsum_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cumulative_trapezoid_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_cumulative_trapezoid_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_deg2rad_cpu_float64" time="0.006" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diag_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diag_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diag_embed_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diag_embed_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagflat_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagflat_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagonal_copy_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagonal_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagonal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagonal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagonal_scatter_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diagonal_scatter_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diff_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_diff_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_digamma_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dist_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dist_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_div_floor_rounding_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_div_no_rounding_mode_cpu_complex128" time="0.091" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_div_no_rounding_mode_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_div_trunc_rounding_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dot_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_double_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_double_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dsplit_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dsplit_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dstack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_dstack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_einsum_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_einsum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_empty_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_empty_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_empty_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_empty_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_empty_permuted_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_empty_permuted_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_eq_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_eq_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_equal_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_equal_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_erf_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_erfc_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_erfinv_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_exp2_cpu_complex128" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_exp2_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_exp_cpu_complex128" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_exp_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_expand_as_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_expand_as_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_expand_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_expand_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_expm1_cpu_complex128" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_expm1_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_exponential_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_eye_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_eye_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fft2_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fft2_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fft_cpu_complex128" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fftn_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fftn_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fftshift_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_fftshift_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_hfft2_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_hfft2_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_hfft_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_hfft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_hfftn_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_hfftn_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifft2_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifft2_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifft_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifft_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifftn_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifftshift_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ifftshift_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ihfft2_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ihfft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_ihfftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_irfft2_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_irfft2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_irfft_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_irfft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_irfftn_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_irfftn_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_rfft2_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_rfft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fft_rfftn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fill_cpu_complex128" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fill_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_flatten_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_flatten_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_flip_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_flip_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fliplr_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fliplr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_flipud_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_flipud_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_float_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_float_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_float_power_cpu_complex128" time="0.112" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_float_power_cpu_float64" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_floor_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_floor_divide_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_fmod_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_frac_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_frexp_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_full_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_full_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_full_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_full_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_gather_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_gather_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ge_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_geometric_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_geqrf_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_geqrf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_gradient_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_gradient_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_grid_sampler_2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_gt_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_half_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_half_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_heaviside_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_histc_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_histogram_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_histogramdd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_hsplit_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_hsplit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_hstack_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_hstack_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_hypot_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_i0_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_igamma_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_igammac_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_imag_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_add_cpu_complex128" time="0.148" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_add_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_copy_cpu_complex128" time="0.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_copy_cpu_float64" time="0.012" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_fill_cpu_complex128" time="0.082" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_fill_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_put_cpu_complex128" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_put_cpu_float64" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_reduce_cpu_float64" time="0.127" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_select_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_index_select_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_inner_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_inner_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_int_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_int_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isclose_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isclose_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isfinite_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isfinite_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isinf_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isinf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isnan_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isnan_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isneginf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isposinf_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isreal_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_isreal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_istft_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_2inputs_2outputs_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_2inputs_2outputs_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_4inputs_with_extra_args_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_4inputs_with_extra_args_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_binary_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_binary_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_binary_return_by_ref_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_binary_return_by_ref_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_unary_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_jiterator_unary_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_kron_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_kron_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_kthvalue_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ldexp_cpu_complex128" time="0.002" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ldexp_cpu_float64" time="0.002" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_le_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lerp_cpu_complex128" time="0.257" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lerp_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lgamma_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cholesky_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cholesky_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cholesky_ex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cholesky_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cond_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cond_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cross_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_cross_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_det_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_det_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_det_singular_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_det_singular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_diagonal_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_diagonal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eig_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eig_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eigh_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eigh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eigvals_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eigvals_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eigvalsh_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_eigvalsh_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_householder_product_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_householder_product_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_inv_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_inv_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_inv_ex_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_inv_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_ldl_factor_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_ldl_factor_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_ldl_factor_ex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_ldl_factor_ex_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_ldl_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_ldl_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lstsq_cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lstsq_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lstsq_grad_oriented_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lstsq_grad_oriented_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_factor_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_factor_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_factor_ex_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_factor_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_lu_solve_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_norm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_power_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_power_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_rank_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_rank_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_rank_hermitian_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_matrix_rank_hermitian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_multi_dot_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_multi_dot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_norm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_norm_subgradients_at_zero_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_norm_subgradients_at_zero_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_pinv_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_pinv_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_pinv_hermitian_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_pinv_hermitian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_pinv_singular_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_pinv_singular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_qr_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_qr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_slogdet_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_slogdet_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_solve_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_solve_ex_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_solve_ex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_solve_triangular_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_solve_triangular_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_svd_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_svd_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_svdvals_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_svdvals_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_vander_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_vander_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_vecdot_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_vecdot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_vector_norm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linalg_vector_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linspace_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_linspace_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log10_cpu_complex128" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log10_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log1p_cpu_complex128" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log1p_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log2_cpu_complex128" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log2_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log_cpu_complex128" time="0.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log_normal_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log_softmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log_softmax_with_dtype_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_log_softmax_with_dtype_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logaddexp2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logaddexp_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logaddexp_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logcumsumexp_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logcumsumexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logdet_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logdet_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_and_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_and_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_not_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_not_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_or_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_or_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_xor_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logical_xor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logit_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logspace_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logspace_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_logsumexp_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_long_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_long_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lt_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lu_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lu_solve_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lu_solve_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lu_unpack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_lu_unpack_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mH_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mH_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mT_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mT_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_amax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_amin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_argmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_argmin_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_cumprod_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_cumprod_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_cumsum_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_cumsum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_fill_cpu_complex128" time="0.075" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_fill_cpu_float64" time="0.021" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_log_softmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_logaddexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_logsumexp_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_mean_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_median_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_normalize_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_normalize_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_prod_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_prod_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_scatter_cpu_complex128" time="0.060" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_scatter_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_select_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_select_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_softmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_softmin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_std_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_std_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_sum_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_sum_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_var_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_masked_var_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_matmul_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_matmul_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_matrix_exp_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_matrix_exp_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_max_binary_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_max_pool2d_with_indices_backward_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_max_reduction_no_dim_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_max_reduction_with_dim_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_maximum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mean_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_median_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_meshgrid_list_of_tensors_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_meshgrid_list_of_tensors_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_meshgrid_variadic_tensors_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_meshgrid_variadic_tensors_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_min_binary_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_min_reduction_no_dim_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_min_reduction_with_dim_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_minimum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mm_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mode_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_movedim_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_movedim_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_msort_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mul_cpu_complex128" time="0.099" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mul_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_multinomial_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mv_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mv_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mvlgamma_mvlgamma_p_1_cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mvlgamma_mvlgamma_p_3_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_mvlgamma_mvlgamma_p_5_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nan_to_num_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nanmean_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nanmedian_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nanquantile_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nansum_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_narrow_copy_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_narrow_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_narrow_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_narrow_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_native_batch_norm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_native_dropout_backward_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_native_layer_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ne_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ne_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_neg_cpu_complex128" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_neg_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_empty_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_empty_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_empty_strided_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_empty_strided_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_full_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_full_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_ones_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_ones_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_zeros_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_new_zeros_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nextafter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_adaptive_avg_pool1d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_adaptive_avg_pool2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_adaptive_avg_pool3d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_adaptive_max_pool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_adaptive_max_pool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_adaptive_max_pool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_alpha_dropout_cpu_float64" time="0.181" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_avg_pool1d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_avg_pool2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_avg_pool3d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_batch_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_bilinear_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_binary_cross_entropy_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_binary_cross_entropy_with_logits_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_celu_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv1d_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv2d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv2d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv_transpose1d_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv_transpose1d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv_transpose2d_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv_transpose2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv_transpose3d_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_conv_transpose3d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_cosine_embedding_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_cosine_similarity_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_cross_entropy_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_ctc_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_dropout2d_cpu_float64" time="0.086" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_dropout3d_cpu_float64" time="0.086" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_dropout_cpu_float64" time="0.109" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_elu_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_embedding_bag_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_embedding_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_feature_alpha_dropout_with_train_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_feature_alpha_dropout_without_train_cpu_complex128" time="0.495" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_feature_alpha_dropout_without_train_cpu_float64" time="0.087" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_fractional_max_pool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_fractional_max_pool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_gaussian_nll_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_gelu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_glu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_grid_sample_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_group_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_hardshrink_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_hardsigmoid_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_hardswish_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_hardtanh_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_hinge_embedding_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_huber_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_instance_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_interpolate_area_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_interpolate_bicubic_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_interpolate_bilinear_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_interpolate_linear_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_interpolate_nearest_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_interpolate_trilinear_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_kl_div_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_l1_loss_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_l1_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_layer_norm_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_leaky_relu_cpu_float64" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_linear_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_linear_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_local_response_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_logsigmoid_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_margin_ranking_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_pool1d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_pool2d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_pool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_unpool1d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_unpool1d_grad_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_unpool2d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_unpool2d_grad_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_unpool3d_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_max_unpool3d_grad_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_mish_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_mse_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_multi_margin_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_multilabel_margin_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_multilabel_soft_margin_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_nll_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_normalize_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_normalize_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_circular_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_circular_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_constant_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_constant_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_reflect_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_reflect_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_replicate_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pad_replicate_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pairwise_distance_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pairwise_distance_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pdist_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pixel_shuffle_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pixel_shuffle_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pixel_unshuffle_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_pixel_unshuffle_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_poisson_nll_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_prelu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_relu6_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_relu_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_rrelu_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_scaled_dot_product_attention_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_selu_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_silu_complex_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_silu_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_smooth_l1_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_soft_margin_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_softmin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_softmin_with_dtype_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_softmin_with_dtype_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_softplus_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_softshrink_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_softsign_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_softsign_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_tanhshrink_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_tanhshrink_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_threshold_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_triplet_margin_loss_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_triplet_margin_loss_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_triplet_margin_with_distance_loss_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_triplet_margin_with_distance_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_unfold_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_unfold_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_upsample_bilinear_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nn_functional_upsample_nearest_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nonzero_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nonzero_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nonzero_static_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_nonzero_static_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_fro_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_fro_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_inf_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_inf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_nuc_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_norm_nuc_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_normal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_normal_in_place_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_normal_in_place_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_normal_number_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ones_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ones_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ones_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ones_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ormqr_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ormqr_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_outer_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_outer_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_pca_lowrank_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_permute_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_permute_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_pinverse_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_pinverse_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_polar_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_polygamma_polygamma_n_0_cpu_float64" time="0.023" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_polygamma_polygamma_n_1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_polygamma_polygamma_n_2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_polygamma_polygamma_n_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_polygamma_polygamma_n_4_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_positive_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_positive_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_pow_cpu_complex128" time="0.003" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_pow_cpu_float64" time="0.002" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_prod_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_prod_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_put_cpu_complex128" time="0.348" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_put_cpu_float64" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_qr_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_qr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_quantile_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rad2deg_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rand_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rand_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_randint_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_randint_like_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_randn_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_randn_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_randn_like_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_randn_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ravel_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_ravel_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_real_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_real_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_reciprocal_cpu_complex128" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_reciprocal_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_remainder_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_renorm_cpu_complex128" time="0.059" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_renorm_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_repeat_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_repeat_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_repeat_interleave_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_repeat_interleave_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_reshape_as_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_reshape_as_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_reshape_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_reshape_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resize__cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resize__cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resize_as__cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resize_as__cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resolve_conj_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resolve_conj_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resolve_neg_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_resolve_neg_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_roll_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_roll_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rot90_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rot90_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_round_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_round_decimals_0_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_round_decimals_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_round_decimals_neg_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rsqrt_cpu_complex128" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rsqrt_cpu_float64" time="0.008" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rsub_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_rsub_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scalar_tensor_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scalar_tensor_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_add_cpu_complex128" time="0.117" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_add_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_cpu_complex128" time="0.126" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_reduce_amax_cpu_float64" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_reduce_amin_cpu_float64" time="0.079" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_reduce_mean_cpu_float64" time="0.083" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_reduce_prod_cpu_float64" time="0.101" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_scatter_reduce_sum_cpu_float64" time="0.072" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_searchsorted_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_select_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_select_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_select_scatter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sgn_cpu_complex128" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sgn_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_short_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_short_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sigmoid_cpu_complex128" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sigmoid_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sign_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_bartlett_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_blackman_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_cosine_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_exponential_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_gaussian_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_general_cosine_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_general_hamming_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_hamming_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_hann_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_kaiser_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signal_windows_nuttall_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_signbit_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sin_cpu_complex128" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sin_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sinc_cpu_complex128" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sinc_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sinh_cpu_complex128" time="0.015" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sinh_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_slice_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_slice_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_slice_scatter_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_softmax_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_softmax_with_dtype_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_softmax_with_dtype_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sort_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sparse_mm_reduce_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sparse_sampled_addmm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="PyTorch is built without MKL support">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: PyTorch is built without MKL support</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sparse_sampled_addmm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="PyTorch is built without MKL support">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: PyTorch is built without MKL support</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_airy_ai_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_bessel_j0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_bessel_j1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_bessel_y0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_bessel_y1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_chebyshev_polynomial_t_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_chebyshev_polynomial_u_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_chebyshev_polynomial_v_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_chebyshev_polynomial_w_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_entr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_erfcx_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_hermite_polynomial_h_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_hermite_polynomial_he_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_i0e_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_i1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_i1e_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_laguerre_polynomial_l_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_legendre_polynomial_p_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_log_ndtr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_modified_bessel_i0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_modified_bessel_i1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_modified_bessel_k0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_modified_bessel_k1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_ndtr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_ndtri_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_polygamma_special_polygamma_n_0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_scaled_modified_bessel_k0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_scaled_modified_bessel_k1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_shifted_chebyshev_polynomial_t_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_shifted_chebyshev_polynomial_u_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_shifted_chebyshev_polynomial_v_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_shifted_chebyshev_polynomial_w_cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_spherical_bessel_j0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_xlog1py_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_special_zeta_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_split_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_split_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_split_list_args_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_split_list_args_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_split_with_sizes_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_split_with_sizes_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sqrt_cpu_complex128" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sqrt_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_square_cpu_complex128" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_square_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_squeeze_cpu_complex128" time="0.076" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_squeeze_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_squeeze_multiple_cpu_complex128" time="0.064" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_squeeze_multiple_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_stack_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_stack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_mean_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_mean_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_mean_unbiased_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_mean_unbiased_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_unbiased_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_std_unbiased_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_stft_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_stft_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sub_cpu_complex128" time="0.114" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sub_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sum_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sum_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sum_to_size_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_sum_to_size_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_svd_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_svd_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_svd_lowrank_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_t_cpu_complex128" time="0.055" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_t_cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_take_along_dim_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_take_along_dim_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_take_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_take_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tan_cpu_complex128" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tan_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tanh_cpu_complex128" time="0.016" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tanh_cpu_float64" time="0.004" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tensor_split_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tensor_split_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tensordot_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tensordot_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tile_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tile_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_to_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_to_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_to_sparse_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_to_sparse_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_topk_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_trace_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_trace_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_transpose_cpu_complex128" time="0.082" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_transpose_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_trapezoid_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_trapezoid_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_trapz_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_trapz_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_triangular_solve_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_triangular_solve_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tril_cpu_complex128" time="0.127" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_tril_cpu_float64" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_triu_cpu_complex128" time="0.140" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_triu_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_true_divide_cpu_complex128" time="0.111" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_true_divide_cpu_float64" time="0.022" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_trunc_cpu_float64" time="0.005" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unbind_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unbind_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unflatten_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unflatten_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unfold_copy_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unfold_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unfold_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unfold_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_uniform_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_uniform_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unique_consecutive_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unique_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unsafe_split_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unsafe_split_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unsqueeze_cpu_complex128" time="0.096" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_unsqueeze_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_mean_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_mean_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_mean_unbiased_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_mean_unbiased_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_unbiased_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_var_unbiased_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_vdot_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_vdot_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_view_as_complex_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_view_as_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_view_as_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_view_as_real_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_view_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_view_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_view_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_vsplit_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_vsplit_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_vstack_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_vstack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_where_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_where_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Op has no inplace variant!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Op has no inplace variant!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_xlogy_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_zero__cpu_complex128" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_zero__cpu_float64" time="0.009" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_zeros_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_zeros_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_zeros_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_grad_zeros_like_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:35: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_H_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_H_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_T_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_T_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___getitem___cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___getitem___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___radd___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___radd___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rdiv___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rdiv___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rmatmul___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rmatmul___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rmod___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rmul___cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rmul___cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rpow___cpu_complex128" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rpow___cpu_float64" time="0.000" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rsub___cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad___rsub___cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad__native_batch_norm_legit_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad__segment_reduce_lengths_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad__segment_reduce_offsets_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad__softmax_backward_data_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad__upsample_bilinear2d_aa_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_abs_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="In-place abs not supported for complex tensors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: In-place abs not supported for complex tensors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_abs_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_acos_cpu_complex128" time="0.198" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_acos_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_acosh_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_acosh_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_add_cpu_complex128" time="0.572" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_add_cpu_float64" time="0.111" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addbmm_cpu_complex128" time="0.816" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addbmm_cpu_float64" time="0.071" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addcdiv_cpu_complex128" time="1.050" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addcdiv_cpu_float64" time="0.180" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addcmul_cpu_complex128" time="0.944" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addcmul_cpu_float64" time="0.164" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addmm_cpu_complex128" time="0.495" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addmm_cpu_float64" time="0.032" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addmm_decomposed_cpu_complex128" time="0.529" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addmm_decomposed_cpu_float64" time="0.030" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addmv_cpu_complex128" time="0.319" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addmv_cpu_float64" time="0.105" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addr_cpu_complex128" time="0.365" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_addr_cpu_float64" time="0.068" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_all_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_all_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_allclose_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_allclose_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_amax_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_amin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_aminmax_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_angle_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_angle_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_any_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_any_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_arange_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_argmax_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_argmin_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_argsort_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_argwhere_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_argwhere_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_as_strided_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_as_strided_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Numerous errors">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Numerous errors</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_as_strided_partial_views_cpu_complex128" time="0.097" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_as_strided_partial_views_cpu_float64" time="0.037" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_as_strided_scatter_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_as_strided_scatter_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_asin_cpu_complex128" time="0.093" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_asin_cpu_float64" time="0.020" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_asinh_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_asinh_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atan2_cpu_float64" time="0.174" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atan_cpu_complex128" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atan_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atanh_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atanh_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atleast_1d_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atleast_1d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atleast_2d_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atleast_2d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atleast_3d_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_atleast_3d_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_baddbmm_cpu_complex128" time="0.872" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_baddbmm_cpu_float64" time="0.092" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bernoulli_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bfloat16_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bfloat16_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_block_diag_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_block_diag_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bmm_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bmm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bool_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bool_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_broadcast_tensors_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_broadcast_tensors_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_broadcast_to_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_broadcast_to_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_bucketize_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_byte_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_byte_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cartesian_prod_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cartesian_prod_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cat_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cat_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cauchy_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cdist_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cdouble_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cdouble_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ceil_cpu_float64" time="0.007" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cfloat_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cfloat_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_chalf_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_chalf_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_char_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_char_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cholesky_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cholesky_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cholesky_inverse_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cholesky_inverse_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cholesky_solve_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cholesky_solve_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_chunk_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_chunk_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_clamp_cpu_float64" time="0.149" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_clamp_max_cpu_float64" time="0.090" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_clamp_min_cpu_float64" time="0.100" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_clone_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_clone_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_column_stack_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_column_stack_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_combinations_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_combinations_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_complex_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_conj_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_conj_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_conj_physical_cpu_complex128" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_conj_physical_cpu_float64" time="0.014" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_constant_pad_nd_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_constant_pad_nd_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_contiguous_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_contiguous_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_copysign_cpu_float64" time="0.089" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_corrcoef_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_corrcoef_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cos_cpu_complex128" time="0.198" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cos_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cosh_cpu_complex128" time="0.158" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cosh_cpu_float64" time="0.029" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_count_nonzero_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_count_nonzero_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cov_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cov_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cross_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cross_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cummax_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cummin_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cumprod_cpu_complex128" time="114.653" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cumprod_cpu_float64" time="30.196" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cumsum_cpu_complex128" time="0.430" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cumsum_cpu_float64" time="0.135" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cumulative_trapezoid_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_cumulative_trapezoid_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_deg2rad_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diag_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diag_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diag_embed_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diag_embed_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagflat_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagflat_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagonal_copy_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagonal_copy_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagonal_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagonal_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagonal_scatter_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diagonal_scatter_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diff_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_diff_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_digamma_cpu_float64" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dist_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dist_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_div_floor_rounding_cpu_float64" time="0.150" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_div_no_rounding_mode_cpu_complex128" time="1.413" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_div_no_rounding_mode_cpu_float64" time="0.259" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_div_trunc_rounding_cpu_float64" time="0.155" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dot_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dot_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_double_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_double_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dsplit_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dsplit_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dstack_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_dstack_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_einsum_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_einsum_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_empty_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_empty_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_empty_like_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_empty_like_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_empty_permuted_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_empty_permuted_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_eq_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_eq_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_equal_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_equal_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_erf_cpu_float64" time="0.031" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_erfc_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_erfinv_cpu_float64" time="0.035" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_exp2_cpu_complex128" time="0.377" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_exp2_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_exp_cpu_complex128" time="0.341" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_exp_cpu_float64" time="0.062" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_expand_as_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_expand_as_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_expand_cpu_complex128" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_expand_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_expm1_cpu_complex128" time="0.187" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_expm1_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_exponential_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_eye_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_eye_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fft2_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fft2_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fft_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fft_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fftn_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fftn_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fftshift_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_fftshift_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_hfft2_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_hfft2_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_hfft_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_hfft_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_hfftn_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_hfftn_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifft2_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifft2_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifft_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifft_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifftn_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifftn_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifftshift_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ifftshift_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ihfft2_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ihfft_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_ihfftn_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_irfft2_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_irfft2_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_irfft_cpu_complex128" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_irfft_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_irfftn_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_irfftn_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_rfft2_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_rfft_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fft_rfftn_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fill_cpu_complex128" time="0.299" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fill_cpu_float64" time="0.074" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_flatten_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_flatten_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_flip_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_flip_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fliplr_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fliplr_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_flipud_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_flipud_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_float_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_float_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_float_power_cpu_complex128" time="1.980" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_float_power_cpu_float64" time="0.363" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_floor_cpu_float64" time="0.035" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_floor_divide_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fmax_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fmin_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_fmod_cpu_float64" time="0.231" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_frac_cpu_float64" time="0.025" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_frexp_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_full_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_full_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_full_like_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_full_like_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_gather_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_gather_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ge_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_geometric_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_geqrf_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_geqrf_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_gradient_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_gradient_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_grid_sampler_2d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_gt_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_half_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_half_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_heaviside_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_histc_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_histogram_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_histogramdd_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_hsplit_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_hsplit_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_hstack_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_hstack_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_hypot_cpu_float64" time="0.257" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_i0_cpu_float64" time="0.084" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_igamma_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_igammac_cpu_float64" time="0.013" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_imag_cpu_complex128" time="0.012" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_add_cpu_complex128" time="1.992" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_add_cpu_float64" time="0.371" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_copy_cpu_complex128" time="0.710" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_copy_cpu_float64" time="0.141" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_fill_cpu_complex128" time="0.969" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_fill_cpu_float64" time="0.194" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_put_cpu_complex128" time="0.948" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_put_cpu_float64" time="0.189" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_reduce_cpu_float64" time="2.039" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_select_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_index_select_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_inner_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_inner_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_int_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_int_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isclose_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isclose_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isfinite_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isfinite_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isin_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isinf_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isinf_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isnan_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isnan_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isneginf_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isposinf_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isreal_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_isreal_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_istft_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_2inputs_2outputs_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_2inputs_2outputs_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_4inputs_with_extra_args_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_4inputs_with_extra_args_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_binary_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_binary_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_binary_return_by_ref_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_binary_return_by_ref_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_unary_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_jiterator_unary_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_kron_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_kron_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_kthvalue_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ldexp_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ldexp_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_le_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lerp_cpu_complex128" time="3.918" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lerp_cpu_float64" time="0.448" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lgamma_cpu_float64" time="0.075" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cholesky_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cholesky_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cholesky_ex_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cholesky_ex_cpu_float64" time="0.013" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cond_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cond_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cross_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_cross_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_det_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_det_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_det_singular_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_det_singular_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_diagonal_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_diagonal_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eig_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eig_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eigh_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eigh_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eigvals_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eigvals_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eigvalsh_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_eigvalsh_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_householder_product_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_householder_product_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_inv_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_inv_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_inv_ex_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_inv_ex_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_ldl_factor_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_ldl_factor_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_ldl_factor_ex_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_ldl_factor_ex_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_ldl_solve_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_ldl_solve_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lstsq_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lstsq_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lstsq_grad_oriented_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lstsq_grad_oriented_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_factor_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_factor_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_factor_ex_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_factor_ex_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_solve_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_lu_solve_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_norm_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_norm_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_power_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_power_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_rank_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_rank_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_rank_hermitian_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_matrix_rank_hermitian_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_multi_dot_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_multi_dot_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_norm_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_norm_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_norm_subgradients_at_zero_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_norm_subgradients_at_zero_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_pinv_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_pinv_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_pinv_hermitian_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_pinv_hermitian_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_pinv_singular_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_pinv_singular_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_qr_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_qr_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_slogdet_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_slogdet_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_solve_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_solve_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_solve_ex_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_solve_ex_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_solve_triangular_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_solve_triangular_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_svd_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_svd_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_svdvals_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_svdvals_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_vander_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_vander_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_vecdot_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_vecdot_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_vector_norm_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linalg_vector_norm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linspace_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_linspace_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log10_cpu_complex128" time="0.336" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log10_cpu_float64" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log1p_cpu_complex128" time="0.163" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log1p_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log2_cpu_complex128" time="0.355" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log2_cpu_float64" time="0.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log_cpu_complex128" time="0.320" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log_cpu_float64" time="0.058" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log_normal_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log_softmax_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log_softmax_with_dtype_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_log_softmax_with_dtype_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logaddexp2_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logaddexp_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logaddexp_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logcumsumexp_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logcumsumexp_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logdet_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logdet_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_and_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_and_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_not_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_not_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_or_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_or_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_xor_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logical_xor_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logit_cpu_float64" time="0.102" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logspace_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logspace_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_logsumexp_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_long_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_long_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lt_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lu_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lu_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lu_solve_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lu_solve_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lu_unpack_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_lu_unpack_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mH_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mH_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mT_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mT_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_amax_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_amin_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_argmax_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_argmin_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_cumprod_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_cumprod_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_cumsum_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_cumsum_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_fill_cpu_complex128" time="0.867" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_fill_cpu_float64" time="0.171" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_log_softmax_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_logaddexp_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_logsumexp_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_mean_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_mean_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_median_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_norm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_normalize_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_normalize_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_prod_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_prod_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_scatter_cpu_complex128" time="0.711" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_scatter_cpu_float64" time="0.211" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_select_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_select_cpu_float64" time="0.014" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_softmax_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_softmin_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_std_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_std_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_sum_cpu_complex128" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_sum_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_var_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_masked_var_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_matmul_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_matmul_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_matrix_exp_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_matrix_exp_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_max_binary_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_max_pool2d_with_indices_backward_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_max_reduction_no_dim_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_max_reduction_with_dim_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_maximum_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mean_cpu_complex128" time="0.010" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mean_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_median_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_meshgrid_list_of_tensors_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_meshgrid_list_of_tensors_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_meshgrid_variadic_tensors_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_meshgrid_variadic_tensors_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_min_binary_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_min_reduction_no_dim_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_min_reduction_with_dim_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_minimum_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mm_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mm_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mode_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_movedim_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_movedim_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_msort_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mul_cpu_complex128" time="1.286" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mul_cpu_float64" time="0.258" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_multinomial_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mv_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mv_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mvlgamma_mvlgamma_p_1_cpu_float64" time="0.323" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mvlgamma_mvlgamma_p_3_cpu_float64" time="0.244" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_mvlgamma_mvlgamma_p_5_cpu_float64" time="0.253" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nan_to_num_cpu_float64" time="0.066" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nanmean_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nanmedian_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nanquantile_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nansum_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_narrow_copy_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_narrow_copy_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_narrow_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_narrow_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_native_batch_norm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_native_dropout_backward_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_native_layer_norm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ne_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ne_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_neg_cpu_complex128" time="0.113" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_neg_cpu_float64" time="0.037" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_empty_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_empty_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_empty_strided_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_empty_strided_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_full_cpu_complex128" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_full_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_ones_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_ones_cpu_float64" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_zeros_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_new_zeros_cpu_float64" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nextafter_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_adaptive_avg_pool1d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_adaptive_avg_pool2d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_adaptive_avg_pool3d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_adaptive_max_pool1d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_adaptive_max_pool2d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_adaptive_max_pool3d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_alpha_dropout_cpu_float64" time="1.532" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_avg_pool1d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_avg_pool2d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_avg_pool3d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_batch_norm_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_bilinear_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_binary_cross_entropy_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_binary_cross_entropy_with_logits_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_celu_cpu_float64" time="0.066" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv1d_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv1d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv2d_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv2d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv_transpose1d_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv_transpose1d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv_transpose2d_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv_transpose2d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv_transpose3d_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_conv_transpose3d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_cosine_embedding_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_cosine_similarity_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_cross_entropy_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_ctc_loss_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_dropout2d_cpu_float64" time="0.869" file="test_ops_gradients.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\torch\nn\functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
      </system-err>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_dropout3d_cpu_float64" time="0.869" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_dropout_cpu_float64" time="0.855" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_elu_cpu_float64" time="0.081" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_embedding_bag_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_embedding_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_feature_alpha_dropout_with_train_cpu_float64" time="0.357" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_feature_alpha_dropout_without_train_cpu_complex128" time="3.485" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_feature_alpha_dropout_without_train_cpu_float64" time="0.578" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_fractional_max_pool2d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_fractional_max_pool3d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_gaussian_nll_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_gelu_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_glu_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_grid_sample_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_group_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_hardshrink_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_hardsigmoid_cpu_float64" time="0.008" file="test_ops_gradients.py">
      <skipped type="pytest.xfail" message="" />
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_hardswish_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_hardtanh_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_hinge_embedding_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_huber_loss_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_instance_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_interpolate_area_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_interpolate_bicubic_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_interpolate_bilinear_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_interpolate_linear_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_interpolate_nearest_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_interpolate_trilinear_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_kl_div_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_l1_loss_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_l1_loss_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_layer_norm_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_leaky_relu_cpu_float64" time="0.140" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_linear_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_linear_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_local_response_norm_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_logsigmoid_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_margin_ranking_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_pool1d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_pool2d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_pool3d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_unpool1d_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_unpool1d_grad_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_unpool2d_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_unpool2d_grad_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_unpool3d_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_max_unpool3d_grad_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_mish_cpu_float64" time="0.076" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_mse_loss_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_multi_margin_loss_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_multilabel_margin_loss_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_multilabel_soft_margin_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_nll_loss_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_normalize_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_normalize_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_circular_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_circular_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_constant_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_constant_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_reflect_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_reflect_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_replicate_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pad_replicate_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pairwise_distance_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pairwise_distance_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pdist_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pixel_shuffle_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pixel_shuffle_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pixel_unshuffle_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_pixel_unshuffle_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_poisson_nll_loss_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_prelu_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_relu6_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_relu_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_rrelu_cpu_float64" time="0.183" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_scaled_dot_product_attention_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_selu_cpu_float64" time="0.049" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_silu_complex_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_silu_cpu_float64" time="0.061" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_smooth_l1_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_soft_margin_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_softmin_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_softmin_with_dtype_cpu_complex128" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_softmin_with_dtype_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_softplus_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_softshrink_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_softsign_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_softsign_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_tanhshrink_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_tanhshrink_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_threshold_cpu_float64" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_triplet_margin_loss_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_triplet_margin_loss_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_triplet_margin_with_distance_loss_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_triplet_margin_with_distance_loss_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_unfold_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_unfold_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_upsample_bilinear_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nn_functional_upsample_nearest_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nonzero_cpu_complex128" time="0.007" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nonzero_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nonzero_static_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_nonzero_static_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_fro_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_fro_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_inf_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_inf_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_nuc_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_norm_nuc_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_normal_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_normal_in_place_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_normal_in_place_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_normal_number_mean_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Gradients are incorrect!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Gradients are incorrect!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ones_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ones_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ones_like_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ones_like_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ormqr_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ormqr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_outer_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_outer_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_pca_lowrank_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_permute_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_permute_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_pinverse_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_pinverse_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_polar_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_polygamma_polygamma_n_0_cpu_float64" time="0.145" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_polygamma_polygamma_n_1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_polygamma_polygamma_n_2_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_polygamma_polygamma_n_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_polygamma_polygamma_n_4_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_positive_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_positive_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_pow_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_pow_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_prod_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_prod_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_put_cpu_complex128" time="2.984" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_put_cpu_float64" time="0.526" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_qr_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_qr_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_quantile_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rad2deg_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rand_like_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rand_like_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_randint_cpu_float64" time="0.006" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_randint_like_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_randn_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_randn_cpu_float64" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_randn_like_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_randn_like_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ravel_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_ravel_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_real_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_real_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_reciprocal_cpu_complex128" time="0.284" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_reciprocal_cpu_float64" time="0.046" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_remainder_cpu_float64" time="0.186" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_renorm_cpu_complex128" time="0.669" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_renorm_cpu_float64" time="0.099" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_repeat_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_repeat_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_repeat_interleave_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_repeat_interleave_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_reshape_as_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_reshape_as_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_reshape_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_reshape_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resize__cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resize__cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resize_as__cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resize_as__cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resolve_conj_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resolve_conj_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resolve_neg_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_resolve_neg_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_roll_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_roll_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rot90_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rot90_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_round_cpu_float64" time="0.011" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_round_decimals_0_cpu_float64" time="0.027" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_round_decimals_3_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_round_decimals_neg_3_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped!">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped!</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rsqrt_cpu_complex128" time="0.201" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rsqrt_cpu_float64" time="0.041" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rsub_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_rsub_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scalar_tensor_cpu_complex128" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scalar_tensor_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_add_cpu_complex128" time="0.894" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_add_cpu_float64" time="0.203" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_cpu_complex128" time="1.042" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_cpu_float64" time="0.223" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_reduce_amax_cpu_float64" time="0.757" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_reduce_amin_cpu_float64" time="0.674" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_reduce_mean_cpu_float64" time="0.647" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_reduce_prod_cpu_float64" time="1.199" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_scatter_reduce_sum_cpu_float64" time="0.577" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_searchsorted_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_select_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_select_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_select_scatter_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sgn_cpu_complex128" time="0.098" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sgn_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_short_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_short_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sigmoid_cpu_complex128" time="0.154" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sigmoid_cpu_float64" time="0.045" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sign_cpu_float64" time="0.010" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_bartlett_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_blackman_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_cosine_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_exponential_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_gaussian_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_general_cosine_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_general_hamming_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_hamming_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_hann_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_kaiser_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signal_windows_nuttall_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_signbit_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sin_cpu_complex128" time="0.081" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sin_cpu_float64" time="0.018" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sinc_cpu_complex128" time="0.256" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sinc_cpu_float64" time="0.043" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sinh_cpu_complex128" time="0.108" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sinh_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_slice_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_slice_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_slice_scatter_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_softmax_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_softmax_with_dtype_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_softmax_with_dtype_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sort_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sparse_mm_reduce_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sparse_sampled_addmm_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="PyTorch is built without MKL support">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: PyTorch is built without MKL support</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sparse_sampled_addmm_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="PyTorch is built without MKL support">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: PyTorch is built without MKL support</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_airy_ai_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_bessel_j0_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_bessel_j1_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_bessel_y0_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_bessel_y1_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_chebyshev_polynomial_t_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_chebyshev_polynomial_u_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_chebyshev_polynomial_v_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_chebyshev_polynomial_w_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_entr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_erfcx_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_hermite_polynomial_h_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_hermite_polynomial_he_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_i0e_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_i1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_i1e_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_laguerre_polynomial_l_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_legendre_polynomial_p_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_log_ndtr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_modified_bessel_i0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_modified_bessel_i1_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_modified_bessel_k0_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_modified_bessel_k1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_ndtr_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_ndtri_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_polygamma_special_polygamma_n_0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_scaled_modified_bessel_k0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_scaled_modified_bessel_k1_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_shifted_chebyshev_polynomial_t_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_shifted_chebyshev_polynomial_u_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_shifted_chebyshev_polynomial_v_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_shifted_chebyshev_polynomial_w_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipping - testing takes an unreasonably long time, #79528">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipping - testing takes an unreasonably long time, #79528</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_spherical_bessel_j0_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_xlog1py_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_special_zeta_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_split_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_split_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_split_list_args_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_split_list_args_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_split_with_sizes_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_split_with_sizes_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sqrt_cpu_complex128" time="0.069" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sqrt_cpu_float64" time="0.019" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_square_cpu_complex128" time="0.177" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_square_cpu_float64" time="0.035" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_squeeze_cpu_complex128" time="0.395" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_squeeze_cpu_float64" time="0.070" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_squeeze_multiple_cpu_complex128" time="0.271" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_squeeze_multiple_cpu_float64" time="0.063" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_stack_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_stack_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_mean_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_mean_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_mean_unbiased_cpu_complex128" time="0.005" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_mean_unbiased_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_unbiased_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_std_unbiased_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_stft_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_stft_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sub_cpu_complex128" time="0.696" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sub_cpu_float64" time="0.118" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sum_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sum_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sum_to_size_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_sum_to_size_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_svd_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_svd_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_svd_lowrank_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_t_cpu_complex128" time="0.137" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_t_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_take_along_dim_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_take_along_dim_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_take_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_take_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tan_cpu_complex128" time="0.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tan_cpu_float64" time="0.017" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tanh_cpu_complex128" time="0.087" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tanh_cpu_float64" time="0.033" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tensor_split_cpu_complex128" time="0.009" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tensor_split_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tensordot_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tensordot_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tile_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tile_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_to_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_to_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_to_sparse_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_to_sparse_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_topk_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_trace_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_trace_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_transpose_cpu_complex128" time="0.347" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_transpose_cpu_float64" time="0.080" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_trapezoid_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_trapezoid_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_trapz_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_trapz_cpu_float64" time="0.004" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_triangular_solve_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_triangular_solve_cpu_float64" time="0.028" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tril_cpu_complex128" time="0.472" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_tril_cpu_float64" time="0.140" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_triu_cpu_complex128" time="0.348" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_triu_cpu_float64" time="0.111" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_true_divide_cpu_complex128" time="0.648" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_true_divide_cpu_float64" time="0.141" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_trunc_cpu_float64" time="0.013" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unbind_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unbind_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unflatten_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unflatten_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unfold_copy_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unfold_copy_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unfold_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unfold_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_uniform_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_uniform_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unique_consecutive_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unique_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unsafe_split_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unsafe_split_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unsqueeze_cpu_complex128" time="0.451" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_unsqueeze_cpu_float64" time="0.065" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_mean_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_mean_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_mean_unbiased_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_mean_unbiased_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_unbiased_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_var_unbiased_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_vdot_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_vdot_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_view_as_complex_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_view_as_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_view_as_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_view_as_real_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_view_copy_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_view_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_view_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_vsplit_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_vsplit_cpu_float64" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_vstack_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_vstack_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_where_cpu_complex128" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_where_cpu_float64" time="0.001" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Operation does not support inplace autograd.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Operation does not support inplace autograd.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_xlogy_cpu_float64" time="0.107" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_zero__cpu_complex128" time="0.129" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_zero__cpu_float64" time="0.026" file="test_ops_gradients.py" />
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_zeros_cpu_complex128" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_zeros_cpu_float64" time="0.003" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_zeros_like_cpu_complex128" time="0.002" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
    <testcase classname="TestBwdGradientsCPU" name="test_inplace_gradgrad_zeros_like_cpu_float64" time="0.075" file="test_ops_gradients.py">
      <skipped type="pytest.skip" message="Skipped! Op doesn't support autograd for this dtype.">C:\Users\radekbarton\Projects\pytorch\test\test_ops_gradients.py:80: Skipped! Op doesn't support autograd for this dtype.</skipped>
    </testcase>
  </testsuite>
</testsuites>