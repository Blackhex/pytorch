<testsuites>
  <testsuite name="pytest" errors="0" failures="0" skipped="66" tests="840" time="33.251" timestamp="2023-04-06T22:02:39.474751" hostname="BartonTest">
    <testcase classname="TestBasicVitalSigns" name="test_basic_vitals" time="0.062" file="test_torch.py" />
    <testcase classname="TestBasicVitalSigns" name="test_basic_vitals_read_write" time="0.002" file="test_torch.py" />
    <testcase classname="TestBasicVitalSigns" name="test_dataloader_vitals" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_RNGState" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_RNGStateAliasing" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_RNG_after_pickle" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_Size" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_Size_iter" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_Size_scalar" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_add_meta_scalar" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_allow_tensor_metadata_change" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_apply" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_as_subclass" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_assert_async" time="0.315" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_backward_hooks_traverse" time="0.055" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_batch_norm_cpu_inference" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_bmm_multithreaded" time="0.986" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [1, 23, 12], which does not match the required output shape [1, 23, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [1, 23, 12], which does not match the required output shape [1, 0, 12]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [1, 23, 12], which does not match the required output shape [1, 0, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [1, 23, 12], which does not match the required output shape [0, 23, 12]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [1, 23, 12], which does not match the required output shape [0, 23, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [1, 23, 12], which does not match the required output shape [0, 0, 12]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [1, 23, 12], which does not match the required output shape [0, 0, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [10, 23, 12], which does not match the required output shape [10, 23, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [10, 23, 12], which does not match the required output shape [10, 0, 12]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [10, 23, 12], which does not match the required output shape [10, 0, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [10, 23, 12], which does not match the required output shape [0, 23, 12]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [10, 23, 12], which does not match the required output shape [0, 23, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [10, 23, 12], which does not match the required output shape [0, 0, 12]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8771: UserWarning: An output with one or more elements was resized since it had shape [10, 23, 12], which does not match the required output shape [0, 0, 0]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.bmm(b1, b2, out=res2)
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_boxMullerState" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_c10_layer_norm" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Pytorch is compiled without Caffe2">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7396: Pytorch is compiled without Caffe2</skipped>
    </testcase>
    <testcase classname="TestTorch" name="test_cat_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_check" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_chunk_neg_dim" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_conj_neg_tolist" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_contains" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_copy_broadcast" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_copy_dtypes" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_copy_float16" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_copy_many_to_one" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_copy_transpose" time="0.005" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7932: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\EmptyTensor.cpp:32.)
  x = torch.arange(100 * 100).reshape(100, 100).to(dtype=torch.complex32).t()
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_cuda_not_built" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_cummax_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_cummin_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_cumprod_neg_dim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_cumsum_neg_dim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_cxx_flags" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_dead_weak_ref" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_deepcopy_gradient" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_deepcopy_parameter" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_deterministic_flag" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_device" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_dir" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_doc" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_doc_template" time="0.024" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_dot_data_use" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_dtype_is_signed" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_element_size" time="0.003" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  byte = torch.ByteStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6115: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  char = torch.CharStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  short = torch.ShortStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6117: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  int = torch.IntStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  long = torch.LongStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6119: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  float = torch.FloatStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6120: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  double = torch.DoubleStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6121: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  bool = torch.BoolStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6122: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  bfloat16 = torch.BFloat16Storage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6123: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  complexfloat = torch.ComplexFloatStorage().element_size()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6124: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  complexdouble = torch.ComplexDoubleStorage().element_size()
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_empty_meta" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_empty_storage_view" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_equal" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_error_msg_type_translation" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_fill_diagonal" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_fix_weakref_no_leak" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_format_scalar_meta" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_from_buffer" time="0.010" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6496: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(torch.ByteStorage.from_buffer(a).tolist(), [1, 2, 3, 4])
c:\users\radekbarton\projects\pytorch\torch\storage.py:731: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return list(self)
c:\users\radekbarton\projects\pytorch\torch\storage.py:705: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return iter(map(lambda i: self[i], range(self.size())))
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6497: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  shorts = torch.ShortStorage.from_buffer(a, 'big' if sys.byteorder == 'little' else 'little')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6498: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(shorts.size(), 2)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6499: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(shorts.tolist(), [258, 772])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6500: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  ints = torch.IntStorage.from_buffer(a, 'little' if sys.byteorder == 'little' else 'big')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6501: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(ints.size(), 1)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6502: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(ints[0], 67305985)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6504: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  floats = torch.FloatStorage.from_buffer(f, 'big' if sys.byteorder == 'little' else 'little')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6505: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(floats.size(), 1)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6506: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(floats[0], 2.25)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6509: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  bools = torch.BoolStorage.from_buffer(f, 'big' if sys.byteorder == 'little' else 'little')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6510: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bools.size(), 8)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6511: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bools.tolist(), [False, True, True, True, True, True, True, True])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6512: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bools.type(), 'torch.BoolStorage')
c:\users\radekbarton\projects\pytorch\torch\storage.py:1015: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type not in ['cpu', 'cuda']:
c:\users\radekbarton\projects\pytorch\torch\storage.py:1018: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  module = torch if self.device.type == 'cpu' else torch.cuda
c:\users\radekbarton\projects\pytorch\torch\storage.py:1034: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return (cls_device == instance.device.type) and (cls.dtype == instance.dtype)
c:\users\radekbarton\projects\pytorch\torch\_utils.py:777: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6516: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  bools = torch.BoolStorage.from_buffer(f, 'big' if sys.byteorder == 'little' else 'little')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6517: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bools.size(), 19)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6520: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  bools = torch.BoolStorage.from_buffer(f, 'big' if sys.byteorder == 'little' else 'little')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6521: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bools.size(), 4)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6522: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bools.tolist(), [False, True, True, True])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6523: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  bytes = torch.ByteStorage.from_buffer(a)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6524: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bytes.nbytes(), 4)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6525: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bytes.tolist(), [1, 2, 3, 4])
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_from_file" time="0.030" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6837: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s1 = torch.FloatStorage.from_file(filename, True, size)
c:\users\radekbarton\projects\pytorch\torch\storage.py:955: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = cls(wrap_storage=untyped_storage)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6839: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s1.data_ptr(), torch.FloatTensor(s1).data_ptr())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6842: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s2 = torch.FloatStorage.from_file(filename, True, size)
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_gather_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_generator_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_has_internal_overlap" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_has_storage" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7793: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertIsNotNone(torch.tensor([]).storage())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7794: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertIsNotNone(torch.empty(0).storage())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7795: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertIsNotNone(torch.tensor([]).clone().storage())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7796: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertIsNotNone(torch.tensor([0, 0, 0]).nonzero().storage())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7797: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertIsNotNone(torch.tensor([]).new().storage())
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_index_add" time="0.048" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_index_add_all_dtypes" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_index_add_correctness" time="2.361" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_index_add_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_index_copy_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_index_fill_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_index_select_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_invalid_generator_raises" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_is_nonzero" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_is_same_size" time="0.004" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:5996: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\NestedTensorImpl.cpp:179.)
  nt1 = torch.nested.nested_tensor([torch.ones(2, 4), torch.ones(3, 4), torch.ones(5, 4)])
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_iter" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_kthvalue_neg_dim" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_logcumsumexp_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_manual_seed" time="0.012" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_map" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_map2" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_max_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_mean_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_median_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_memory_format" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_memory_format_contiguous_returns_same_tensor_if_already_satisfies" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_memory_format_empty" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_min_neg_dim" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_mode_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_multinomial_invalid_probs" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="FIXME: CUDA OOM error on Windows">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:8173: FIXME: CUDA OOM error on Windows</skipped>
    </testcase>
    <testcase classname="TestTorch" name="test_nanmedian_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_narrow_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_ndim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_new" time="0.005" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7190: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(x.new(y.storage()).data_ptr(), y.data_ptr())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7196: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertRaises(RuntimeError, lambda: x.new(z.storage()))
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_newaxis_numpy_comparison" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_newindex" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_no_cuda_monkeypatch" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_norm_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_normal_shape" time="0.015" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_numel" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_parallel_info" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_parsing_double" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_parsing_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_parsing_intlist" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_permute" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pickle" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pickle_dtype" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pickle_function" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pickle_parameter" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pickle_parameter_no_requires_grad" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pickle_size" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pin_memory" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_print" time="0.086" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_prod_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_pyobj_preserved" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_qengine" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_renorm_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_resurrected_weak_ref" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_reversed" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_scatter_neg_dim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_select_neg_dim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_set_flush_denormal" time="0.000" file="test_torch.py">
      <skipped type="pytest.skip" message="flush_denormal not supported">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7284: flush_denormal not supported</skipped>
    </testcase>
    <testcase classname="TestTorch" name="test_setting_real_imag_to_a_number" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_show_config" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_size_neg_dim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sizeof" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7154: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  sizeof_empty = torch.randn(0).storage().__sizeof__()
c:\users\radekbarton\projects\pytorch\torch\storage.py:721: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return super().__sizeof__() + self.nbytes()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7155: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  sizeof_10 = torch.randn(10).storage().__sizeof__()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7156: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  sizeof_100 = torch.randn(100).storage().__sizeof__()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7160: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  sizeof_empty = torch.randn(0).to(torch.uint8).storage().__sizeof__()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7161: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  sizeof_10 = torch.randn(10).to(torch.uint8).storage().__sizeof__()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7162: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  sizeof_100 = torch.randn(100).to(torch.uint8).storage().__sizeof__()
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_slice" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_slow_test" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:7317: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestTorch" name="test_sobolengine_bounds" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_bounds_scrambled" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_continuing" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_continuing_scrambled" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_distribution" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_distribution_scrambled" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_draw" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_draw_base2" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_draw_base2_scrambled" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_draw_scrambled" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_fast_forward" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_fast_forward_scrambled" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_first_point" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_high_dim" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_raise" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_reset" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sobolengine_reset_scrambled" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sort_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_split_neg_dim" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_squeeze_neg_dim" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_std_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_storage_casts" time="0.021" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6644: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.IntStorage([-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6645: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(storage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6646: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(storage.tolist(), [-1, 0, 1, 2, 3, 4])
c:\users\radekbarton\projects\pytorch\torch\storage.py:731: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return list(self)
c:\users\radekbarton\projects\pytorch\torch\storage.py:705: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return iter(map(lambda i: self[i], range(self.size())))
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6647: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(storage.type(), 'torch.IntStorage')
c:\users\radekbarton\projects\pytorch\torch\storage.py:1015: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type not in ['cpu', 'cuda']:
c:\users\radekbarton\projects\pytorch\torch\storage.py:1018: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  module = torch if self.device.type == 'cpu' else torch.cuda
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6650: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  floatStorage = storage.float()
c:\users\radekbarton\projects\pytorch\torch\storage.py:864: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.tensor([], dtype=self.dtype, device=self.device).set_(self).to(dtype)._typed_storage()
c:\users\radekbarton\projects\pytorch\torch\storage.py:865: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if storage.data_ptr() == self.data_ptr():
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6651: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(floatStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6652: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(floatStorage.tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6653: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(floatStorage.type(), 'torch.FloatStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6654: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(floatStorage.int().tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6657: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  halfStorage = storage.half()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6658: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(halfStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6659: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(halfStorage.tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6660: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(halfStorage.type(), 'torch.HalfStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6661: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(halfStorage.int().tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6664: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  bfloat16Storage = storage.bfloat16()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bfloat16Storage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6666: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bfloat16Storage.tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6667: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bfloat16Storage.type(), 'torch.BFloat16Storage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6668: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(bfloat16Storage.int().tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6671: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  longStorage = storage.long()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6672: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(longStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6673: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(longStorage.tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6674: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(longStorage.type(), 'torch.LongStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6675: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(longStorage.int().tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6678: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  shortStorage = storage.short()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6679: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(shortStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6680: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(shortStorage.tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6681: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(shortStorage.type(), 'torch.ShortStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6682: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(shortStorage.int().tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6685: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  doubleStorage = storage.double()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6686: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(doubleStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6687: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(doubleStorage.tolist(), [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6688: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(doubleStorage.type(), 'torch.DoubleStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6689: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(doubleStorage.int().tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6692: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  charStorage = storage.char()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6693: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(charStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6694: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(charStorage.tolist(), [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6695: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(charStorage.type(), 'torch.CharStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6696: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(charStorage.int().tolist(), [-1, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6699: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  byteStorage = storage.byte()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6700: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(byteStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6701: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(byteStorage.tolist(), [255, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6702: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(byteStorage.type(), 'torch.ByteStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6703: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(byteStorage.int().tolist(), [255, 0, 1, 2, 3, 4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6706: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  boolStorage = storage.bool()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6707: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(boolStorage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6708: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(boolStorage.tolist(), [True, False, True, True, True, True])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6709: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(boolStorage.type(), 'torch.BoolStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6710: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(boolStorage.int().tolist(), [1, 0, 1, 1, 1, 1])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6713: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  complexfloat_storage = torch.ComplexFloatStorage([-1, 0, 1 + 2j, 2.5j, 3.5, 4 - 2j])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6714: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(complexfloat_storage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6715: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(complexfloat_storage.tolist(), [-1, 0, 1 + 2j, 2.5j, 3.5, 4 - 2j])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6716: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(complexfloat_storage.type(), 'torch.ComplexFloatStorage')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6719: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  complexdouble_storage = complexfloat_storage.complex_double()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6720: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(complexdouble_storage.size(), 6)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6721: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(complexdouble_storage.tolist(), [-1, 0, 1 + 2j, 2.5j, 3.5, 4 - 2j])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6722: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(complexdouble_storage.type(), 'torch.ComplexDoubleStorage')
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_storage_error" time="0.024" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6538: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  torch.storage._LegacyStorage()
c:\users\radekbarton\projects\pytorch\torch\_utils.py:777: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6552: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() storage_class(device='cpu')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6555: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() storage_class(dtype=torch.float)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6561: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_class(0, 0)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6564: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_class('string')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6567: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_class(torch.tensor([]))
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6569: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s = storage_class()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6572: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_class(0, wrap_storage=s.untyped())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6575: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() storage_class(wrap_storage=s)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6594: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  torch.TypedStorage(0, wrap_storage=s.untyped(), dtype=dtype)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6597: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() torch.TypedStorage(wrap_storage=s.untyped())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6600: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() torch.TypedStorage(wrap_storage=s.untyped(), dtype=0)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6603: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() torch.TypedStorage(wrap_storage=s.untyped(), dtype=dtype, device=device)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6606: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() torch.TypedStorage(wrap_storage=s, dtype=dtype)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6609: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() torch.TypedStorage(dtype=dtype, device='xla')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6617: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  torch.TypedStorage(torch.tensor([]), dtype=dtype, device=device)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6620: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  torch.TypedStorage(0, 0, dtype=dtype, device=device)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6623: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s_other = torch.TypedStorage([1, 2, 3, 4], device=device, dtype=dtype)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6626: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s.fill_(s_other)
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_storage_error_no_attribute" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6635: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_class.from_buffer()
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_structseq_repr" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_subclass_preserved" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_subclass_tensors" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_sum_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_t_not_2d_error" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_base_init" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_base_new" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_ctor_scalar" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_cycle_via_dict" time="0.121" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_cycle_via_slots" time="0.053" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_dict_dealloc" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_finalizer_dealloc" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_set" time="0.003" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6014: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(t1.storage()._cdata, t2.storage()._cdata)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6016: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  t1.set_(t2.storage(), 0, size)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6018: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  t1.set_(t2.storage(), 0, tuple(size))
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6022: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  t1.set_(t2.storage(), 0, size, stride)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6024: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  t1.set_(t2.storage(), 0, size=size, stride=stride)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6032: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(t1.storage()._cdata, t2.storage()._cdata)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6034: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() t1.set_(source=t2.storage())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6035: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(t1.storage()._cdata, t2.storage()._cdata)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6037: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() t1.set_(source=t2.storage(), storage_offset=0, size=size, stride=stride)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6044: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(t1.storage()._cdata, t2.storage()._cdata)
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_tensor_set_errors" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6051: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertRaises(RuntimeError, lambda: f_cpu.set_(d_cpu.storage()))
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6053: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  lambda: f_cpu.set_(d_cpu.storage(), 0, d_cpu.size(), d_cpu.stride()))
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_tensor_slot_dealloc" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_weakref_dealloc" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensor_where_scalar" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_tensoriterator_output_setup" time="0.265" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_to" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_to_with_tensor" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_topk_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_torch_from_file" time="0.018" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_transpose_neg_dim" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_type" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_type_alias" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_type_conversion_via_dtype_name" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_typed_storage_deprecation_warning" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6798: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0 = torch.FloatStorage(10)
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_typed_storage_internal_no_warning" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6728: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0 = torch.FloatStorage(10)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:6729: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0_untyped = s0.untyped()
      </system-err>
    </testcase>
    <testcase classname="TestTorch" name="test_unbind_neg_dim" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_unflatten" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_unfold_neg_dim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_unsqueeze_neg_dim" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_upsample_nearest1d_meta" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_upsample_nearest2d_meta" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_var_neg_dim" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_warn_types" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorch" name="test_wildcard_import" time="0.003" file="test_torch.py" />
    <testcase classname="TestVitalSignsCudaCPU" name="test_cuda_vitals_gpu_only_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:111: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_complex64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcdiv_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_complex64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_addcmul_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_assertRaisesRegex_ignore_msg_non_native_device_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_edge_cases_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1988: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_edge_cases_cpu_float64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1988: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_mem_overlap_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_p_cpu_bfloat16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_p_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_p_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bernoulli_self_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bfloat16_float_copy_cpu" time="0.134" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bool_tensor_value_change_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_add_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_addcdiv_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_addcmul_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_atan2_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_copy_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_dist_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_div_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_eq_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_fmod_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_ge_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_gt_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_le_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_lerp_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_lt_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_map2_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_map_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_masked_fill_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_masked_scatter_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_masked_select_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_max_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_min_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_mul_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_ne_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_pow_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_remainder_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_broadcast_fn_sub_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_bool" time="0.003" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:161: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(scalar.storage().untyped().tolist(), bytes_list)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_complex128" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_complex64" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_float32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_float64" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_int16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_int32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_int64" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_bytes_to_scalar_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_cpu_bfloat16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_cpu_float16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_kstest_cpu_bfloat16" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2116: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_kstest_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2116: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_kstest_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2116: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_kstest_cpu_float64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2116: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_no_inf_cpu_bfloat16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2128: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cauchy_no_inf_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2128: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_cuda_backward_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2253: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_empty_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_euclidean_large_cpu" time="0.062" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_grad_p_lt_1_no_nan_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_large_batch_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2285: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_large_cpu" time="0.274" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_non_contiguous_batch_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_non_contiguous_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_norm_batch_cpu" time="0.560" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_norm_cpu" time="0.188" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cdist_same_inputs_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_check_tensor_all_cpu" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_check_tensor_internal_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_clone_all_dtypes_and_devices_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_clone_not_memory_dense_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_clone_zero_stride_dim_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_complex_half_experimental_warning_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_constants_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_conv_transposed_large_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:979: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_bfloat16" time="0.005" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:5392: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Copy.cpp:276.)
  t.copy_(src)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_complex128" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_complex32" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_complex64" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_float16" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_float32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_float64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_int16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_int32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_int64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_int8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy__cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy_all_dtypes_and_devices_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy_math_view_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy_mem_overlap_cpu_float64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy_transpose_math_view_cpu_complex64" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy_transpose_math_view_cpu_float32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_copy_transpose_math_view_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_corrcoef_cpu_complex64" time="0.049" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2043: UserWarning: cov(): degrees of freedom is &lt;= 0 (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Correlation.cpp:117.)
  res = torch.corrcoef(x)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:518: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\core\_methods.py:184: RuntimeWarning: invalid value encountered in divide
  ret = um.true_divide(
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:2846: RuntimeWarning: Degrees of freedom &lt;= 0 for slice
  c = cov(x, y, rowvar, dtype=dtype)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:2705: RuntimeWarning: divide by zero encountered in divide
  c *= np.true_divide(1, fact)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:2705: RuntimeWarning: invalid value encountered in multiply
  c *= np.true_divide(1, fact)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:2852: RuntimeWarning: invalid value encountered in divide
  return c / c
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:2854: RuntimeWarning: invalid value encountered in divide
  c /= stddev[:, None]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:2855: RuntimeWarning: invalid value encountered in divide
  c /= stddev[None, :]
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_corrcoef_cpu_float32" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_corrcoef_cpu_int32" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cov_cpu_complex64" time="0.107" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2050: UserWarning: cov(): degrees of freedom is &lt;= 0 (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Correlation.cpp:117.)
  res = torch.cov(t, correction=correction, fweights=fweights, aweights=aweights)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2054: RuntimeWarning: Degrees of freedom &lt;= 0 for slice
  ref = np.cov(t, ddof=correction, fweights=fweights, aweights=aweights)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:551: RuntimeWarning: invalid value encountered in multiply
  avg = avg_as_array = np.multiply(a, wgt,
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cov_cpu_float32" time="0.059" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cov_cpu_int32" time="0.065" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cpp_warnings_have_python_context_cpu" time="0.350" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cublas_config_nondeterministic_alert_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1181: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cummax_cummin_cpu" time="0.014" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cummax_discontiguous_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cummin_discontiguous_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cumprod_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_cumsum_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_deepcopy_cpu_complex64" time="0.027" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:385: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  q = [a, [a.storage(), b.storage()], b, c]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\copy.py:153: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  y = copier(memo)
c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_utils.py:1937: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() device=typed_storage.device,
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:396: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(w[1][0][i], q[1][0][i] + 1)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:400: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(w[1][1][i], q[1][1][i] - 1)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_deepcopy_cpu_float32" time="0.016" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_deepcopy_scalar_cpu_complex64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_deepcopy_scalar_cpu_float32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_device_guard_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="fewer than 2 devices detected">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4376: fewer than 2 devices detected</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_bool" time="0.058" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_complex128" time="0.070" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_complex64" time="0.072" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_float16" time="0.069" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_float32" time="0.065" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_float64" time="0.064" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_int16" time="0.051" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_int32" time="0.052" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_int64" time="0.049" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_int8" time="0.050" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_cpu_uint8" time="0.050" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_bool" time="0.049" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_complex128" time="0.068" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_complex64" time="0.071" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_float16" time="0.067" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_float32" time="0.070" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_float64" time="0.065" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_int16" time="0.051" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_int32" time="0.051" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_int64" time="0.049" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_int8" time="0.051" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_diff_noncontig_cpu_uint8" time="0.051" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_dim_function_empty_cpu" time="0.019" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_discontiguous_out_cumsum_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_dist_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_errors_index_copy_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_expected_failure_xla_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_cpu_bfloat16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_cpu_float16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_kstest_cpu_bfloat16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2105: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_kstest_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2105: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_kstest_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2105: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_kstest_cpu_float64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2105: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_no_zero_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2016: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_exponential_no_zero_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2016: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gather_backward_deterministic_path_cpu" time="2.318" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gather_backward_one_dim_cpu" time="2.309" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_bfloat16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_float16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_int16" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_int32" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_int64" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_int8" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_cpu_uint8" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_bfloat16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_float64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_int16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_int32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_int64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_int8" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_geometric_kstest_cpu_uint8" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2152: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gradient_all_cpu_complex64" time="0.282" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gradient_all_cpu_float32" time="0.259" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gradient_all_cpu_int64" time="0.212" file="test_torch.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1240: RuntimeWarning: divide by zero encountered in divide
  a = -(dx2)/(dx1 * (dx1 + dx2))
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1241: RuntimeWarning: divide by zero encountered in divide
  b = (dx2 - dx1) / (dx1 * dx2)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1242: RuntimeWarning: divide by zero encountered in divide
  c = dx1 / (dx2 * (dx1 + dx2))
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1248: RuntimeWarning: invalid value encountered in add
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1296: RuntimeWarning: divide by zero encountered in scalar divide
  a = (dx2) / (dx1 * (dx1 + dx2))
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1297: RuntimeWarning: divide by zero encountered in scalar divide
  b = - (dx2 + dx1) / (dx1 * dx2)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1300: RuntimeWarning: invalid value encountered in scalar add
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1279: RuntimeWarning: divide by zero encountered in scalar divide
  a = -(2. * dx1 + dx2)/(dx1 * (dx1 + dx2))
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1280: RuntimeWarning: divide by zero encountered in scalar divide
  b = (dx1 + dx2) / (dx1 * dx2)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1283: RuntimeWarning: invalid value encountered in add
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1300: RuntimeWarning: invalid value encountered in add
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1257: RuntimeWarning: divide by zero encountered in divide
  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1257: RuntimeWarning: invalid value encountered in divide
  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1248: RuntimeWarning: invalid value encountered in multiply
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1281: RuntimeWarning: divide by zero encountered in scalar divide
  c = - dx1 / (dx2 * (dx1 + dx2))
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1283: RuntimeWarning: invalid value encountered in multiply
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1300: RuntimeWarning: invalid value encountered in multiply
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1298: RuntimeWarning: divide by zero encountered in scalar divide
  c = (2. * dx2 + dx1) / (dx2 * (dx1 + dx2))
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1264: RuntimeWarning: divide by zero encountered in divide
  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1264: RuntimeWarning: invalid value encountered in divide
  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gradient_extreme_cases_cpu_complex64" time="0.139" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gradient_extreme_cases_cpu_float32" time="0.190" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gradient_extreme_cases_cpu_int64" time="0.152" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_gradient_type_promotion_cpu" time="0.115" file="test_torch.py">
      <system-err>C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1236: ComplexWarning: Casting complex values to real discards the imaginary part
  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1257: ComplexWarning: Casting complex values to real discards the imaginary part
  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1264: ComplexWarning: Casting complex values to real discards the imaginary part
  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n
c:\users\radekbarton\projects\pytorch\torch\testing\_comparison.py:682: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\torch\csrc\utils\tensor_numpy.cpp:212.)
  return torch.as_tensor(tensor_like)
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1283: ComplexWarning: Casting complex values to real discards the imaginary part
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1300: ComplexWarning: Casting complex values to real discards the imaginary part
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
C:\Users\radekbarton\AppData\Local\Programs\Python\Python311-arm64\Lib\site-packages\numpy\lib\function_base.py:1248: ComplexWarning: Casting complex values to real discards the imaginary part
  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_hook_remove_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_add_deterministic_cpu" time="0.125" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_add_mem_overlap_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_bfloat16" time="0.017" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_bool" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_complex128" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_complex64" time="0.017" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_float16" time="0.011" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_float32" time="0.015" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_float64" time="0.028" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_int16" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_int32" time="0.019" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_int64" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_int8" time="0.012" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_cpu_uint8" time="0.014" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_deterministic_cpu" time="5.856" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_mem_overlap_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_bfloat16" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_bool" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_complex128" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_complex64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_float16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_float32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_float64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_int16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_int32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_int64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_int8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_copy_scalars_cpu_uint8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_bfloat16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_bool" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_complex128" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_complex64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_float16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_float32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_fill_mem_overlap_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_put_mem_overlap_cpu" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_put_non_accumulate_deterministic_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_bfloat16" time="0.078" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:3123: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\TensorAdvancedIndexing.cpp:1110.)
  dest.index_reduce_(dim, idx, src, reduce, include_self=include_self)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_float16" time="0.106" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_float32" time="0.103" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_float64" time="0.133" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_int16" time="0.100" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_int32" time="0.094" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_int64" time="0.092" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_int8" time="0.093" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amax_cpu_uint8" time="0.075" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_bfloat16" time="0.227" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_float16" time="0.109" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_float32" time="0.108" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_float64" time="0.101" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_int16" time="0.103" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_int32" time="0.127" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_int64" time="0.068" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_int8" time="0.065" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_amin_cpu_uint8" time="0.096" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_bfloat16" time="0.123" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_float16" time="0.315" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_float32" time="0.121" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_float64" time="0.097" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_int16" time="0.080" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_int32" time="0.130" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_int64" time="0.116" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_int8" time="0.101" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_mean_cpu_uint8" time="0.082" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_bfloat16" time="0.079" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_float16" time="0.359" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_float32" time="0.104" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_float64" time="0.095" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_int16" time="0.089" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_int32" time="0.214" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_int64" time="0.076" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_int8" time="0.081" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_reduce_reduce_prod_cpu_uint8" time="0.084" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_bfloat16" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_bool" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_complex128" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_complex64" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_float16" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_float32" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_float64" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_int16" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_int32" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_int64" time="0.012" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_int8" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_index_select_cpu_uint8" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_invalid_shapes_grid_sampler_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_is_set_to_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_is_signed_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_bfloat16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_complex32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_complex64" time="0.014" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_float16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_float32" time="0.032" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_int32" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_int64" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_int8" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_item_cpu_uint8" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_large_cumprod_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2856: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_large_cumsum_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2842: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_log_normal_cpu_bfloat16" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_log_normal_cpu_float16" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_log_normal_cpu_float32" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_log_normal_cpu_float64" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_logcumsumexp_cpu" time="0.018" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_lognormal_kstest_cpu_bfloat16" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2090: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_lognormal_kstest_cpu_float16" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2090: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_lognormal_kstest_cpu_float32" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2090: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_lognormal_kstest_cpu_float64" time="0.023" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2090: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_bool_tensor_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_bfloat16_bool" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_bfloat16_uint8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_bool_bool" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_bool_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_complex128_bool" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_complex128_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_complex64_bool" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_complex64_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_float16_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_float16_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_float32_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_float32_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_float64_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_float64_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int16_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int16_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int32_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int32_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int64_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int64_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int8_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_int8_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_uint8_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_cpu_uint8_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_fill_mem_overlap_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_bool_tensor_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_bfloat16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_complex128" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_complex64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_float16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_float32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_float64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_int16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_int32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_int64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_int8" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_cpu_uint8" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_large_tensor_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:3734: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_scatter_mem_overlap_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_bfloat16" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_bool" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_complex128" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_complex64" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_float16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_float32" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_float64" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_int16" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_int32" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_int64" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_int8" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_cpu_uint8" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_masked_select_discontiguous_cpu" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_clone_cpu" time="0.017" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_consistency_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_cpu_and_cuda_ops_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:5153: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_empty_like_cpu" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_factory_like_functions_preserve_cpu" time="0.278" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_operators_cpu" time="0.245" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_preserved_after_permute_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_propagation_rules_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_to_cpu" time="0.022" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_type_cpu" time="0.023" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_memory_format_type_shortcuts_cpu" time="0.376" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_module_share_memory_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:371: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_cpu_cpu_bfloat16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_cpu_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_cpu_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_cpu_float32" time="0.039" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_cpu_float64" time="0.037" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_deterministic_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4953: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_deterministic_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4953: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_deterministic_cpu_float64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4953: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_device_constrain_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4356: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_empty_w_replacement_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_empty_wo_replacement_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_gpu_device_constrain_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="fewer than 2 devices detected">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4365: fewer than 2 devices detected</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_multinomial_rng_state_advance_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4975: test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_narrow_copy_non_contiguous_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_narrow_empty_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_AdaptiveAvgPool2d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_AdaptiveAvgPool3d_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_AdaptiveMaxPool2d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_AvgPool3d_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_CTCLoss_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_EmbeddingBag_max_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_FractionalMaxPool2d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_FractionalMaxPool3d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxPool3d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool1d_cpu_float16" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="float16 not implemented on CPU">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1345: float16 not implemented on CPU</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool1d_cpu_float32" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool1d_cpu_float64" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool2d_cpu_float16" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="float16 not implemented on CPU">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1359: float16 not implemented on CPU</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool2d_cpu_float32" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool2d_cpu_float64" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool3d_cpu_float16" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="float16 not implemented on CPU">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1373: float16 not implemented on CPU</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool3d_cpu_float32" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_MaxUnpool3d_cpu_float64" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_NLLLoss_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_ReflectionPad1d_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_ReflectionPad2d_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_ReflectionPad3d_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_ReplicationPad1d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_ReplicationPad2d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_ReplicationPad3d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_bincount_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_complex64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_cumsum_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_grid_sample_2d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_grid_sample_3d_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_histc_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_interpolate_bicubic_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_interpolate_bilinear_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_interpolate_linear_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_interpolate_trilinear_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_kthvalue_cpu_float64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_median_cpu_float64" time="0.003" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1754: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape []. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\Resize.cpp:33.)
  torch.median(a, 0, out=(result, indices))
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_put_accumulate_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nondeterministic_alert_put_cpu" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_normal_kstest_cpu_float16" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2078: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_normal_kstest_cpu_float32" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2078: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_normal_kstest_cpu_float64" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2078: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_nullary_op_mem_overlap_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_pairwise_distance_empty_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_pdist_empty_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_pdist_norm_large_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4074: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_pickle_gradscaler_cpu" time="0.004" file="test_torch.py">
      <system-err>c:\users\radekbarton\projects\pytorch\torch\cuda\amp\grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_pin_memory_from_constructor_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4816: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_bfloat16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_complex64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_float16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_accumulate_cpu_uint8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_bfloat16" time="0.063" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_complex128" time="0.110" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_complex64" time="0.065" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_float16" time="0.058" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_float32" time="0.063" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_float64" time="0.057" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_int16" time="0.044" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_int32" time="0.058" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_int64" time="0.073" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_int8" time="0.155" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_cpu_uint8" time="0.058" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_empty_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_put_mem_overlap_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_repeat_interleave_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scalar_check_cpu" time="0.023" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual((), zero_d_clone.set_(one_d.storage(), 0, (), ()).shape)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:666: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual((1,), zero_d_clone.set_(one_d.storage(), 0, (1,), (1,)).shape)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:667: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual((), one_d_clone.set_(one_d.storage(), 0, (), ()).shape)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:668: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual((1,), one_d_clone.set_(one_d.storage(), 0, (1,), (1,)).shape)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_add_bool_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_add_non_unique_index_cpu" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_add_one_dim_deterministic_cpu" time="2.455" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_add_to_large_input_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_bool_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_mem_overlap_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_multiply_unsupported_dtypes_cpu_complex128" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:3603: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_multiply_unsupported_dtypes_cpu_complex64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:3603: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_bfloat16" time="0.005" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:3600: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at C:\Users\radekbarton\Projects\pytorch\aten\src\ATen\native\TensorAdvancedIndexing.cpp:227.)
  input.scatter_(0, index, src, reduce=operation)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_bool" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_complex128" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_complex64" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_float16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_float32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_float64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_int16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_int32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_int64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_non_unique_index_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_bfloat16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_complex64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_float16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_operations_to_large_input_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_bfloat16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_complex64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_float16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_int16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_reduce_scalar_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_to_large_input_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_scatter_zero_size_index_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_serialization_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4485: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_bfloat16" time="0.006" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:257: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  a_s = a.storage()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:260: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  c = torch.tensor([], device=device, dtype=dtype).set_(a_s.untyped()).reshape(a.size())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:267: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  error_storage = a.to(error_dtype).storage()
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_bool" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_complex128" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_complex64" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_float16" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_float32" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_float64" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_int16" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_int32" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_int64" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_int8" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_set_storage_cpu_uint8" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_shift_mem_overlap_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_skip_xla_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_all_devices_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4851: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_bool" time="0.006" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:168: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(v.storage()[0], v[0][0])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:169: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(v.storage()[14], v[2][4])
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:170: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  v_s = v.storage()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:176: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  v_s[el_num],
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:179: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  v_s_byte = v.storage().untyped()
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_complex128" time="0.017" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_complex64" time="0.012" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_float32" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_float64" time="0.012" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_int16" time="0.007" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_int32" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_int64" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_int8" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_cpu_uint8" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_bfloat16" time="0.006" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:331: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0 = torch.TypedStorage([1, 2, 3, 4], device='meta', dtype=dtype)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:334: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0.cpu()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:353: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0.resize_(10)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:356: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0.share_memory_()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:359: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0.tolist()
c:\users\radekbarton\projects\pytorch\torch\storage.py:731: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return list(self)
c:\users\radekbarton\projects\pytorch\torch\storage.py:705: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return iter(map(lambda i: self[i], range(self.size())))
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:363: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s0._write_file(f, True, True, s0.element_size())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:366: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s1 = torch.TypedStorage([1, 2, 3, 4], device=device, dtype=dtype)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:369: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s1.copy_(s0)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_bool" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_complex128" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_complex64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_float16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_float32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_float64" time="0.005" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_int16" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_int32" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_int64" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_int8" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_errors_cpu_uint8" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_bfloat16" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:324: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s_check = t_check.storage()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:325: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s = t.storage()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:279: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s.device.type, 'meta')
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:280: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s.nbytes(), s_check.nbytes())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:281: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s.size(), s_check.size())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:282: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s.data_ptr(), 0)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:285: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s[0]
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:289: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self._check_storage_meta(s.untyped(), s_check.untyped())
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_bool" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_complex64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_float16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_float32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_float64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_int16" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_int64" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_int8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_meta_from_tensor_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_bool" time="0.003" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:210: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s = storage_type(N)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:211: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s[:] = 0
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:213: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s, storage_type(l))
c:\users\radekbarton\projects\pytorch\torch\testing\_internal\common_utils.py:1937: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() device=typed_storage.device,
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:216: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s[i] = i
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:219: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s, storage_type(l))
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:222: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s[2:7] = 1
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:223: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(s, storage_type(l))
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_complex128" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_complex64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_float32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_float64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_int16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_int32" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_int64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_int8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_qint32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_qint8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_quint4x2" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_quint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_storage_setitem_cpu_uint8" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_strides_propagation_cpu" time="0.109" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_sync_warning_cpu" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="Only runs on cuda">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:1836: Only runs on cuda</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_bfloat16" time="0.011" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_bool" time="0.011" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_complex128" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_complex64" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_float16" time="0.013" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_float32" time="0.012" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_float64" time="0.011" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_int16" time="0.011" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_int32" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_int64" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_int8" time="0.011" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_cpu_uint8" time="0.011" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_take_empty_cpu" time="0.004" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_bfloat16" time="0.007" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:240: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  a_s = a.storage()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:241: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  b = torch.tensor(a_s, device=device, dtype=dtype).reshape(a.size())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:243: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  c = torch.tensor(a_s.untyped(), device=device, dtype=dtype).reshape(a.size())
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:250: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  error_storage = a.to(error_dtype).storage()
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:251: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  torch.tensor(error_storage, device=device, dtype=dtype)
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_bool" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_complex128" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_complex64" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_float16" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_float32" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_float64" time="0.008" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_int16" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_int32" time="0.009" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_int64" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_int8" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_from_storage_cpu_uint8" time="0.006" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_set_errors_multigpu_cpu" time="0.002" file="test_torch.py">
      <skipped type="pytest.skip" message="fewer than 2 devices detected">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:4472: fewer than 2 devices detected</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_shape_empty_cpu" time="0.010" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_bfloat16" time="0.002" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:234: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.assertEqual(a.storage_type(), expected_storage_type)
c:\users\radekbarton\projects\pytorch\torch\storage.py:1015: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type not in ['cpu', 'cuda']:
c:\users\radekbarton\projects\pytorch\torch\storage.py:1018: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  module = torch if self.device.type == 'cpu' else torch.cuda
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_bool" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_complex128" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_complex64" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_float16" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_float32" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_float64" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_int16" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_int32" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_int64" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_int8" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_tensor_storage_type_cpu_uint8" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_ternary_op_mem_overlap_cpu_float64" time="0.016" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_bfloat16" time="0.003" file="test_torch.py">
      <system-err>C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:301: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s_check = torch.TypedStorage(*args, dtype=dtype, device=device)
C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:302: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  s = torch.TypedStorage(*args, dtype=dtype, device='meta')
      </system-err>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_bool" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_complex128" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_complex64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_float16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_float32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_float64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_int16" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_int32" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_int64" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_int8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_typed_storage_meta_cpu_uint8" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_unfold_all_devices_and_dtypes_cpu" time="0.003" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_unfold_scalars_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_uniform_kstest_cpu_bfloat16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2066: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_uniform_kstest_cpu_float16" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2066: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_uniform_kstest_cpu_float32" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2066: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_uniform_kstest_cpu_float64" time="0.001" file="test_torch.py">
      <skipped type="pytest.skip" message="test require SciPy, but SciPy not found">C:\Users\radekbarton\Projects\pytorch\test\test_torch.py:2066: test require SciPy, but SciPy not found</skipped>
    </testcase>
    <testcase classname="TestTorchDeviceTypeCPU" name="test_untyped_storage_meta_cpu" time="0.002" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_warn_always_caught_cpu" time="0.001" file="test_torch.py" />
    <testcase classname="TestTorchDeviceTypeCPU" name="test_where_scalar_handcrafted_values_cpu" time="0.023" file="test_torch.py" />
  </testsuite>
</testsuites>